,Unnamed: 0,title,publication_year,title_link,authors,author_href,content
0,0,An Extended Plant Circadian Clock Model for Characterising Flowering Time under Different Light Quality Conditions,['9 Jan 2023'],https://pureportal.coventry.ac.uk/en/publications/an-extended-plant-circadian-clock-model-for-characterising-flower,"['Pay, M. L.', 'Christensen, J.', 'He, F.', 'Roden, L.']","['https://pureportal.coventry.ac.uk/en/persons/miao-lin-pay', 'https://pureportal.coventry.ac.uk/en/persons/jesper-christensen', 'https://pureportal.coventry.ac.uk/en/persons/fei-he', 'https://pureportal.coventry.ac.uk/en/persons/laura-roden']","Speed breeding has recently emerged as an innovative agricultural technology solution to meet the ever-increasing global food demand. In speed breeding, typically various light qualities (e.g., colour, duration, intensity) are modified to manipulate the circadian clock of the plants, which in turn alter the plant growth and enhance the productivity such as by reducing the flowering time. In order to develop a comprehensive framework describing plant growth, a model incorporating the effect of various light qualities on plant growth needs to be established. Recently a mathematical model of the plant circadian clock for Arabidopsis thaliana has been developed to characterise the hypocotyl growth subject to multiple light quality properties. This is a first step towards developing a more comprehensive model that links light quality, plant circadian clock and plant growth. In this work, we extend the model by adding the effect of various light qualities on the flowering time. The proposed model can capture the flowering time behaviours of plant when subject to red, blue, and mixed lights and can be used to guide experiment of light properties manipulation for optimised plant growth via hypocotyl growth and flowering time. "
1,1,Challenges and prospects of climate change impact assessment on mangrove environments through mathematical models,['25 Feb 2023'],https://pureportal.coventry.ac.uk/en/publications/challenges-and-prospects-of-climate-change-impact-assessment-on-m,"['Fanous, M.', 'Eden, J.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/majdi-fanous', 'https://pureportal.coventry.ac.uk/en/persons/jonathan-eden', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","The impacts of climate change, especially sea-level rise, are an increasing threat to the world’s coastal regions. Following recommendations made by the United Nations about the preservation of mangrove environments, particularly given their potential for effective natural defence against wave-driven hazards, a series of experiments have been conducted to quantify the ability of mangroves to counter climate change impacts. To date, these experiments have been limited by computational cost and inability to model multiple scenarios. With improved data quality and availability, machine learning has enormous potential to supplement, or even replace, existing numerical methods. This article presents both an outline of the importance of protecting mangrove environments and a review of methods currently used to quantify the capacity of mangroves to adapt to climate change impacts. In view of the limitations of existing numerical methods, the article also discusses the potential of machine learning as an efficient and effective alternative."
2,2,Diabetic Retinopathy Detection Using Transfer and Reinforcement Learning with Effective Image Preprocessing and Data Augmentation Techniques,['7 Feb 2023'],https://pureportal.coventry.ac.uk/en/publications/diabetic-retinopathy-detection-using-transfer-and-reinforcement-l,"['Tariq, M.', 'Palade, V.', 'Ma, Y.']","['https://pureportal.coventry.ac.uk/en/persons/maria-tariq', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade', 'https://pureportal.coventry.ac.uk/en/persons/yingliang-ma']","Diabetic retinopathy is the consequence of advanced stages of diabetes, which can ultimately lead to permanent blindness. An early detection of diabetic retinopathy is extremely important to avoid blindness and to recover from it as soon as possible. This chapter discusses the application of recent deep and transfer learning models for medical image analysis, with the focus on diabetic retinopathy detection. The chapter presents an extensive discussion on the publicly available datasets with diabetic retinopathy images, and the Kaggle dataset is used for training and testing of our proposed model. The main challenges to handle noisy and not large enough datasets are discussed in this chapter as well, where image preprocessing techniques and data augmentation play a significant role. An extensive overview of recent data augmentation techniques is also given to tackle the problem of imbalanced nature of diabetic retinopathy datasets. The proposed model integrates deep learning and reinforcement learning to perform detection and imbalanced classification on the Kaggle dataset."
3,3,Entropy‐based lamarckian quantum‐behaved particle swarm optimization for flexible ligand docking,['Mar 2023'],https://pureportal.coventry.ac.uk/en/publications/entropybased-lamarckian-quantumbehaved-particle-swarm-optimizatio,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"AutoDock is a widely used software for flexible ligand docking problems since it is open source and easy to be implemented. In this paper, a novel hybrid algorithm is proposed and applied in the docking environment of AutoDock version 4.2.6 in order to enhance the accuracy and the efficiency for dockings with flexible ligands. This search algorithm, called entropy-based Lamarckian quantum-behaved particle swarm optimization (ELQPSO), is a combination of the QPSO with an entropy-based update strategy and the Solis and Wet local search (SWLS) method. By using the PDBbind core set v.2016, the ELQPSO is compared with the Lamarckian genetic algorithm (LGA), Lamarckian particle swarm optimization (LPSO) and Lamarckian QPSO (LQPSO). The experimental results reveal that the corresponding docking program of ELQPSO, named as EQDOCK in this paper, has a competitive performance in dealing with the protein-ligand docking problems. Moreover, for the test cases with different number of torsions, the EQDOCK outperforms the other three docking programs in finding docking conformations with small root mean squared deviation (RMSD) values in most cases. In particular, it has an advantage of solving highly flexible ligand docking problems over the others."
4,4,Extracting the Evolutionary Backbone of Scientific Domains: The Semantic Main Path Network Approach Based on Citation Context Analysis,['15 Feb 2023'],https://pureportal.coventry.ac.uk/en/publications/extracting-the-evolutionary-backbone-of-scientific-domains-the-se,"['Jiang, X.']",['https://pureportal.coventry.ac.uk/en/persons/xiaorui-jiang'],"Main path analysis is a popular method for extracting the scientific backbone from the citation network of a research domain. Existing approaches ignored the semantic relationships between the citing and cited publications, resulting in several adverse issues, in terms of coherence of main paths and coverage of significant studies. This paper advocated the semantic main path analysis approach to alleviate these issues based on citation function analysis. A wide variety of SciBERT-based deep learning models were designed for identifying citation functions. Semantic citation networks were built by either including important citations, e.g., extension, motivation, usage and similarity, or excluding incidental citations like background and future work. Semantic main path network was built by merging the top-K main paths extracted from various time slices of semantic citation network. In addition, this study proposed a three-way framework for quantitative evaluation of main path analysis results. Both qualitative and quantitative analysis on three research areas of computational linguistics demonstrated that, compared to semantics-agnostic counterparts, different types of semantic main path networks provide complementary views scientific knowledge flows. Combining them together, we can obtain a more precise and comprehensive picture of domain evolution and uncover more coherent development pathways between scientific ideas. "
5,5,Gene Regulatory Network Inference through Link Prediction using Graph Neural Network,['19 Jan 2023'],https://pureportal.coventry.ac.uk/en/publications/gene-regulatory-network-inference-through-link-prediction-using-g,"['Ganeshamoorthy, S.', 'Roden, L.', 'Klepl, D.', 'He, F.']","['https://pureportal.coventry.ac.uk/en/persons/sivasharmini-ganeshamoorthy', 'https://pureportal.coventry.ac.uk/en/persons/laura-roden', 'https://pureportal.coventry.ac.uk/en/persons/dominik-klepl', 'https://pureportal.coventry.ac.uk/en/persons/fei-he']","Gene Regulatory Networks (GRNs) depict the causal regulatory interactions between transcription factors (TFs) and their target genes [2], where TFs are proteins that regulate gene transcription. GRN plays a vital role in explaining gene function, which helps to identify and prioritize the candidate genes for functional analysis [3]. Currently, high-dimensional transcriptome datasets are produced from high-throughput sequencing techniques, such as microarray and RNA-Seq. These techniques can capture the differences in the expression of thousands of genes at once. Through these wet-lab experiments, studying the interconnections among a large number of genes or TFs at a network level is challenging [4]. Therefore, one of the important topics in computational biology is the inference of GRNs from high-dimensional gene expression data through statistical and machine learning approaches [2]."
6,6,Hydro-morphodynamic modelling of mangroves imposed by tidal waves using finite element discontinuous Galerkin method,['28 Mar 2023'],https://pureportal.coventry.ac.uk/en/publications/hydro-morphodynamic-modelling-of-mangroves-imposed-by-tidal-waves,"['Fanous, M.', 'Daneshkhah, A.', 'Eden, J. M.', 'Palade, V.']","['https://pureportal.coventry.ac.uk/en/persons/majdi-fanous', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah', 'https://pureportal.coventry.ac.uk/en/persons/jonathan-eden', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade']","Modelling the hydro-morphodynamics of mangrove environments is key for implementing successful protection and restoration projects in a climatically vulnerable region. Nevertheless, simulating such dynamics is faced with computational and time complexities, given the nonlinear and complex nature of the problem, which could become a bottleneck for large-scale applications. This study investigates the effect of mangrove environments on the hydro-morphodynamics of its region. A depth-averaged model was built using a novel finite element model for simulating coastal models, within Thetis. The Sundarbans, the largest mangrove forest in the world located between India and Bangladesh, is taken as a case study. The Sundarbans is regularly subjected to tropical cyclones, the impacts of which endanger the lives of the region’s four million people. This is a first-time application of a coupled hydro-morphodyamic model using discontinuous Galerkin finite element discretisation for modelling mangrove environments in a real-world application. A wetting drying scheme was implemented in the models in order to avoid numerical instabilities. The effect of mangrove environments is demonstrated ,by imposing a periodic tidal boundary, conditions using TPXO tidal solver, using experiments with and without mangroves. The model is validated against the results of another study on the same region and tidal gauge data. Mangrove environments are able to decrease water elevations and velocities by more than 97%, and prevent almost any sediment erosion when compared with the experiment with no mangroves."
7,7,Kernel-based Nonlinear Manifold Learning for EEG Functional Connectivity Analysis with Application to Alzheimer's Disease,['19 Jan 2023'],https://pureportal.coventry.ac.uk/en/publications/kernel-based-nonlinear-manifold-learning-for-eeg-functional-conne,"['Gunawardena, S. R. A. S.', 'He, F.']","['https://pureportal.coventry.ac.uk/en/persons/shenal-rajintha-alexander-samarathunge-gunawardena', 'https://pureportal.coventry.ac.uk/en/persons/fei-he']","Dynamical, causal and cross-frequency coupling analysis using the EEG has received significant interest for the analysis and diagnosis of neurological disorders [1]–[3]. Due to the high computational requirements needed for some of these methods, EEG channel selection is crucial [4]. Functional connectivity (FC) between EEG channels is often used for channel selection and connectivity analysis [4, S, 6]. Ideally, in the case of selecting channels for dynamical and causal analysis, FC methods should be able to account for linear and nonlinear spatial and temporal interactions between EEG channels. In neuroscience, FC is quantified using different measures of (dis) similarity to assess the statistical dependence between two signals [5]. However, the interpretation of FC measures can differ significantly from one measure to another[5, 7]. In the early diagnosis of AD, [7] showed correlations among various (dis)similarity measures, and therefore these measures can be grouped. Thus, one from each is sufficient to extract information from the data [7]. Therefore, the development of a generic measure of (dis)similarity is important in FC analysis."
8,8,Not Born of Woman: Gendered Robots,['26 Feb 2023'],https://pureportal.coventry.ac.uk/en/publications/not-born-of-woman-gendered-robots,"['Shah, H.']",['https://pureportal.coventry.ac.uk/en/persons/huma-shah'],"This chapter posits that gender, while being messy and non-binary, is a salient consideration in the development of virtual and embodied robots to avoid replicating stereotypical representations of men and women's roles and occupations in our future artificial work colleagues, and companions. Some questions are posed for robot developers with early responses from researchers working in the field."
9,9,PoseNormNet: Identity-preserved Posture Normalization of 3D Body Scans in Arbitrary Postures,['16 Feb 2023'],https://pureportal.coventry.ac.uk/en/publications/posenormnet-identity-preserved-posture-normalization-of-3d-body-s,"['Hu, P.']",['https://pureportal.coventry.ac.uk/en/persons/pengpeng-hu'],"3D human models accurately represent the shape of the subjects, which is key to many human-centric industrial applications, including fashion design, body biometrics extraction, and computer animation. These tasks usually require a high-fidelity human body mesh in a canonical posture (e.g., ‘A’ pose or ‘T’ pose). Although 3D scanning technology is fast and popular for acquiring the subject's body shape, automatically normalizing the posture of scanned bodies is still under-researched. Existing methods highly rely on skeleton-driven animation technologies. However, these methods require carefully-designed skeleton and skin weights, which is time-consuming and fails when the initial posture is complicated. In this work, a novel deep learning-based approach, dubbed PoseNormNet, is proposed to automatically normalize the postures of scanned bodies. The proposed algorithm provides strong operability since it does not require any rigging priors and works well for subjects in arbitrary postures. Extensive experimental results on both synthetic and real-world datasets demonstrate that the proposed method achieves state-of-the-art performance in both objective and subjective terms."
10,10,Unidirectional Migration of Populations with Allee Effect,['10 Jan 2023'],https://pureportal.coventry.ac.uk/en/publications/unidirectional-migration-of-populations-with-allee-effect,"['Sadeghimanesh, A.']",['https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh'],"In this note we consider two populations living on identical patches, connected by unidirectional migration, and subject to strong Allee effect. We show that by increasing the migration rate, there are more bifurcation sequences than previous works showed. In particular, the number of steady states can change from 9 (small migration) to 3 (large migration) at a single bifurcation point, or via a sequence of bifurcations with the system having 9, 7, 5, 3 steady states or 9, 7, 9, 3 steady states, depending on the Allee threshold. This is in contrast with the case of bidirectional migration, where the number of steady states always goes through the same bifurcation sequence of 9, 5, 3 steady states as we increase the migration rate, regardless of the value of the Allee threshold. These results have practical implications as well in spatial ecology."
11,11,XDLL: Explained Deep Learning LiDAR-Based Localization and Mapping Method for Self-Driving Vehicles,['22 Jan 2023'],https://pureportal.coventry.ac.uk/en/publications/xdll-explained-deep-learning-lidar-based-localization-and-mapping,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Self-driving vehicles need a robust positioning system to continue the revolution in intelligent transportation. Global navigation satellite systems (GNSS) are most commonly used to accomplish this task because of their ability to accurately locate the vehicle in the environment. However, recent publications have revealed serious cases where GNSS fails miserably to determine the position of the vehicle, for example, under a bridge, in a tunnel, or in dense forests. In this work, we propose a framework architecture of explaining deep learning LiDAR-based (XDLL) models that predicts the position of the vehicles by using only a few LiDAR points in the environment, which ensures the required fastness and accuracy of interactions between vehicle components. The proposed framework extracts non-semantic features from LiDAR scans using a clustering algorithm. The identified clusters serve as input to our deep learning model, which relies on LSTM and GRU layers to store the trajectory points and convolutional layers to smooth the data. The model has been extensively tested with short- and long-term trajectories from two benchmark datasets, Kitti and NCLT, containing different environmental scenarios. Moreover, we investigated the obtained results by explaining the contribution of each cluster feature by using several explainable methods, including Saliency, SmoothGrad, and VarGrad. The analysis showed that taking the mean of all the clusters as an input for the model is enough to obtain better accuracy compared to the first model, and it reduces the time consumption as well. The improved model is able to obtain a mean absolute positioning error of below one meter for all sequences in the short- and long-term trajectories."
12,12,A community energy management system for smart microgrids,['Aug 2022'],https://pureportal.coventry.ac.uk/en/publications/a-community-energy-management-system-for-smart-microgrids,"['Nixon, J. D.', 'Gaura, E.', 'Halford, A.']","['https://pureportal.coventry.ac.uk/en/persons/jonathan-nixon', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura', 'https://pureportal.coventry.ac.uk/en/persons/alison-halford']","Community micro-grid energy projects are needed to drive de-carbonisation and increase equity of energy systems among displaced communities. However, micro-grid solutions are often inflexible and lack functionality to respond to displaced community energy needs and ensure the long-term sustainability of interventions. This paper explores the use of fog-computing retrofit architectures deployed on community micro-grid infrastructures to enable flexible demand management to improve service delivery and longevity. A micro-services solution is proposed that decouples components increasing resilience and testability while allowing hybrid edge-cloud deployments. The architecture is outlined and demonstrated for a micro-grid providing energy to two nurseries and a playground in Kigeme refugee camp, Rwanda. To enact the community priorities within the demand management system, modified Genetic Algorithm (GA) methods are outlined and tested for different use-case scenarios. The performance of the modified GA methods are then compared with a pre-existing battery protect controller and an alternative deterministic (space-shared) energy manager model. A modified search space GA method was required for GA to outperform both the existing battery controller and proposed deterministic method in terms of achieving the highest utility function in almost every use-case. The results further showed how simple community priorities can be set and used to enact control on the system in 24h timeframes that are in line with the local decision-making context."
13,13,A Hybrid Linear Iterative Clustering and Bayes Classification-Based GrabCut Segmentation Scheme for Dynamic Detection of Cervical Cancer,['18 Oct 2022'],https://pureportal.coventry.ac.uk/en/publications/a-hybrid-linear-iterative-clustering-and-bayes-classification-bas,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Cervical cancer earlier detection remains indispensable for enhancing the survival rate probability among women patients worldwide. The early detection of cervical cancer is done relatively by using the Pap Smear cell Test. This method of detection is challenged by the degradation phenomenon within the image segmentation task that arises when the superpixel count is minimized. This paper introduces a Hybrid Linear Iterative Clustering and Bayes classification-based GrabCut Segmentation Technique (HLC-BC-GCST) for the dynamic detection of Cervical cancer. In this proposed HLC-BC-GCST approach, the Linear Iterative Clustering process is employed to cluster the potential features of the preprocessed image, which is then combined with GrabCut to prevent the issues that arise when the number of superpixels is minimized. In addition, the proposed HLC-BC-GCST scheme benefits of the advantages of the Gaussian mixture model (GMM) on the extracted features from the iterative clustering method, based on which the mapping is performed to describe the energy function. Then, Bayes classification is used for reconstructing the graph cut model from the extracted energy function derived from the GMM model-based Linear Iterative Clustering features for better computation and implementation. Finally, the boundary optimization method is utilized to considerably minimize the roughness of cervical cells, which contains the cytoplasm and nuclei regions, using the GrabCut algorithm to facilitate improved segmentation accuracy. The results of the proposed HLC-BC-GCST scheme are 6% better than the results obtained by other standard detection approaches of cervical cancer using graph cuts."
14,14,Allocating Medical Resources (vaccine) to Control a Pandemic,['26 Apr 2022'],https://pureportal.coventry.ac.uk/en/publications/allocating-medical-resources-vaccine-to-control-a-pandemic,"['Ajao-Olarinoye, M.']",['https://pureportal.coventry.ac.uk/en/persons/michael-ajao-olarinoye'],"In the aftermath of the COVID-19 pandemic, we need to better understand how to prepare for other pandemics in the future. This research uses computational techniques to better understand how medical resources can be allocated to controlling pandemics. Mathematical modelling techniques are used to study the transmission dynamics of infectious diseases, and to estimate the cost of implementing control measures. A mathematical model is used to solve problem statements drawn from assumptions. Optimizing the allocation of resources can be achieved by using algorithms to optimise the cost of distributing resources in order to control a pandemic. The goal of this research would be to find the most cost-effective algorithm, utilizing all operational research methodologies. In general, the product is software that implements the best algorithm designed to deal with the problem of resource allocation for pandemics."
15,15,An Agent-Based Optimisation Approach for Vehicle Routing Problem with Unique Vehicle Location and Depot,['15 Apr 2022'],https://pureportal.coventry.ac.uk/en/publications/an-agent-based-optimisation-approach-for-vehicle-routing-problem-,"['Al Bazi, A.', 'Palade, V.']","['https://pureportal.coventry.ac.uk/en/persons/ammar-al-bazi', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade']","The Vehicle Routing Problem (VRP) is a well studied logistical problem along with its various variants such as VRP with customer Time-Window (VRPTW). However, all the previously studied variants assume that vehicles are mostly the same in terms of their capacity, location and home location (depot). This study uses the agent-based approach for solving VRPTW with vehicle's unique location and depot. This is to minimise the number of used vehicles as the main target. Other targets including total distance travelled, waiting time and time are also considered as criteria to evaluate the quality of the generated vehicle routes. This is achieved by proposing a Messaging Protocol-based Heuristics Optimisation (MPHO) model that balances between centrally-distributed agents' interactions and accommodates certain priority rules specifically developed for the problem. Furthermore, modifications to certain constraints checking techniques are introduced by implementing time Push Forward (PF) checking recursively tailored to the route's unique start/ending locations as well as calculating the reduced waiting time to find and check the limit of the total route duration. In order to justify the superiority of the proposed MPHO model, numerical tests have been conducted on benchmark problems including single and multiple depot instances as well as modified instances tailored to the problem. This is made possible by randomising vehicles' capacities and their unique locations and depots. Key results reveal that, in multiple depot instances, higher quality solutions compared with previous benchmark outcomes are obtained in terms of minimising the total number of vehicles along with fastest solution time (CPU) at the expense of total time and distance travelled."
16,16,An Effective Swarm Intelligence Optimization Algorithm for Flexible Ligand Docking,['1 Sep 2022'],https://pureportal.coventry.ac.uk/en/publications/an-effective-swarm-intelligence-optimization-algorithm-for-flexib,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"In general, flexible ligand docking is used for docking simulations under the premise that the position of the binding site is already known, and meanwhile, it can also be used without prior knowledge of the binding site. However, most of the optimization search algorithms used in popular docking software are far from being ideal in the first case, and they can hardly be directly utilized for the latter case due to the relatively large search area. In order to design an algorithm that can flexibly adapt to different sizes of the search area, we propose an effective swarm intelligence optimization algorithm in this paper, called diversity-controlled Lamarckian quantum particle swarm optimization (DCL-QPSO). The highlights of the algorithm are a diversity-controlled strategy and a modified local search method. Integrated with the docking environment of Autodock, the DCL-QPSO is compared with Autodock Vina, Glide and other two Autodock-based search algorithms for flexible ligand docking. Experimental results revealed that the proposed algorithm has a performance comparable to those of Autodock Vina and Glide for dockings within a certain area around the binding sites, and is a more effective solver than all the compared methods for dockings without prior knowledge of the binding sites."
17,17,An improved Gaussian distribution based quantum-behaved particle swarm optimization algorithm for engineering shape design problems,['4 May 2022'],https://pureportal.coventry.ac.uk/en/publications/an-improved-gaussian-distribution-based-quantum-behaved-particle-,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"In this article, an improved Gaussian distribution based quantum-behaved particle swarm optimization (IG-QPSO) algorithm is proposed to solve engineering shape design problems with multiple constraints. In this algorithm, the Gaussian distribution is employed to generate the sequence of random numbers in the QPSO algorithm. By decreasing the variance of the Gaussian distribution linearly, the algorithm is able not only to maintain its global search ability during the early search stages, but can also obtain gradually enhanced local search ability in the later search stages. Additionally, a weighted mean best position in the IG-QPSO is employed to achieve a good balance between local search and global search. The proposed algorithm and some other well-known PSO variants are tested on ten standard benchmark functions and six well-studied engineering shape design problems. Experimental results show that the IG-QPSO algorithm can optimize these problems effectively in terms of precision and robustness compared to its competitors."
18,18,An integrated framework for diagnosing process faults with incomplete features,['Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/an-integrated-framework-for-diagnosing-process-faults-with-incomp,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Handling missing values and large-dimensional features are crucial requirements for data-driven fault diagnosis systems. However, most intelligent data-driven diagnostic systems are not able to handle missing data. The presence of high-dimensional feature sets can also further complicate the process of fault diagnosis. This paper aims to devise a missing data imputation unit along with a dimensionality reduction unit in the pre-processing module of the diagnostic system. This paper proposes a novel pooling strategy for missing data imputation (PSMI). This strategy can simplify complex patterns of missingness and incrementally update the pool. The pre-processing module receives incomplete observations, PSMI estimates missing values, and, then, the dimensionality reduction unit transforms completed observations onto a lower-dimensional feature space. These transformed observations are then fed as inputs to the fault classification module for decision making and diagnosis. This diagnostic scheme makes use of various state-of-the-art missing data imputation, dimensionality reduction and classification algorithms. This enables a comprehensive comparison and allows to find the best techniques for the sake of diagnosing faults in the Tennessee Eastman process. The obtained results show the effectiveness of the proposed pooling strategy and indicate that principal component analysis imputation and heteroscedastic discriminant analysis approaches outperform other imputation and dimensionality reduction techniques in this diagnostic application."
19,19,An SMT solver for non-linear real arithmetic inside maple,['23 Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/an-smt-solver-for-non-linear-real-arithmetic-inside-maple-2,"['Sadeghimanesh, A.', 'England, M.']","['https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh', 'https://pureportal.coventry.ac.uk/en/persons/matthew-england']",We report on work-in-progress to create an SMT-solver inside Maple for non-linear real arithmetic (NRA). We give background information on the algorithm being implemented: cylindrical algebraic coverings as a theory solver in the lazy SMT paradigm. We then present some new work on the identification of minimal conflicting cores from the coverings.
20,20,An SMT solver for non-linear real arithmetic inside Maple,['6 Jul 2022'],https://pureportal.coventry.ac.uk/en/publications/an-smt-solver-for-non-linear-real-arithmetic-inside-maple,"['Sadeghimanesh, A.', 'England, M.']","['https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh', 'https://pureportal.coventry.ac.uk/en/persons/matthew-england']",We report on work-in-progress to create an SMT-solver inside Maple for non-linear real arithmetic (NRA). We give background information on the algorithm being implemented: cylindrical algebraic coverings as a theory solver in the lazy SMT paradigm. We then present some new work on the identification of minimal conflicting cores from the coverings.
21,21,Application of Amazon Web Services within teaching & learning at Coventry University Group,['6 Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/application-of-amazon-web-services-within-teaching-amp-learning-a,[],[],"Since September 2020, CU Group offers a Cloud Computing BSc(Hons) degree program developed with support from Amazon Web Services (AWS), leveraging their platform for teaching and learning and building upon their Cloud Competency Framework (CCF). This paper seeks to share how industry cloud technology stacks can be employed within authentic student learning. This has ensured a scenario led assessment for learning approach as an alternative to a simulated learning environment. CU Group is also an AWS Academy and Educate member, facilitating certification and platform access. This incorporates the experience of an industry leader in direct collaboration with HE to embed cloud skills within existing programs or develop specific curricula to target-fill skill gaps within the cloud landscape. Current students will graduate in August 2022, the first degree level graduates globally for HEIs working within the CCF."
22,22,Artificial Intelligence in Cars: How Close Yet Far Are We from Fully Autonomous Vehicles?,['3 May 2022'],https://pureportal.coventry.ac.uk/en/publications/artificial-intelligence-in-cars-how-close-yet-far-are-we-from-ful,"['Palade, V.', 'Deo, A.']","['https://pureportal.coventry.ac.uk/en/persons/vasile-palade', 'https://pureportal.coventry.ac.uk/en/persons/ankur-deo']","In the last several years, strides in Artificial Intelligence (AI) have allowed for substantial developments in autonomous driving. As a result, moving to Level-4 and Level-5 autonomy in the near future is starting to look like a certain possibility. Use of AI in vehicles and, in particular, cutting-edge computer vision, signal processing and control techniques have contributed significantly to the high-tech nature of state-of-the-art Advanced Driver Assistance Systems (ADAS) available in cars today. In modern automobiles, AI not only contributes substantially to systems such as ADAS, but also in the areas of vehicles’ connectivity, automotive cybersecurity, and smart road infrastructure development. The next generation driverless vehicles will be completely reliant on these technologies to transport passengers and goods from one place to other, whilst eliminating human intervention entirely. However, despite the many advancements in AI for connected and autonomous vehicles done so far, there are several issues that are responsible of holding back the wide-scale deployment of AI based autonomous vehicles on roads, which are discussed in this editorial paper. Until and unless these critical issues are addressed, it would be difficult to indicate an accurate future moment in time when autonomous vehicles will become a reality globally."
23,23,Assessing Risks in Dairy Supply Chain Systems: A System Dynamics Approach,['4 Aug 2022'],https://pureportal.coventry.ac.uk/en/publications/assessing-risks-in-dairy-supply-chain-systems-a-system-dynamics-a,"['Azizsafaei, M.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/maryam-azizsafaei', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","Due to the dynamic nature of the food supply chain system, food supply management could suffer because of, and be interrupted by, unforeseen events. Considering the perishable nature of fresh food products and their short life cycle, fresh food companies feel immense pressure to adopt an efficient and proactive risk management system. The risk management aspects within the food supply chains have been addressed in several studies. However, only a few studies focus on the complex interactions between the various types of risks impacting food supply chain functionality and dynamic feedback effects, which can generate a reliable risk management system. This paper strives to contribute to this evident research gap by adopting a system dynamics modelling approach to generate a systemic risk management model. The system dynamics model serves as the basis for the simulation of risk index values and can be explored in future work to further analyse the dynamic risk’s effect on the food supply chain system’s behaviour. According to a literature review of published research from 2017 to 2021, nine different risks across the food supply chain were identified as a subsection of the major risk categories: macro-level and operational risks. Following this stage, two of the risk groups identified first were integrated with a developed system dynamics model to conduct this research and to evaluate the interaction between the risks and the functionality of the three main dairy supply chain processes: production, logistics, and retailing. The key findings drawn from this paper can be beneficial for enhancing managerial discernment regarding the critical role of system dynamics models for analysing various types of risks across the food supply chain process and improving its efficiency."
24,24,Bispectrum-based Cross-frequency Functional Connectivity: Classification of Alzheimer's disease,['8 Sep 2022'],https://pureportal.coventry.ac.uk/en/publications/bispectrum-based-cross-frequency-functional-connectivity-classifi,"['Klepl, D.', 'He, F.']","['https://pureportal.coventry.ac.uk/en/persons/dominik-klepl', 'https://pureportal.coventry.ac.uk/en/persons/fei-he']","Alzheimer’s disease (AD) is a neurodegenerative disease known to affect brain functional connectivity (FC). Linear FC measures have been applied to study the differences in AD by splitting neurophysiological signals such as electroencephalography (EEG) recordings into discrete frequencypbands and analysing them in isolation. We address this limitation by quantifying cross-frequency FC in addition to the traditional within-band approach. Cross-bispectrum, a higher-order spectral analysis, is used to measure the nonlinear FC and is compared with the cross-spectrum, which only measures the linear FC within bands. Each frequency coupling is then used to construct an FC network, which is in turn vectorised and used to train a classifier. We show that fusing features from networks improves classification accuracy. Although both within-frequency and cross-frequency networks can be used to predict AD with high accuracy, our results show that bispectrum-based FC outperforms cross-spectrum suggesting an important role of cross-frequency FC."
25,25,Brain Tumor Classification Using a Combination of Variational Autoencoders and Generative Adversarial Networks,['21 Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/brain-tumor-classification-using-a-combination-of-variational-aut,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Brain tumors are a pernicious cancer with one of the lowest five-year survival rates. Neurologists often use magnetic resonance imaging (MRI) to diagnose the type of brain tumor. Automated computer-assisted tools can help them speed up the diagnosis process and reduce the burden on the health care systems. Recent advances in deep learning for medical imaging have shown remarkable results, especially in the automatic and instant diagnosis of various cancers. However, we need a large amount of data (images) to train the deep learning models in order to obtain good results. Large public datasets are rare in medicine. This paper proposes a framework based on unsupervised deep generative neural networks to solve this limitation. We combine two generative models in the proposed framework: Variational autoencoders (VAEs) and generative adversarial networks (GANs). We swap the encoder–decoder network after initially training it on the training set of available MR images. The output of this swapped network is a noise vector that has information of the image manifold, and the cascaded generative adversarial network samples the input from this informative noise vector instead of random Gaussian noise. The proposed method helps the GAN to avoid mode collapse and generate realistic-looking brain tumor magnetic resonance images. These artificially generated images could solve the limitation of small medical datasets up to a reasonable extent and help the deep learning models perform acceptably. We used the ResNet50 as a classifier, and the artificially generated brain tumor images are used to augment the real and available images during the classifier training. We compared the classification results with several existing studies and state-of-the-art machine learning models. Our proposed methodology noticeably achieved better results. By using brain tumor images generated artificially by our proposed method, the classification average accuracy improved from 72.63% to 96.25%. For the most severe class of brain tumor, glioma, we achieved 0.769, 0.837, 0.833, and 0.80 values for recall, specificity, precision, and F1-score, respectively. The proposed generative model framework could be used to generate medical images in any domain, including PET (positron emission tomography) and MRI scans of various parts of the body, and the results show that it could be a useful clinical tool for medical experts."
26,26,Cell site analysis; Changes to networks with time,['May 2022'],https://pureportal.coventry.ac.uk/en/publications/cell-site-analysis-changes-to-networks-with-time,"['Tart, M. S.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-stephen-tart'],"Cell service areas may change over time as sites or cells are adjusted, decommissioned or introduced, and there may have been changes between the time of calls and the analysis undertaken. The manner in which survey data is used as part of an analysis is of particular relevance as the data gathered may not reflect the state of the network at the time of calls and thus potentially mislead. Overlaying “historic” data (potentially generated before the calls) with “targeted” surveys (usually generated after the calls) may enable an assessment of possible network changes, or whether additional cells may also have served at a given location at a previous time. This paper outlines a case in which there was a significant time gap between the analysis of call data records and the date on which they were generated."
27,27,Characterising Alzheimers Disease with EEG-based Energy Landscape Analysis,['1 Mar 2022'],https://pureportal.coventry.ac.uk/en/publications/characterising-alzheimers-disease-with-eeg-based-energy-landscape-2,"['Klepl, D.', 'He, F.']","['https://pureportal.coventry.ac.uk/en/persons/dominik-klepl', 'https://pureportal.coventry.ac.uk/en/persons/fei-he']","Alzheimer's disease (AD) is one of the most common neurodegenerative diseases, with around 50 million patients worldwide. Accessible and non-invasive methods of diagnosing and characterising AD are therefore urgently required. Electroencephalography (EEG) fulfils these criteria and is often used when studying AD. Several features derived from EEG were shown to predict AD with high accuracy, e.g. signal complexity and synchronisation. However, the dynamics of how the brain transitions between stable states have not been properly studied in the case of AD and EEG. Energy landscape analysis is a method that can be used to quantify these dynamics. This work presents the first application of this method to both AD and EEG. Energy landscape assigns energy value to each possible state, i.e. pattern of activations across brain regions. The energy is inversely proportional to the probability of occurrence. By studying the features of energy landscapes of 20 AD patients and 20 age-matched healthy counterparts (HC), significant differences are found. The dynamics of AD patients' EEG are shown to be more constrained - with more local minima, less variation in basin size, and smaller basins. We show that energy landscapes can predict AD with high accuracy, performing significantly better than baseline models. Moreover, these findings are replicated in a separate dataset including 9 AD and 10 HC above 70 years old."
28,28,"Clogs and Shawls: Mormons, Moorlands, and the Search for Zion",['31 Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/clogs-and-shawls-mormons-moorlands-and-the-search-for-zion,"['Halford, A.']",['https://pureportal.coventry.ac.uk/en/persons/alison-halford'],"Alzheimer's disease (AD) is one of the most common neurodegenerative diseases, with around 50 million patients worldwide. Accessible and non-invasive methods of diagnosing and characterising AD are therefore urgently required. Electroencephalography (EEG) fulfils these criteria and is often used when studying AD. Several features derived from EEG were shown to predict AD with high accuracy, e.g. signal complexity and synchronisation. However, the dynamics of how the brain transitions between stable states have not been properly studied in the case of AD and EEG. Energy landscape analysis is a method that can be used to quantify these dynamics. This work presents the first application of this method to both AD and EEG. Energy landscape assigns energy value to each possible state, i.e. pattern of activations across brain regions. The energy is inversely proportional to the probability of occurrence. By studying the features of energy landscapes of 20 AD patients and 20 age-matched healthy counterparts (HC), significant differences are found. The dynamics of AD patients' EEG are shown to be more constrained - with more local minima, less variation in basin size, and smaller basins. We show that energy landscapes can predict AD with high accuracy, performing significantly better than baseline models. Moreover, these findings are replicated in a separate dataset including 9 AD and 10 HC above 70 years old."
29,29,Comparative Graph-based Summarization of Scientific Papers Guided by Comparative Citations,['Oct 2022'],https://pureportal.coventry.ac.uk/en/publications/comparative-graph-based-summarization-of-scientific-papers-guided,"['Jiang, X.']",['https://pureportal.coventry.ac.uk/en/persons/xiaorui-jiang'],"With the rapid growth of scientific papers, understanding the changes and trends in a research area is rather time-consuming. The first challenge is to find related and comparable articlespfor the research. Comparative citations compare co-cited papers in a citation sentence and can serve as good guidance for researchers to track a research area. We thus go throughpcomparative citations to find comparable objects and build a comparative scientific summarization corpus (CSSC). And then, we propose the comparative graph-based summarizationp(CGSUM) method to create comparative summaries using citations as guidance. The comparative graph is constructed using sentences as nodes and three different relationships of sentencespas edges. The relationship that sentences occur in the same paper is used to calculate the salience of sentences, the relationship that sentences occur in two different papers is used to calculate the difference between sentences, and the relationship that sentences are related to citations is used to calculate the commonality ofpsentences. Experiments show that CGSUM outperformspcomparative baselines on CSSC and performs well on DUC2006 and DUC2007."
30,30,Comparing the Behaviour of Two Topic-Modelling Algorithms in COVID-19 Vaccination Tweets,['Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/comparing-the-behaviour-of-two-topic-modelling-algorithms-in-covi,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Coronavirus is a newly developed infectious disease that has triggered a pandemic due to its ease of transmission as of early 2020. Several groups from various countries have been working on a vaccine to prevent and avoid the spread of the virus in this outbreak. In this article, the main objective is to compare LDA against LSA to gain a better understanding of the Tweets and which Topic Modelling technique fits best for this task, additionally if the feedback of the Tweets were positive or negative sentiment. It was concluded that LDA was a better-unsupervised technique for categorizing the raw text in 12 topics."
31,31,Contextualised Segment-Wise Citation Function Classification,['2022'],https://pureportal.coventry.ac.uk/en/publications/contextualised-segment-wise-citation-function-classification,"['Jiang, X.']",['https://pureportal.coventry.ac.uk/en/persons/xiaorui-jiang'],"Much effort has been made in the past decades to citation function classification. Noteworthy issues exist. Annotation difficulty made existing datasets quite limited in size, especially for minority classes, and quite limited in the representativeness of a scientific domain. Different annotation schemes made existing studies not easily mappable and comparable. Concerning algorithmic classification, state-of-the-art deep learning-based methods are flawed by generating a feature vector for the whole citation context (or sentence) and failing to exploit the full realm of citation modelling options. Responding to these issues, this paper studied contextualised citation function classification. Specifically, a large new citation context dataset was created by merging and re-annotating six datasets about computational linguistics. A variety of strong SciBERT-based citation function classification models were proposed. In addition to achieving the new state of the art of citation function classification, this study focused on deeper performance analysis of to answer several research questions about the effective ways of performing citation function classification, more specifically, the necessity of modelling in-text citations in context and doing citation function classification at citation (segment) level. A particular emphasis was placed on in-depth per-class performance analysis for the purpose of understanding whether citation function classification is robust enough for scientometric applications, what implications can be derived for the applicability of citation function classification to different scientometric analysis tasks, and what further efforts are required to meet such analytic needs. "
32,32,Convolution neural networks for pothole detection of critical road infrastructure,['Apr 2022'],https://pureportal.coventry.ac.uk/en/publications/convolution-neural-networks-for-pothole-detection-of-critical-roa,"['Pandey, A. K.', 'Palade, V.']","['https://pureportal.coventry.ac.uk/en/persons/anup-pandey-2', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade']","A well developed and maintained highway infrastructure is essential for the economic and social prosperity of modern societies. Highway maintenance poses significant challenges pertaining to the ever-increasing ongoing traffic, insufficient budget allocations and lack of resources. Road potholes detection and timely repair is a major contributing factor to sustaining a safe and resilient critical road infrastructure. Current pothole detection methods require laborious manual inspection of roads and lack in terms of accuracy and inference speed. This paper proposes a novel application of Convolutional Neural Networks on accelerometer data for pothole detection. Data is collected using an iOS smartphone installed on the dashboard of a car, running a dedicated application. The experimental results show that the proposed CNN approach has a significant advantage over the existing solutions, with respect to accuracy and computational complexity in pothole detection."
33,33,Data-driven dynamical modelling of a pathogen-infected plant gene regulatory network: A comparative analysis,['Sep 2022'],https://pureportal.coventry.ac.uk/en/publications/data-driven-dynamical-modelling-of-a-pathogen-infected-plant-gene,"['He, F.']",['https://pureportal.coventry.ac.uk/en/persons/fei-he'],"Recent advances in synthetic biology have enabled the design of genetic feedback control circuits that could be implemented to build resilient plants against pathogen attacks. To facilitate the proper design of these genetic feedback control circuits, an accurate model that is able to capture the vital dynamical behaviour of the pathogen-infected plant is required. In this study, using a data-driven modelling approach, we develop and compare four dynamical models (i.e. linear, Michaelis-Menten with Hill coefficient (Hill Function), standard S-System and extended S-System) of a pathogen-infected plant gene regulatory network (GRN). These models are then assessed across several criteria, i.e. ease of identifying the type of gene regulation, the predictive capability, Akaike Information Criterion (AIC) and the robustness to parameter uncertainty to determine its viability of balancing between biological complexity and accuracy when modelling the pathogen-infected plant GRN. Using our defined ranking score, we obtain the following insights to the modelling of GRN. Our analyses show that despite commonly used and provide biological relevance, the Hill Function model ranks the lowest while the extended S-System model ranks highest in the overall comparison. Interestingly, the performance of the linear model is more consistent throughout the comparison, making it the preferred model for this pathogen-infected plant GRN when considering data-driven modelling approach."
34,34,Detection of sleep apnea using Machine learning algorithms based on ECG Signals: A comprehensive systematic review,['Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/detection-of-sleep-apnea-using-machine-learning-algorithms-based-,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Sleep apnea (SA) is a common sleep disorder that is not easy to detect. Recent studies have highlighted ECG analysis as an effective method of diagnosing SA. Because the changes caused by SA on the ECG are imperceptible, the need for new methods in diagnosing this disease is required more than ever. Machine Learning (ML) is recognized as one of the most successful methods of computer aided diagnosis. ML uses new methods to diagnose diseases using past clinical results. The purpose of this study is to evaluate studies using ML algorithms based on ECG characteristics to assess people suffering from SA. In this study, systematically-reviewed articles written in English before October 2020 and indexed in PubMed, Scopus, Web of Science, and IEEE databases were searched with no lower time limit. From these articles, 48 were selected for further review. The selected articles adopteddifferent ML methods for classification. All of these studies were binary where SA was detected from the normal state based on a full ECG stripe (per record), or based on one-minute segments (per segment). Our analysis show that the most common features used in the studies were frequency, time series, and statistical features. Support-Vector Machine (SVM) and deep learning-based neural network (i.e. CNN, DNN) performed best in full record data detection. The highest accuracy, sensitivity, and specificity reported among the selected studies were 100%, which was obtained by an SVM. In another study, the classification was conducted based on ECG segments, and accordingly, the highest classification accuracy was observed in the residual neural network algorithm (RNN). The accuracy, sensitivity, and specificity of this algorithm were reported to be 99%. In general, it can be stated that ML techniques based on ECG characteristics have a high capability in diagnosing SA. These techniques can increase the diagnosis of patients with SA or the detection of SA episodes on ECG record, and can potentially prevent complications of the disease at later stages."
35,35,Differential radial basis function network for sequence modelling,['1 Mar 2022'],https://pureportal.coventry.ac.uk/en/publications/differential-radial-basis-function-network-for-sequence-modelling,"['Brusey, J.', 'Gaura, E.']","['https://pureportal.coventry.ac.uk/en/persons/james-brusey', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura']","We propose a differential radial basis function (RBF) network termed RBF-DiffNet—whose hidden layer blocks are partial differential equations (PDEs) linear in terms of the RBF—to make the baseline RBF network robust to noise in sequential data. Assuming that the sequential data derives from the discretisation of the solution to an underlying PDE, the differential RBF network learns constant linear coefficients of the PDE, consequently regularising the RBF network by following modified backward-Euler updates. We experimentally validate the differential RBF network on the logistic map chaotic timeseries as well as on 30 real-world timeseries provided by Walmart in the M5 forecasting competition. The proposed model is compared with the normalised and unnormalised RBF networks, ARIMA, and ensembles of multilayer perceptrons (MLPs) and recurrent networks with long short-term memory (LSTM) blocks. From the experimental results, RBF-DiffNet consistently shows a marked reduction in the prediction error over the baseline RBF network (e.g., 41% reduction in the root mean squared scaled error on the M5 dataset, and 53% reduction in the mean absolute error on the logistic map); RBF-DiffNet also shows a comparable performance to the LSTM ensemble but requires 99% less computational time. Our proposed network consequently enables more accurate predictions—in the presence of observational noise—in sequence modelling tasks such as timeseries forecasting that leverage the model interpretability, fast training, and function approximation properties of the RBF network."
36,36,Edge-Enhancement DenseNet for X-ray Fluoroscopy Image Denoising in Cardiac Electrophysiology Procedures,['Feb 2022'],https://pureportal.coventry.ac.uk/en/publications/edge-enhancement-densenet-for-x-ray-fluoroscopy-image-denoising-i,"['Ma, Y.']",['https://pureportal.coventry.ac.uk/en/persons/yingliang-ma'],"Purpose: Reducing X-ray dose increases safety in cardiac electrophysiology procedures but also increases image noise and artifacts which may affect the discernibility of devices and anatomical cues. Previous denoising methods based on convolutional neural networks (CNNs) have shown improvements in the quality of low-dose X-ray fluoroscopy images but may compromise clinically important details required by cardiologists. Methods: In order to obtain denoised X-ray fluoroscopy images whilst preserving details, we propose a novel deep-learning-based denoising framework, namely edge-enhancement densenet (EEDN), in which an attention-awareness edge-enhancement module is designed to increase edge sharpness. In this framework, a CNN-based denoiser is first used to generate an initial denoising result. Contours representing edge information are then extracted using an attention block and a group of interacted ultra-dense blocks for edge feature representation. Finally, the initial denoising result and enhanced edges are combined to generate the final X-ray image. The proposed denoising framework was tested on a total of 3262 clinical images taken from 100 low-dose X-ray sequences acquired from 20 patients. The performance was assessed by pairwise voting from five cardiologists as well as quantitative indicators. Furthermore, we evaluated our technique's effect on catheter detection using 416 images containing coronary sinus catheters in order to examine its influence as a pre-processing tool. Results: The average signal-to-noise ratio of X-ray images denoised with EEDN was 24.5, which was 2.2 times higher than that of the original images. The accuracy of catheter detection from EEDN denoised sequences showed no significant difference compared with their original counterparts. Moreover, EEDN received the highest average votes in our clinician assessment when compared to our existing technique and the original images. Conclusion: The proposed deep learning-based framework shows promising capability for denoising interventional X-ray fluoroscopy images. The results from the catheter detection show that the network does not affect the results of such an algorithm when used as a pre-processing step. The extensive qualitative and quantitative evaluations suggest that the network may be of benefit to reduce radiation dose when applied in real time in the catheter laboratory."
37,37,EEG-based Graph Neural Network Classification of Alzheimer's Disease: An Empirical Evaluation of Functional Connectivity Methods,['6 Sep 2022'],https://pureportal.coventry.ac.uk/en/publications/eeg-based-graph-neural-network-classification-of-alzheimers-disea,"['Klepl, D.', 'He, F.']","['https://pureportal.coventry.ac.uk/en/persons/dominik-klepl', 'https://pureportal.coventry.ac.uk/en/persons/fei-he']","Alzheimer's disease (AD) is the leading form of dementia worldwide. AD disrupts neuronal pathways and thus is commonly viewed as a network disorder. Many studies demonstrate the power of functional connectivity (FC) graph-based biomarkers for automated diagnosis of AD using electroencephalography (EEG). However, various FC measures are commonly utilised, as each aims to quantify a unique aspect of brain coupling. Graph neural networks (GNN) provide a powerful framework for learning on graphs. While a growing number of studies use GNN to classify EEG brain graphs, it is unclear which method should be utilised to estimate the brain graph. We use eight FC measures to estimate FC brain graphs from sensor-level EEG signals. GNN models are trained in order to compare the performance of the selected FC measures. Additionally, three baseline models based on literature are trained for comparison. We show that GNN models perform significantly better than the other baseline models. Moreover, using FC measures to estimate brain graphs improves the performance of GNN compared to models trained using a fixed graph based on the spatial distance between the EEG sensors. However, no FC measure performs consistently better than the other measures. The best GNN reaches 0.984 area under sensitivity-specificity curve (AUC) and 92% accuracy, whereas the best baseline model, a convolutional neural network, has 0.924 AUC and 84.7% accuracy."
38,38,Efficacy of COVID-19 vaccines by race and ethnicity,['5 May 2022'],https://pureportal.coventry.ac.uk/en/publications/efficacy-of-covid-19-vaccines-by-race-and-ethnicity,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Objectives: Vaccine uptake amongst ethnic minority populations has been persistently lower, which may be because of socio-economic factors such as health literacy and health insurance status. This review aimed to assess to what extent COVID-19 clinical trials have considered the impact of race and ethnicity on COVID-19 vaccine safety and efficacy. Study design: This was a systematic review. Methods: Data regarding ethnicity in COVID-19 vaccine clinical trials were systematically reviewed according to Preferred Reporting Items for Systematic Reviews and Meta-Analysis guidelines in this systematic review, which ran from inception until June 2021. Three international databases, PubMed, Scopus and Web of Science, were used to conduct systematic article searches. Only two studies reported vaccine efficacy among ethnic minority groups. Results: The efficacy of the mRNA-1273 vaccine was confirmed to be 95% in Caucasians and 97.5% in ‘people of colour’ in a study by Baden et al. In another study by Polack et al., BNT162b2 mRNA vaccine efficacy was reported to be 95.2% in Caucasians, 100% in Afro-Caribbean or African Americans, 94.2% in Hispanic or Latinx and 95.4% in non-Hispanic, non-Latinx people. Conclusions: Given the highly differing effect of COVID-19 on the Afro-Caribbean, Hispanic and South Asian populations, it is imperative for COVID-19 vaccine clinical trials to thoroughly assess the safety and efficacy of vaccines in different ethnicities and, if necessary, develop ethnicity-specific protocols, which can minimise the disproportionate effect of COVID-19 on ethnic minority populations."
39,39,Examining Type 1 Diabetes Mathematical Models Using Experimental Data,['10 Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/examining-type-1-diabetes-mathematical-models-using-experimental-,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Type 1 diabetes requires treatment with insulin injections and monitoring glucose levels in affected individuals. We explored the utility of two mathematical models in predicting glucose concentration levels in type 1 diabetic mice and determined disease pathways. We adapted two mathematical models, one with β-cells and the other with no β-cell component to determine their ca-pability in predicting glucose concentration and determine type 1 diabetes pathways using published glucose concentration data for four groups of experimental mice. The groups of mice were numbered Mice Group 1–4, depending on the diabetes severity of each group, with severity increasing from group 1–4. A Markov Chain Monte Carlo method based on a Bayesian framework was used to fit the model to determine the best model structure. Akaike information criteria (AIC) and Bayesian information criteria (BIC) approaches were used to assess the best model structure for type 1 diabetes. In fitting the model with no β-cells to glucose level data, we varied insulin absorption rate and insulin clearance rate. However, the model with β-cells required more parameters to match the data and we fitted the β-cell glucose tolerance factor, whole body insulin clearance rate, glucose production rate, and glucose clearance rate. Fitting the models to the blood glucose concentration level gave the least difference in AIC of 1.2, and a difference in BIC of 0.12 for Mice Group 4. The estimated AIC and BIC values were highest for Mice Group 1 than all other mice groups. The models gave substantial differences in AIC and BIC values for Mice Groups 1–3 ranging from 2.10 to 4.05. Our results suggest that the model without β-cells provides a more suitable structure for modelling type 1 diabetes and predicting blood glucose concentration for hypoglycaemic episodes."
40,40,Exploiting Domain Structures in Heuristic Algorithms for the Set Covering Problem: A Literature Review,['1 Apr 2022'],https://pureportal.coventry.ac.uk/en/publications/exploiting-domain-structures-in-heuristic-algorithms-for-the-set-,"['Babatunde, A.']",['https://pureportal.coventry.ac.uk/en/persons/abiola-babatunde'],"This review aims at understanding the set covering problem (SCP) as an NP-hard problem, the variants of SCP, the methods that have been proposed to solve the problem, and gaps in the existing solutions that have been provided which need further research. A polynomial time algorithm to give an optimal solution to the Set Covering Problem is only possible if P=NP and so we do not expect to find such an algorithm. Instead, various heuristic algorithms have been used in an attempt to find an optimal solution for the problem. Exploring these types of algorithms provides solutions that are usable, or near optimal, but not exact which reduces the computational cost for the set covering problem. A comparison of metaheuristic algorithms and optimization of these algorithms is explored in this review"
41,41,Exploring dynamical properties of a Type 1 diabetes model using sensitivity approaches,['Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/exploring-dynamical-properties-of-a-type-1-diabetes-model-using-s,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"The high global prevalence of diabetes, and the extortionate costs imposed on healthcare providers necessitate further research to understand different perspectives of the disease. In this paper, a mathematical model for Type 1 diabetes glucose homeostasis system was developed to better understand disease pathways. Type 1 diabetes pathological state is shown to be globally asymptomatically stable when the model threshold , and exchanges stability with the managed diabetes equilibrium state i.e. globally asymptotically stable when . Sensitivity analysis was conducted using partial rank correlation coefficient (PRCC) and Sobol method to determine influential model parameters. Sensitivity analysis was performed at different significant time points relevant to diabetes dynamics. Our sensitivity analysis was focused on the model parameters for glucose homeostasis system, at 3 to 4 hour time interval, when the system returns to homeostasis after food uptake. PRCC and Sobol method showed that insulin clearance and absorption rates were influential parameters in determining the model response variables at all time points at which sensitivity analysis was performed. PRCC method also showed the model subcutaneous bolus injection term to be important, thus identified all parameters in  as influential in determining diabetes model dynamics. Sobol method complemented the sensitivity analysis by identifying relationships between parameters. Sensitivity analysis methods concurred in identifying some of the influential parameters and demonstrated that parameters which are influential remain so at every time point. The concurrence of both PRCC and Sobol methods in identifying influential parameters (in ) and their dynamic relationships highlight the importance of statistical and mathematical analytic approaches in understanding the processes modelled by the parameters in the glucose homeostasis system."
42,42,"Fast, detailed, accurate simulation of a thermal car-cabin using machine-learning",['10 Mar 2022'],https://pureportal.coventry.ac.uk/en/publications/fast-detailed-accurate-simulation-of-a-thermal-car-cabin-using-ma,"['Jess, B. J.', 'Brusey, J.', 'Gaura, E.']","['https://pureportal.coventry.ac.uk/en/persons/brandi-jo-jess', 'https://pureportal.coventry.ac.uk/en/persons/james-brusey', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura']","Car-cabin thermal systems, including heated seats, air-conditioning, and radiant panels, use a large proportion of the energy budget of electric vehicles and thus reduce their effective range. Optimising these systems and their controllers might be possible with computationally efficient simulation. Unfortunately, state-of-the-art simulators are either too slow or provide little resolution of the cabin's thermal environment. In this work, we propose a novel approach to developing a fast simulation by machine learning (ML) from measurements within the car cabin over a number of trials within a climatic wind tunnel. A range of ML approaches are tried and compared. The best-performing ML approach is compared to more traditional 1D simulation in terms of accuracy and speed. The resulting simulation, based on Multivariate Linear Regression, is fast (5 microseconds per simulation second), and yields good accuracy (NRMSE 1.8%), which exceeds the performance of the traditional 1D simulator. Furthermore, the simulation is able to differentially simulate the thermal environment of the footwell versus the head and the driver position versus the front passenger seat, but unlike a traditional 1D model cannot support changes to the physical structure.pThis fast method for obtaining computationally efficient simulators of car cabins will accelerate adoption of techniques such as Deep Reinforcement Learning for climate control."
43,43,Feedback and Engagement on an Introductory Programming Module,['6 Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/feedback-and-engagement-on-an-introductory-programming-module,"['Grawemeyer, B.', 'Halloran, J.', 'England, M.']","['https://pureportal.coventry.ac.uk/en/persons/beate-grawemeyer', 'https://pureportal.coventry.ac.uk/en/persons/john-halloran', 'https://pureportal.coventry.ac.uk/en/persons/matthew-england']","We ran a study on engagement and achievement for a first year undergraduate programming module which  used an online learning environment containing tasks which generate automated feedback.  Students could also access human feedback from traditional labs. We gathered quantitative data on engagement and achievement which allowed us to split the cohort into 6 groups.  We then ran interviews with students after the end of the module to produce qualitative data on perceptions of what feedback is, how useful it is, the uses made of it, and how it bears on engagement. A general finding was that human and automated feedback are different but complementary. However there are different feedback needs by group. Our findings imply: (1) that a blended human-automated feedback approach improves engagement; and (2) that this approach needs to be differentiated according to type of student. We give implications for the design of feedback for programming modules. "
44,44,Framework for Generating Integrable Expressions,['2 Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/framework-for-generating-integrable-expressions,"['Barket, R.']",['https://pureportal.coventry.ac.uk/en/persons/rashid-barket'],"Applications of machine learning are becoming more prominent in the field of computer algebra. Examples of such applications include selecting S-pairs in Buchberger’s algorithm or solving integrals and differential equations directly. With many of these applications, data must be generated to train a model. Methods such as generating binary trees representing mathematical expressions or created randomly in a recursive manner from a set of available function symbols, variables and constants have been discussed. However, these generated expressions do not represent a realistic dataset that draws from the typical Maple user’s experience.pI propose a framework for generating valid mathematical expressions. More precisely, the focus will be on integrable expressions. The difference from other methods lies in the fact that the data generation method will be based on a test suite of data generated from Maple users. Thus, the new synthetic data will have properties similar to integrable expressions that Maple users would typically try. This data generation method will be used to train machine learning models that make efficient choices algorithm selection problems."
45,45,From Theory to Practice: A review of co-design methods for humanitarian energy ecosystems,['Jul 2022'],https://pureportal.coventry.ac.uk/en/publications/from-theory-to-practice-a-review-of-co-design-methods-for-humanit,"['Halford, A.', 'Gaura, E.']","['https://pureportal.coventry.ac.uk/en/persons/alison-halford', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura']","Our planet is currently in the midst of a global humanitarian crisis. Yet, there is a widening gap between over 80 million displaced people and the political will to meet their needs. Improving energy access in the displaced setting to build capacity and resilience requires meaningful integration of the needs of communities throughout the design, delivery and evaluation process within the socio-technical energy system. This paper aims to explore the ways in which co-design is conceptualised and applied, from an interdisciplinary perspective, within the socio-technical framing. We do this by first conducting a rapid review of relevant co-design literature to understand theories, typologies and identify methods of best co-design practice in the Humanitarian Energy sector. Second, we present the Humanitarian Engineering and Energy for Displacement project as a co-design case study for Humanitarian Energy using Technology Implementation Model for Energy (TIME) as a framework for analysis. Our rapid review resulted in the typology of the Spectrum of Co-Design, a mapping of differing conceptualisations of co-design showing their positioning and interactions. Our results show that by exploring if and how conceptual frameworks, such as TIME, adds value to practitioner orientated humanitarian programming this can make a significant contribution to future proofing energy systems that seek to deliver inclusive, sustainable and just transitions. We highlight specific learnings from HEED around the disconnection between perceptions of key stakeholder roles, misunderstandings of energy access and use, and building trusting partnerships through the creation of meaningful rectification pathways."
46,46,Gaussian Process Emulation of Spatio-temporal Outputs of a 2D Inland Flood Model,['15 Oct 2022'],https://pureportal.coventry.ac.uk/en/publications/gaussian-process-emulation-of-spatio-temporal-outputs-of-a-2d-inl,"['Donnelly, J.', 'Chatrabgoun, O.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/james-donnelly', 'https://pureportal.coventry.ac.uk/en/persons/omid-chatrabgoun', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","The computational limitations of complex numerical models have led to adoption of statistical emulators across a variety of problems in science and engineering disciplines to circumvent the high computational costs associated with numerical simulations. In flood modelling, many hydraulic and hydrodynamic numerical models, especially when operating at high spatiotemporal resolutions, have prohibitively high computational costs for tasks requiring the instantaneous generation of very large numbers of simulation results. This study examines the appropriateness and robustness of Gaussian Process (GP) models to emulate the results from a hydraulic inundation model. The developed GPs produce real-time predictions based on the simulation output from LISFLOOD-FP numerical model. An efficient dimensionality reduction scheme is developed to tackle the high dimensionality of the output space and is combined with the GPs to investigate the predictive performance of the proposed emulator for estimation of the inundation depth. The developed GP-based framework is capable of robust and straightforward quantification of the uncertainty associated with the predictions, without requiring additional model evaluations and simulations. Further, this study explores the computational advantages of using a GP-based emulator over alternative methodologies such as neural networks, by undertaking a comparative analysis. For the case study data presented in this paper, the GP model was found to accurately reproduce water depths and inundation extent by classification and produce computational speedups of approximately 10,000 times compared with the original simulator, and 80 times for a neural network-based emulator."
47,47,Impact Evaluation of Solar Photovoltaic Electrification: Indigenous Community Case Study in Brazilian Amazon,['14 Apr 2022'],https://pureportal.coventry.ac.uk/en/publications/impact-evaluation-of-solar-photovoltaic-electrification-indigenou,[],[],"Despite efforts to promote universal access to electrification, the Brazilian Amazon basin has around 82,000 families without electricity. The basin is huge, with few roads, many rivers, and conservative areas, which is an enormous challenge in terms of logistics and electrification costs. This paper describes a case study at the Nova Esperança community site in the Cuieiras River, Brazil. The community received stand-alone solar photovoltaic systems in 2018 and 2019. The process started with a survey and finished with an interview with each dweller that received a 975 W and 2-day autonomy photovoltaic system. A monitoring system was developed and deployed, and weather monitoring was performed to evaluate the impact of high temperatures on the equipment. The community does not have cell phone coverage and it is far from the main cities. We claim that the model created and adopted in the case study has interesting outcomes, even considering a small budget. Some houses, after 1 year of deployment, had their electrical demand rise by 300%, and 50% improved their income. We estimate the number of greenhouse gases annually avoided after electrification, replacing the consumed fossil fuel. The project also estimates the expenditure on energy sources that residents used due to the lack of electricity, which they stopped doing after electrification. The avoided expense can cover maintenance costs over the years. The goals of the SDG that were covered by the project are good health and well-being, accessible and clean energy, sustainable cities and communities, combating climate change, and partnerships for the goals."
48,48,Incorporating forecasting and peer-to-peer negotiation frameworks into a distributed model predictive control approach for meshed electric networks,['1 Sep 2022'],https://pureportal.coventry.ac.uk/en/publications/incorporating-forecasting-and-peer-to-peer-negotiation-frameworks,"['Gaura, E.']",['https://pureportal.coventry.ac.uk/en/persons/elena-gaura'],"The continuous integration of renewable energy sources into power networks is causing a paradigm shift in energy generation and distribution with regard to trading and control. The intermittent nature of renewable sources affects the pricing of energy sold or purchased. The networks are subject to operational constraints, voltage limits at each node, rated capacities for the power electronic devices, and current bounds for distribution lines. These economic and technical constraints, coupled with intermittent renewable injection, may pose a threat to system stability and performance. In this article, we propose a novel holistic approach to energy trading composed of a distributed predictive control framework to handle physical interactions, i.e., voltage constraints and power dispatch, together with a negotiation framework to determine pricing policies for energy transactions. We study the effect of forecasting generation and consumption on the overall network's performance and market behaviors. We provide a rigorous convergence analysis for both the negotiation framework and the distributed control. Finally, we assess the impact of forecasting in the proposed system with the aid of testing scenarios."
49,49,Kac-Rice formulas and the number of solutions of parametrized systems of polynomial equations,['11 Aug 2022'],https://pureportal.coventry.ac.uk/en/publications/kac-rice-formulas-and-the-number-of-solutions-of-parametrized-sys,"['Sadeghimanesh, A.']",['https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh']," Kac-Rice formulas express the expected number of elements a fiber of a random field has in terms of a multivariate integral. We consider here parametrized systems of polynomial equations that are linear in enough parameters, and provide a Kac-Rice formula for the expected number of solutions of the system when the parameters follow continuous distributions. Combined with Monte Carlo integration, we apply the formula to partition the parameter region according to the number of solutions or find a region in parameter space where the system has the maximal number of solutions. The motivation stems from the study of steady states of chemical reaction networks and gives new tools for the open problem of identifying the parameter region where the network has at least two positive steady states. We illustrate with numerous examples that our approach successfully handles a larger number of parameters than exact methods. "
50,50,Levelwise construction of a single cylindrical algebraic cell,['25 Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/levelwise-construction-of-a-single-cylindrical-algebraic-cell,"['England, M.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-england'],"Satisfiability Modulo Theories (SMT) solvers check the satisfiability of quantifier-free first-order logic formulas. We consider the theory of non-linear real arithmetic where the formulae are logical combinations of polynomial constraints. Here a commonly used tool is the Cylindrical Algebraic Decomposition (CAD) to decompose real space into cells where the constraints are truth-invariant through the use of projection polynomials.pAn improved approach is to repackage the CAD theory into a search-based algorithm: one that guesses sample points to satisfy the formula, and generalizes guesses that conflict constraints to cylindrical cells around samples which are avoided in the continuing search. Such an approach can lead to a satisfying assignment more quickly, or conclude unsatisfiability with fewer cells. A notable example of this approach is Jovanović and de Moura's NLSAT algorithm. Since these cells are produced locally to a sample we might need fewer projection polynomials than the traditional CAD projection. The original NLSAT algorithm reduced the set a little; while Brown's single cell construction reduced it much further still. However, the shape and size of the cell produced depends on the order in which the polynomials are considered.pThis paper proposes a method to construct such cells levelwise, i.e. built level-by-level according to a variable ordering. We still use a reduced number of projection polynomials, but can now consider a variety of different reductions and use heuristics to select the projection polynomials in order to optimise the shape of the cell under construction. We formulate all the necessary theory as a proof system: while not a common presentation for work in this field, it allows an elegant decoupling of heuristics from the algorithm and its proof of correctness."
51,51,Leveraging Arabic sentiment classification using an enhanced CNN-LSTM approach and effective Arabic text preparation,['Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/leveraging-arabic-sentiment-classification-using-an-enhanced-cnn-,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"The high variety in the forms of the Arabic words creates significant complexity related challenges in Natural Language Processing (NLP) tasks for Arabic text. These challenges can be dealt with by using different techniques for semantic representation, such as word embedding methods. In addition, approaches for reducing the diversity in Arabic morphologies can also be employed, for example using appropriate word normalisation for Arabic texts. Deep learning has proven to be very popular in solving different NLP tasks in recent years as well. This paper proposes an approach that combines Convolutional Neural Networks (CNNs) with Long Short-Term Memory (LSTM) networks to improve sentiment classification, by excluding the max-pooling layer from the CNN. This layer reduces the length of generated feature vectors after convolving the filters on the input data. As such, the LSTM networks will receive well-captured vectors from the feature maps. In addition, the paper investigated different effective approaches for preparing and representing the text features in order to increase the accuracy of Arabic sentiment classification."
52,52,LIFT: lncRNA identification and function-prediction tool,['17 Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/lift-lncrna-identification-and-function-prediction-tool,"['Shuttleworth, J.', 'England, M.']","['https://pureportal.coventry.ac.uk/en/persons/james-shuttleworth', 'https://pureportal.coventry.ac.uk/en/persons/matthew-england']","Long non-coding RNAs (lncRNAs) are a class of non-coding RNAs which play a significant role in several biological processes. Accurate identification and sub-classification of lncRNAs is crucial for exploring their characteristic functions in the genome as most coding potential computation (CPC) tools fail to accurately identify, classify and predict their biological functions in plant species. In this study, a novel computational framework called LncRNA identification and function prediction tool (LIFT) has been developed, which implements least absolute shrinkage and selection operator (LASSO) optimisation and iterative random forests classification for selection of optimal features, a novel position-based classification (PBC) method for sub-classifying lncRNAs into different classes, and a Bayesian-based function prediction approach for annotating lncRNA transcripts. Using LASSO, LIFT selected 31 optimal features and achieved a 15-30% improvement in the prediction accuracy on plant species when evaluated against state-of-the-art CPC tools. Using PBC, LIFT successfully identified the intergenic and antisense transcripts with greater accuracy in the A. thaliana and Z. mays datasets."
53,53,Machine Learning for Computer Algebra,['2022'],https://pureportal.coventry.ac.uk/en/publications/machine-learning-for-computer-algebra,"['Barket, R.', 'del Río, T.', 'England, M.']","['https://pureportal.coventry.ac.uk/en/persons/rashid-barket', 'https://pureportal.coventry.ac.uk/en/persons/tereso-del-r%C3%ADo-almajano', 'https://pureportal.coventry.ac.uk/en/persons/matthew-england']","Long non-coding RNAs (lncRNAs) are a class of non-coding RNAs which play a significant role in several biological processes. Accurate identification and sub-classification of lncRNAs is crucial for exploring their characteristic functions in the genome as most coding potential computation (CPC) tools fail to accurately identify, classify and predict their biological functions in plant species. In this study, a novel computational framework called LncRNA identification and function prediction tool (LIFT) has been developed, which implements least absolute shrinkage and selection operator (LASSO) optimisation and iterative random forests classification for selection of optimal features, a novel position-based classification (PBC) method for sub-classifying lncRNAs into different classes, and a Bayesian-based function prediction approach for annotating lncRNA transcripts. Using LASSO, LIFT selected 31 optimal features and achieved a 15-30% improvement in the prediction accuracy on plant species when evaluated against state-of-the-art CPC tools. Using PBC, LIFT successfully identified the intergenic and antisense transcripts with greater accuracy in the A. thaliana and Z. mays datasets."
54,54,Markov Chain Monte Carlo-Based Estimation of Stress–Strength Reliability Parameter for Generalized Linear Failure Rate Distributions,['2022'],https://pureportal.coventry.ac.uk/en/publications/markov-chain-monte-carlo-based-estimation-of-stressstrength-relia,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"This paper provides Bayesian and classical inference of Stress–Strength reliability parameter, [Formula: see text], where both [Formula: see text] and [Formula: see text] are independently distributed as 3-parameter generalized linear failure rate (GLFR) random variables with different parameters. Due to importance of stress–strength models in various fields of engineering, we here address the maximum likelihood estimator (MLE) of [Formula: see text] and the corresponding interval estimate using some efficient numerical methods. The Bayes estimates of R are derived, considering squared error loss functions. Because the Bayes estimates could not be expressed in closed forms, we employ a Markov Chain Monte Carlo procedure to calculate approximate Bayes estimates. To evaluate the performances of different estimators, extensive simulations are implemented and also real datasets are analyzed."
55,55,"Matrix decomposition by transforming the unit sphere to an Ellipsoid through Dilation, Rotation and Shearing",['19 Oct 2022'],https://pureportal.coventry.ac.uk/en/publications/matrix-decomposition-by-transforming-the-unit-sphere-to-an-ellips,"['Sadeghimanesh, A.']",['https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh'],"There are various decompositions of matrices in the literature such as lower-upper, singular value and polar decompositions to name a few. In this paper we are concerned with a less standard matrix decomposition for invertible matrices of order 3 with real entries, called TRD decomposition. In this decomposition an invertible matrix is written as product of three matrices corresponding to a shear, a rotation and a dilation map that transform the unit sphere to an ellipsoid. The reason of our interest is the geometric visualization of this decomposition. We also implemented an algorithm to compute this decomposition both in Maple and Matlab."
56,56,Minimizing Age of Information in Multi-hop Energy-Harvesting Wireless Sensor Network,['9 Aug 2022'],https://pureportal.coventry.ac.uk/en/publications/minimizing-age-of-information-in-multi-hop-energy-harvesting-wire,"['Benkhelifa, F.']",['https://pureportal.coventry.ac.uk/en/persons/fatma-benkhelifa'],"Age of information (AoI), a metric measuring the information freshness, has drawn increased attention due to its importance in monitoring applications in which nodes send time-stamped status updates to interested recipients, and timely updates about phenomena are important. In this work, we consider the AoI minimization scheduling problem in multi-hop energy harvesting(EH) wireless sensor networks (WSNs). We design the generation time of updates for nodes and develop transmission schedules under both protocol and physical interference models, aiming at achieving minimum peak AoI and average AoI among all nodes for a given time duration. We prove that it is an NP-Hard problem and propose an energy-adaptive, distributed algorithm called MAoIG. We derive its theoretical upper bounds for the peak and average AoI and a lower bound for peak AoI. The numerical results validate that MAoIG outperforms all of the baseline schemes in all scenarios and that the experimental results tightly track the theoretical upper bound optimal solutions while the lower bound tightness decreases with the number of nodes."
57,57,Monte Carlo Simulation of Stochastic Differential Equation to Study Information Geometry,['12 Aug 2022'],https://pureportal.coventry.ac.uk/en/publications/monte-carlo-simulation-of-stochastic-differential-equation-to-stu,"['Thiruthummal, A. A.', 'Kim, E.']","['https://pureportal.coventry.ac.uk/en/persons/abhiram-thiruthummal', 'https://pureportal.coventry.ac.uk/en/persons/e-j-kim']","Information Geometry is a useful tool to study and compare the solutions of a Stochastic Differential Equations (SDEs) for non-equilibrium systems. As an alternative method to solving the Fokker−Planck equation, we propose a new method to calculate time-dependent probability density functions (PDFs) and to study Information Geometry using Monte Carlo (MC) simulation of SDEs. Specifically, we develop a new MC SDE method to overcome the challenges in calculating a time-dependent PDF and information geometric diagnostics and to speed up simulations by utilizing GPU computing. Using MC SDE simulations, we reproduce Information Geometric scaling relations found from the Fokker−Planck method for the case of a stochastic process with linear and cubic damping terms. We showcase the advantage of MC SDE simulation over FPE solvers by calculating unequal time joint PDFs. For the linear process with a linear damping force, joint PDF is found to be a Gaussian. In contrast, for the cubic process with a cubic damping force, joint PDF exhibits a bimodal structure, even in a stationary state. This suggests a finite memory time induced by a nonlinear force. Furthermore, several power-law scalings in the characteristics of bimodal PDFs are identified and investigated."
58,58,More than faith - Muslim-heritage children in care: Strategic Briefing,['31 May 2022'],https://pureportal.coventry.ac.uk/en/publications/more-than-faith-muslim-heritage-children-in-care-strategic-briefi,"['Halford, A.', 'Cheruvallil-Contractor, S.']","['https://pureportal.coventry.ac.uk/en/persons/alison-halford', 'https://pureportal.coventry.ac.uk/en/persons/sariya-cheruvallil-contractor']","This briefing aims to support senior managers in meeting the needs of Muslim-heritage children and young people in care. Although it is aimed at senior leaders and managers, the content is of relevance to anyone working with Muslim-heritage children and young people.pThe briefing draws upon research and illustrative case examples, and comprises the following sections:pIntroduction and terminologypDiversity of the Muslim faithpThe importance of cultural identity and lived religionpChildren and young people’s intersectional identitiespOvercoming challenges to meet the needs of Muslim-heritage children and young peoplepHow can professionals support Muslim-heritage children and young people in care, and their carers?"
59,59,Multi-phase locking value: A generalized method for determining instantaneous multi-frequency phase coupling,['Apr 2022'],https://pureportal.coventry.ac.uk/en/publications/multi-phase-locking-value-a-generalized-method-for-determining-in-2,"['He, F.']",['https://pureportal.coventry.ac.uk/en/persons/fei-he'],"Background: Many physical, biological and neural systems behave as coupled oscillators, with characteristic phase coupling across different frequencies. Methods such as n:m phase locking value (where two coupling frequencies are linked as: mfp1p=nfp2p) and bi-phase locking value have previously been proposed to quantify phase coupling between two resonant frequencies (e.g. f,2f/3) and across three frequencies (e.g. fp1p,fp2p,fp1p+fp2p), respectively. However, the existing phase coupling metrics have their limitations and limited applications. They cannot be used to detect or quantify phase coupling across multiple frequencies (e.g. fp1p,fp2p,fp3p,fp4p,fp1p+fp2p+fp3p-fp4p), or coupling that involves non-integer multiples of the frequencies (e.g. fp1p,fp2p,2fp1p/3+fp2p/3). New methods: To address the gap, this paper proposes a generalized approach, named multi-phase locking value (M-PLV), for the quantification of various types of instantaneous multi-frequency phase coupling. Different from most instantaneous phase coupling metrics that measure the simultaneous phase coupling, the proposed M-PLV method also allows the detection of delayed phase coupling and the associated time lag between coupled oscillators. Results: The M-PLV has been tested on cases where synthetic coupled signals are generated using white Gaussian signals, and a system comprised of multiple coupled Rössler oscillators, as well as a human subject dataset. Results indicate that the M-PLV can provide a reliable estimation of the time window and frequency combination where the phase coupling is significant, as well as a precise determination of time lag in the case of delayed coupling. This method has the potential to become a powerful new tool for exploring phase coupling in complex nonlinear dynamic systems."
60,60,New heuristic to choose a cylindrical algebraic decomposition variable ordering motivated by complexity analysis,['11 Aug 2022'],https://pureportal.coventry.ac.uk/en/publications/new-heuristic-to-choose-a-cylindrical-algebraic-decomposition-var,"['del Río, T.', 'England, M.']","['https://pureportal.coventry.ac.uk/en/persons/tereso-del-r%C3%ADo-almajano', 'https://pureportal.coventry.ac.uk/en/persons/matthew-england']", It is well known that the variable ordering can be critical to the efficiency or even tractability of the cylindrical algebraic decomposition (CAD) algorithm. We propose new heuristics inspired by complexity analysis of CAD to choose the variable ordering. These heuristics are evaluated against existing heuristics with experiments on the SMT-LIB benchmarks using both existing performance metrics and a new metric we propose for the problem at hand. The best of these new heuristics chooses orderings that lead to timings on average 17% slower than the virtual-best: an improvement compared to the prior state-of-the-art which achieved timings 25% slower. 
61,61,Off the boil? The challenges of monitoring cooking behaviour in refugee settlements,['22 Aug 2022'],https://pureportal.coventry.ac.uk/en/publications/off-the-boil-the-challenges-of-monitoring-cooking-behaviour-in-re,"['Halford, A.', 'Gaura, E.', 'Brusey, J.', 'Nixon, J.']","['https://pureportal.coventry.ac.uk/en/persons/alison-halford', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura', 'https://pureportal.coventry.ac.uk/en/persons/james-brusey', 'https://pureportal.coventry.ac.uk/en/persons/jonathan-nixon']","To address the need for improved access to energy and meet the United Nations Clean Energy Challenge (2019), humanitarian agencies require robust, valid, and meaningful data that documents the everyday energy practices of displaced people. Collecting data through sensor monitoring is one way of providing quality energy data that will aid humanitarian actors in designing and delivering sustainable affordable energy solutions. Using the case of the design and deployment of 20 stove use monitors (SUM) in Kigeme refugee camp in Rwanda, this paper discusses the benefits and limitations of collecting data on cookstove usage using wireless sensors in refugee settlements., Central to the discussion is the value of reflexivity or critical reflection to uncover significant knowledge gaps that can apply more generally to the problem of designing and deploying sensor systems for the displaced setting. If sensor monitoring systems are to collect data that aid appropriate energy planning and support technology development in the humanitarian sector, we contend improvements in sensor design and deployment protocols are needed to accommodate the displaced setting's cultural, economic, and political complexity. These improvements include the uptake of sensor monitoring design that embeds ethical, progressive, and inclusive protocols when working in the displaced setting."
62,62,On the impact of prior distributions on efficiency of sparse Gaussian process regression,['26 Jun 2022'],https://pureportal.coventry.ac.uk/en/publications/on-the-impact-of-prior-distributions-on-efficiency-of-sparse-gaus,"['Chatrabgoun, O.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/omid-chatrabgoun', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","Gaussian process regression (GPR) is a kernel-based learning model, which unfortunately suffers from computational intractability for irregular domain and large datasets due to the full kernel matrix. In this paper, we propose a novel method to produce a sparse kernel matrix using the compact support radial kernels (CSRKs) to efficiently learn the GPR from large datasets. The CSRKs can effectively avoid the ill-conditioned and full kernel matrix during GPR training and prediction, consequently reducing computational costs and memory requirements. In practice, the interest in CSRKs waned slightly as it became evident that, there is a trade-off principle (conflict between accuracy and sparsity) for compactly supported kernels. Hence, when using kernels with compact support, during GPR training, the main focus will be on providing a high level of accuracy. In this case, the advantage of achieving a sparse covariance matrix for CSRKs will almost disappear, as we will see in the numerical results. This trade-off has led authors to search for an “optimal” value of the scale parameter. Accordingly, by selecting the suitable priors on the kernel hyperparameters, and simply estimating the hyperparameters using a modified version of the maximum likelihood estimation (MLE), the GPR model derived from the CSRKs yields maximal accuracy while still maintaining a sparse covariance matrix. In fact, in GPR training, modified version of the MLE will be proportional to the product of MLE and a given suitable prior distribution for the hyperparameters that provides an efficient method for learning. The misspecification of prior distributions and their impact on the predictability of the sparse GPR models are also comprehensively investigated using several empirical studies. The proposed new approach is applied to some irregular domains with noisy test functions in 2D data sets in a comparative study. We finally investigate the effect of prior on the predictability of GPR models based on the real dataset. The derived results suggest the proposed method leads to more sparsity and well-conditioned kernel matrices in all cases."
63,63,On the Implementation of Cylindrical Algebraic Coverings for Satisfiability Modulo Theories Solving,['10 Feb 2022'],https://pureportal.coventry.ac.uk/en/publications/on-the-implementation-of-cylindrical-algebraic-coverings-for-sati,"['England, M.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-england'],"We recently presented cylindrical algebraic coverings: a method based on the theory of cylindrical algebraic decomposition and suited for nonlinear real arithmetic theory reasoning in Satisfiability Modulo Theories solvers. We now present a more careful implementation within cvc5, discuss some implementation details, and highlight practical benefits compared to previous approaches, i.e., NLSAT and incremental CAD. We show how this new implementation simplifies proof generation for nonlinear real arithmetic problems in cvc5 and announce some very encouraging experimental results that position cvc5 at the very front of currently available SMT solvers for QF_NRA."
64,64,On the Scalability of Duty-Cycled LoRa Networks with Imperfect SF Orthogonality,['1 Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/on-the-scalability-of-duty-cycled-lora-networks-with-imperfect-sf,"['Benkhelifa, F.']",['https://pureportal.coventry.ac.uk/en/persons/fatma-benkhelifa'],"This letter uses stochastic geometry and queuing theory to study the scalability of long-range (LoRa) networks, accounting for duty cycling restrictions and imperfect spreading factor (SFs) orthogonality. The scalability is characterised by the joint boundaries of device density and traffic intensity per device. Novel cross-correlation factors are used to quantify imperfect SF-orthogonality. Our results show that a proper characterisation of LoRa orthogonality extends the scalability of the network. They also highlight that for low/medium densities decreasing the SF extends the spanned spectrum of sensing applications characterised by their traffic requirements (i.e., sensing rate). However, for high density (>104 nodes/Km2), the Pareto frontiers converge to a stability limit governed by the SF allocation scheme and the predefined capture thresholds. The results further evince the importance of capturing threshold distribution among the SFs to mitigate the unfair latency."
65,65,Parallel multi-swarm cooperative particle swarm optimization for protein–ligand docking and virtual screening,['30 May 2022'],https://pureportal.coventry.ac.uk/en/publications/parallel-multi-swarm-cooperative-particle-swarm-optimization-for-,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Background: pA high-quality docking method tends to yield multifold gains with half pains for the new drug development. Over the past few decades, great efforts have been made for the development of novel docking programs with great efficiency and intriguing accuracy. AutoDock Vina (Vina) is one of these achievements with improved speed and accuracy compared to AutoDock4. Since it was proposed, some of its variants, such as PSOVina and GWOVina, have also been developed. However, for all these docking programs, there is still large room for performance improvement. pResults:pIn this work, we propose a parallel multi-swarm cooperative particle swarm model, in which one master swarm and several slave swarms mutually cooperate and co-evolve. Our experiments show that multi-swarm programs possess better docking robustness than PSOVina. Moreover, the multi-swarm program based on random drift PSO can achieve the best highest accuracy of protein–ligand docking, an outstanding enrichment effect for drug-like activate compounds, and the second best AUC screening accuracy among all the compared docking programs, but with less computation consumption than most of the other docking programs. pConclusion:pThe proposed multi-swarm cooperative model is a novel algorithmic modeling suitable for protein–ligand docking and virtual screening. Owing to the existing coevolution between the master and the slave swarms, this model in parallel generates remarkable docking performance. The source code can be freely downloaded from https://github.com/li-jin-xing/MPSOVina."
66,66,Parts of Speech Tagging in NLP- an Investigation on Runtime Optimization with Quantum Formulation and ZX Calculus,['10 Mar 2022'],https://pureportal.coventry.ac.uk/en/publications/parts-of-speech-tagging-in-nlp-an-investigation-on-runtime-optimi,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"This paper presents an optimized formulation of the parts of speech tagging in Natural Language Processing (NLP) with a quantum computing approach, and it further demonstrates the quantum gate-level runnable optimization with ZX-calculus, keeping the implementation target in the context of Noisy Intermediate Scale Quantum Systems (NISQ). The discussed quantum formulation exhibits quadratic speed up over the classical counterpart and further demonstrates the implementable optimization with the help of ZX calculus postulates. "
67,67,Polynomial Superlevel Set Representation of the Multistationarity Region of Chemical Reaction Networks,['27 Sep 2022'],https://pureportal.coventry.ac.uk/en/publications/polynomial-superlevel-set-representation-of-the-multistationarity,"['Sadeghimanesh, A.', 'England, M.']","['https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh', 'https://pureportal.coventry.ac.uk/en/persons/matthew-england']","In this paper we introduce a new representation for the multistationarity region of a reaction network, using polynomial superlevel sets. The advantages of using this polynomial superlevel set representation over the formerly existing representations (cylindrical algebraic decompositions, numeric sampling, rectangular division) is discussed, and algorithms to compute this new representation are provided. The results are given for the general mathematical formalism of a parametric system of equations and therefore can be used in other application areas."
68,68,Predicting Primary Sequence-Based Protein-Protein Interactions Using a Mercer Series Representation of Nonlinear Support Vector Machine,['1 Dec 2022'],https://pureportal.coventry.ac.uk/en/publications/predicting-primary-sequence-based-protein-protein-interactions-us,"['Chatrabgoun, O.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/omid-chatrabgoun', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","The prediction of protein-protein interactions (PPIs) is essential to understand the cellular processes from a medical perspective. Among the various machine learning techniques, kernel-based Support Vector Machine (SVM) has been commonly employed to discriminate between interacting and non-interacting protein pairs. The main drawback of employing the kernel-based SVM to datasets with many features, such as the primary sequence-based protein-protein dataset, is the significant increase in computational time of training stage. This increase in computational time is mainly due to the presence of the kernel in solving the quadratic optimisation problem (QOP) involved in nonlinear SVM. In order to fix this issue, we propose a novel and efficient computational algorithm by approximating the kernel-based SVM using a low-rank truncated Mercer series as well as desired. As a result, the QOP for the approximated kernel-based SVM will be very tractable in the sense that there is a significant reduction in computational time of training and validating stages. We illustrate the novelty of the proposed method by predicting the PPIs of ""S. Cerevisiae” where the protein features extracted using the multiscale local descriptor (MLD), and then we compare the predictive performance of the proposed low-rank approximation with the existing methods. Finally, the new method results in significant reduction in computational time for predicting PPIs with almost as accuracy as kernel-based SVM"
69,69,Predicting the Public Adoption of Connected and Autonomous Vehicles,['1 Feb 2022'],https://pureportal.coventry.ac.uk/en/publications/predicting-the-public-adoption-of-connected-and-autonomous-vehicl,"['Ahmed, M. L.', 'Palade, V.']","['https://pureportal.coventry.ac.uk/en/persons/mohammed-ahmed', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade']","Connected and Autonomous Vehicles (CAV) are gaining increasing importance due to the current needs of modern society for better mobility and societal impact. CAV development and adoption will be driven by Artificial Intelligence (AI) and 5G/6G technologies which will offer increased speed, reduced latency and ubiquity. However, the public is concerned with the concept of handing total control of driving to vehicles. These concerns will inhibit the adoption of CAVs when they become available to the public. In this paper, we investigated user adoption of CAVs by collecting quantitative data from potential users based on their preference and inherent concerns towards adoption. We conducted a statistical analysis and applied machine learning techniques to predict the user adoption for CAVs. Our results show that several machine learning approaches were effective in forecasting user adoption for CAVs. We have employed Neural Networks, Random Forest, Naïve Bayes and Fuzzy Logic based models and achieved accuracies of 81.76%, 83.63%, 82.15% and 86.38, respectively, in forecasting the public adoption of CAV."
70,70,Privacy Enhancing Technologies (PETs) for Connected Vehicles in Smart Cities,['Oct 2022'],https://pureportal.coventry.ac.uk/en/publications/privacy-enhancing-technologies-pets-for-connected-vehicles-in-sma,"['Mitchell, F.']",['https://pureportal.coventry.ac.uk/en/persons/faye-mitchell'],"Many Experts believe that the Internet of Things (IoT) is a new revolution in technology that has brought many benefits for our organizations, businesses, and industries. However, information security and privacy protection are important challenges particularly for smart vehicles in smart cities that have attracted the attention of experts in this domain. Privacy Enhancing Technologies (PETs) endeavor to mitigate the risk of privacy invasions, but the literature lacks a thorough review of the approaches and techniques that support individuals' privacy in the connection between smart vehicles and smart cities. This gap has stimulated us to conduct this research with the main goal of reviewing recent privacy-enhancing technologies, approaches, taxonomy, challenges, and solutions on the application of PETs for smart vehicles in smart cities. The significant aspect of this study originates from the inclusion of data-oriented and process-oriented privacy protection. This research also identifies limitations of existing PETs, complementary technologies, and potential research directions."
71,71,Rapid Localization and Mapping Method Based on Adaptive Particle Filters,['2 Dec 2022'],https://pureportal.coventry.ac.uk/en/publications/rapid-localization-and-mapping-method-based-on-adaptive-particle-,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"With the development of autonomous vehicles, localization and mapping technologies have become crucial to equip the vehicle with the appropriate knowledge for its operation. In this paper, we extend our previous work by prepossessing a localization and mapping architecture for autonomous vehicles that do not rely on GPS, particularly in environments such as tunnels, under bridges, urban canyons, and dense tree canopies. The proposed approach is of two parts. Firstly, a K-means algorithm is employed to extract features from LiDAR scenes to create a local map of each scan. Then, we concatenate the local maps to create a global map of the environment and facilitate data association between frames. Secondly, the main localization task is performed by an adaptive particle filter that works in four steps: (a) generation of particles around an initial state (provided by the GPS); (b) updating the particle positions by providing the motion (translation and rotation) of the vehicle using an inertial measurement device; (c) selection of the best candidate particles by observing at each timestamp the match rate (also called particle weight) of the local map (with the real-time distances to the objects) and the distances of the particles to the corresponding chunks of the global map; (d) averaging the selected particles to derive the estimated position, and, finally, using a resampling method on the particles to ensure the reliability of the position estimation. The performance of the newly proposed technique is investigated on different sequences of the Kitti and Pandaset raw data with different environmental setups, weather conditions, and seasonal changes. The obtained results validate the performance of the proposed approach in terms of speed and representativeness of the feature extraction for real-time localization in comparison with other state-of-the-art methods."
72,72,RDPSOVina: the random drift particle swarm optimization for protein-ligand docking,['Jun 2022'],https://pureportal.coventry.ac.uk/en/publications/rdpsovina-the-random-drift-particle-swarm-optimization-for-protei,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Protein-ligand docking is of great importance to drug design, since it can predict the binding affinity between ligand and protein, and guide the synthesis direction of the lead compounds. Over the past few decades, various docking programs have been developed, some of them employing novel optimization algorithms. However, most of those methods cannot simultaneously achieve both good efficiency and accuracy. Therefore, it is worthwhile to pour the efforts into the development of a docking program with fast speed and high quality of the solutions obtained. The research presented in this paper, based on the docking scheme of Vina, developed a novel docking program called RDPSOVina. The RDPSOVina employes a novel search algorithm but the same scoring function of Vina. It utilizes the random drift particle swarm optimization (RDPSO) algorithm as the global search algorithm, implements the local search with small probability, and applies Markov chain mutation to the particles' personal best positions in order to harvest more potential-candidates. To prove the outstanding docking performance in RDPSOVina, we performed the re-docking experiments on two PDBbind datasets and cross-docking experiments on the Sutherland-crossdock-set, respectively. The RDPSOVina exhibited superior protein-ligand docking accuracy and better cross-docking prediction with higher operation efficiency than most of the compared methods. It is available at https://github.com/li-jin-xing/RDPSOVina . [Abstract copyright: © 2022. The Author(s), under exclusive licence to Springer Nature Switzerland AG.]"
73,73,Resilient Consensus Control Design for DC Microgrids against False Data Injection Attacks Using a Distributed Bank of Sliding Mode Observers,['30 Mar 2022'],https://pureportal.coventry.ac.uk/en/publications/resilient-consensus-control-design-for-dc-microgrids-against-fals,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"This paper investigates the problem of false data injection attack (FDIA) detection in microgrids. The grid under study is a DC microgrid with distributed boost converters, where the false data are injected into the voltage data so as to investigate the effect of attacks. The proposed algorithm uses a bank of sliding mode observers that estimates the states of the neighbor agents. Each agent estimates the neighboring states and, according to the estimation and communication data, the detection mechanism reveals the presence of FDIA. The proposed control scheme provides resiliency to the system by replacing the conventional consensus rule with attack-resilient ones. In order to evaluate the efficiency of the proposed method, a real-time simulation with eight agents has been performed. Moreover, a verification experimental test with three boost converters has been utilized to confirm the simulation results. It is shown that the proposed algorithm is able to detect FDI attacks and it protects the consensus deviation against FDI attacks."
74,74,Saving Research Budgets by Improving Algebraic Tools for the Study of Population Dynamics,['7 Mar 2022'],https://pureportal.coventry.ac.uk/en/publications/saving-research-budgets-by-improving-algebraic-tools-for-the-stud,"['Sadeghimanesh, A.']",['https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh'],"This paper investigates the problem of false data injection attack (FDIA) detection in microgrids. The grid under study is a DC microgrid with distributed boost converters, where the false data are injected into the voltage data so as to investigate the effect of attacks. The proposed algorithm uses a bank of sliding mode observers that estimates the states of the neighbor agents. Each agent estimates the neighboring states and, according to the estimation and communication data, the detection mechanism reveals the presence of FDIA. The proposed control scheme provides resiliency to the system by replacing the conventional consensus rule with attack-resilient ones. In order to evaluate the efficiency of the proposed method, a real-time simulation with eight agents has been performed. Moreover, a verification experimental test with three boost converters has been utilized to confirm the simulation results. It is shown that the proposed algorithm is able to detect FDI attacks and it protects the consensus deviation against FDI attacks."
75,75,SC-Square: Future Progress with Machine Learning,['14 Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/sc-square-future-progress-with-machine-learning,"['England, M.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-england'],"The algorithms employed by our communities are often underspecified, and thus have multiple implementation choices, which do not effect the correctness of the output, but do impact the efficiency or even tractability of its production.  pIn this extended abstract, to accompany a keynote talk at the 2021 SC-Square Workshop, we survey recent work (both the author's and from the literature) on the use of Machine Learning technology to improve algorithms of interest to SC-Square."
76,76,SC-Square: Overview to 2021.,['14 Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/sc-square-overview-to-2021,"['England, M.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-england'],"This extended abstract was written to accompany an invited talk at the 2021 SC-Square Workshop, where the author was asked to give an overview of SC-Square progress to date.  The author first reminds the reader of the definition of SC-Square, then briefly outlines some of the history, before picking out some (personal) scientific highlights."
77,77,Stable likelihood computation for machine learning of linear differential operators with Gaussian processes,['20 Apr 2022'],https://pureportal.coventry.ac.uk/en/publications/stable-likelihood-computation-for-machine-learning-of-linear-diff,"['Chatrabgoun, O.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/omid-chatrabgoun', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","In many applied sciences, the main aim is to learn the parameters in the operational equations which best fit the observed data. A framework for solving such problems is to employ Gaussian process (GP) emulators which are well-known as nonparametric Bayesian machine learning techniques. GPs are among a class of methods known as kernel machines which can be used to approximate rather complex problems by tuning their hyperparameters. The maximum likelihood estimation (MLE) has widely been used to estimate the parameters of the operators and kernels. However, the MLE-based and Bayesian inference in the standard form are usually involved in setting up a covariance matrix which is generally ill-conditioned. As a result, constructing and inverting the covariance matrix using the standard form will become unstable to learn the parameters in the operational equations. In this paper, we propose a novel approach to tackle these computational complexities and also resolve the ill-conditioning problem by forming the covariance matrix using alternative bases via the Hilbert−Schmidt SVD (HS-SVD) approach. Applying this approach yields a novel matrix factorization of the block-structured covariance matrix which can be implemented stably by isolating the main source of the ill-conditioning. In contrast to standard matrix decompositions which start with a matrix and produce the resulting factors, the HS-SVD is constructed from the Hilbert−Schmidt eigenvalues and eigenvectors without the need to ever form the potentially ill-conditioned matrix. We also provide stable MLE and Bayesian inference to adaptively estimate hyperparameters, and the corresponding operators can then be efficiently predicted at some new points using the proposed HS-SVD bases. The efficiency and stability of the proposed HS-SVD method will be compared with the existing methods by several illustrations of the parametric linear equations, such as ordinary and partial differential equations, and integro-differential and fractional order operators."
78,78,Switching Trackers for Effective Sensor Fusion in Advanced Driver Assistance Systems,['3 Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/switching-trackers-for-effective-sensor-fusion-in-advanced-driver,"['Deo, A.', 'Palade, V.']","['https://pureportal.coventry.ac.uk/en/persons/ankur-deo', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade']","Modern cars utilise Advanced Driver Assistance Systems (ADAS) in several ways. In ADAS, the use of multiple sensors to gauge the environment surrounding the ego-vehicle offers numerous advantages, as fusing information from more than one sensor helps to provide highly reliable and error-free data. The fused data is typically then fed to a tracker algorithm, which helps to reduce noise and compensate for situations when received sensor data is temporarily absent or spurious, or to counter the offhand false positives and negatives. The performances of these constituent algorithms vary vastly under different scenarios. In this paper, we focus on the variation in the performance of tracker algorithms in sensor fusion due to the alteration in external conditions in different scenarios, and on the methods for countering that variation. We introduce a sensor fusion architecture, where the tracking algorithm is spontaneously switched to achieve the utmost performance under all scenarios. By employing a Real-time Traffic Density Estimation (RTDE) technique, we may understand whether the ego-vehicle is currently in dense or sparse traffic conditions. A highly dense traffic (or congested traffic) condition would mean that external circumstances are non-linear; similarly, sparse traffic conditions would mean that the probability of linear external conditions would be higher. We also employ a Traffic Sign Recognition (TSR) algorithm, which is able to monitor for construction zones, junctions, schools, and pedestrian crossings, thereby identifying areas which have a high probability of spontaneous, on-road occurrences. Based on the results received from the RTDE and TSR algorithms, we construct a logic which switches the tracker of the fusion architecture between an Extended Kalman Filter (for linear external scenarios) and an Unscented Kalman Filter (for non-linear scenarios). This ensures that the fusion model always uses the tracker that is best suited for its current needs, thereby yielding consistent accuracy across multiple external scenarios, compared to the fusion models that employ a fixed single tracker."
79,79,The benefits of clustering in cylindrical algebraic decomposition,['2022'],https://pureportal.coventry.ac.uk/en/publications/the-benefits-of-clustering-in-cylindrical-algebraic-decomposition,"['del Río, T.', 'England, M.']","['https://pureportal.coventry.ac.uk/en/persons/tereso-del-r%C3%ADo-almajano', 'https://pureportal.coventry.ac.uk/en/persons/matthew-england']","Cylindrical Algebraic Decomposition (CAD) is a very powerful algorithm with many potential applications, however, its doubly exponential complexity limits its usability. In this document we demonstrate how the techniques of adjacency and clustering would reduce the double exponent of CAD complexity."
80,80,"The politics of Matching: Ethnicity, Religion and Muslim-heritage Children in Care in the UK",['1 Dec 2022'],https://pureportal.coventry.ac.uk/en/publications/the-politics-of-matching-ethnicity-religion-and-muslim-heritage-c,"['Cheruvallil-Contractor, S.', 'Halford, A.']","['https://pureportal.coventry.ac.uk/en/persons/sariya-cheruvallil-contractor', 'https://pureportal.coventry.ac.uk/en/persons/alison-halford']","In 2014, in order to improve outcomes for children from ethnic minority backgrounds and to speed up the adoption process, the UK government changed the Children and Families Act. The legal requirement on adoption agencies to consider ethnicity in the decision around 'matching' was removed, thus clearing the way for transracial placements. This article interrogates the impact of the change in law on social work practice around adoption, using the experiences of diverse Muslim-heritage children as a case study. Grounded in the sociology of religion, the findings presented here are based on semi-structured qualitative interviews (n=28) with those involved in the care of Muslim-heritage children. In discussing qualitative findings, all adopters and prospective adopters interviewed in this research insisted on adopting children who 'look like them', and social workers continued to look for the 'best' possible matches. Children from minoritised backgrounds continue to wait for long periods before finding permanent homes. Our evidence raises questions about the efficacy of policy guidance. Based on this evidence we conclude that greater strategizing is needed around the recruitment of adopters from diverse backgrounds."
81,81,The practice of AI and ethics in energy transition futures,['4 Jul 2022'],https://pureportal.coventry.ac.uk/en/publications/the-practice-of-ai-and-ethics-in-energy-transition-futures,"['Stamp, K.', 'Halford, A.', 'Gaura, E.']","['https://pureportal.coventry.ac.uk/en/persons/kathryn-stamp', 'https://pureportal.coventry.ac.uk/en/persons/alison-halford', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura']","With greater implementation of Artificial Intelligence (AI) and big data as part of the transition towards digitalisation of the UK energy sector, there is a need for greater clarity around how ethics and ethical practices are understood and applied by stakeholders.pThe UK Energy Sector is undergoing a significant shift towards digitalisation. Increased use of AI, whilst improving safety, productivity, and sustainability of energy systems, will become increasingly complex with high computational demands. This raises ethical concerns around issues such as security and privacy. While there is a strong culture of regulatory compliance, there is a significantly less established understanding of ethical practices and frameworks in the UK energy sector.pThis briefing paper details work conducted by EnergyREV researchers exploring understanding and experience of ethics and AI, as the sector moves towards greater employment of technology in the data collection, storage and use processes. By addressing ethical concerns from the outset, taking a proactive rather than reactive approach, risks can be mitigated, and potential issues addressed early on, leading to more opportunities for technological advancement and innovation.pThrough engagement with energy actors, an understanding of how ethics is applied by those working in the energy data sector will be improved"
82,82,Transfer Learning based Classification of Diabetic Retinopathy on the Kaggle EyePACS dataset,['15 Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/transfer-learning-based-classification-of-diabetic-retinopathy-on,"['Tariq, M.', 'Palade, V.', 'Ma, Y.']","['https://pureportal.coventry.ac.uk/en/persons/maria-tariq', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade', 'https://pureportal.coventry.ac.uk/en/persons/yingliang-ma']","Severe stages of diabetes can eventually lead to an eye conditionpcalled diabetic retinopathy. It is one of the leading causes of temporary visual disability and permanent blindness. There is no cure for this disease other than a proper treatment in the early stages. Five stages of diabetic retinopathy are discussed in this paper that need to be detected followed by a proper treatment. Transfer learning is used to detect the grades of diabetic retinopathy in eye fundus images, without training from scratch. The Kaggle EyePACS dataset is one of the largest datasetspavailable publicly for experimentation. In our work, an extensive study on the Kaggle EyePACS dataset is carried out using pre-trained models ResNet50 and DenseNet121. The Aptos dataset is also used in comparison with this dataset to examine the performance of the pre-trained models. Different experiments are performed to analyze the images from the different classes in the Kaggle EyePACS dataset. This dataset has significant challenges including image noise, imbalanced classes, and fault annotations. Our work highlights potential problems within the datasetpand the conflicts between the classes. A clustering technique is used to get informative images from the normal class to improve the model’s accuracy to 70%."
83,83,Trustworthiness of systematic review automation: An Interview at Coventry University,['2022'],https://pureportal.coventry.ac.uk/en/publications/trustworthiness-of-systematic-review-automation-an-interview-at-c,"['Jiang, X.']",['https://pureportal.coventry.ac.uk/en/persons/xiaorui-jiang'],"Severe stages of diabetes can eventually lead to an eye conditionpcalled diabetic retinopathy. It is one of the leading causes of temporary visual disability and permanent blindness. There is no cure for this disease other than a proper treatment in the early stages. Five stages of diabetic retinopathy are discussed in this paper that need to be detected followed by a proper treatment. Transfer learning is used to detect the grades of diabetic retinopathy in eye fundus images, without training from scratch. The Kaggle EyePACS dataset is one of the largest datasetspavailable publicly for experimentation. In our work, an extensive study on the Kaggle EyePACS dataset is carried out using pre-trained models ResNet50 and DenseNet121. The Aptos dataset is also used in comparison with this dataset to examine the performance of the pre-trained models. Different experiments are performed to analyze the images from the different classes in the Kaggle EyePACS dataset. This dataset has significant challenges including image noise, imbalanced classes, and fault annotations. Our work highlights potential problems within the datasetpand the conflicts between the classes. A clustering technique is used to get informative images from the normal class to improve the model’s accuracy to 70%."
84,84,Using Machine Learning for Anomaly Detection on a System-on-Chip under Gamma Radiation,['Nov 2022'],https://pureportal.coventry.ac.uk/en/publications/using-machine-learning-for-anomaly-detection-on-a-system-on-chip--2,"['Kasap, S.']",['https://pureportal.coventry.ac.uk/en/persons/server-kasap'],"The emergence of new nanoscale technologies has imposed significant challenges to designing reliable electronic systems in radiation environments. A few types of radiation like Total Ionizing Dose (TID) can cause permanent damages on such nanoscale electronic devices, and current state-of-the-art technologies to tackle TID make use of expensive radiation-hardened devices. This paper focuses on a novel and different approach: using machine learning algorithms on consumer electronic level Field Programmable Gate Arrays (FPGAs) to tackle TID effects and monitor them to replace before they stop working. This condition has a research challenge to anticipate when the board results in a total failure due to TID effects. We observed internal measurements of FPGA boards under gamma radiation and used three different anomaly detection machine learning (ML) algorithms to detect anomalies in the sensor measurements in a gamma-radiated environment. The statistical results show a highly significant relationship between the gamma radiation exposure levels and the board measurements. Moreover, our anomaly detection results have shown that a One-Class SVM with Radial Basis Function Kernel has an average recall score of 0.95. Also, all anomalies can be detected before the boards are entirely inoperative, i.e. voltages drop to zero and confirmed with a sanity check."
85,85,Using Machine Learning for Anomaly Detection on a System-on-Chip under Gamma Radiation,['5 Jan 2022'],https://pureportal.coventry.ac.uk/en/publications/using-machine-learning-for-anomaly-detection-on-a-system-on-chip-,"['Kasap, S.']",['https://pureportal.coventry.ac.uk/en/persons/server-kasap']," The emergence of new nanoscale technologies has imposed significant challenges to designing reliable electronic systems in radiation environments. A few types of radiation like Total Ionizing Dose (TID) effects often cause permanent damages on such nanoscale electronic devices, and current state-of-the-art technologies to tackle TID make use of expensive radiation-hardened devices. This paper focuses on a novel and different approach: using machine learning algorithms on consumer electronic level Field Programmable Gate Arrays (FPGAs) to tackle TID effects and monitor them to replace before they stop working. This condition has a research challenge to anticipate when the board results in a total failure due to TID effects. We observed internal measurements of the FPGA boards under gamma radiation and used three different anomaly detection machine learning (ML) algorithms to detect anomalies in the sensor measurements in a gamma-radiated environment. The statistical results show a highly significant relationship between the gamma radiation exposure levels and the board measurements. Moreover, our anomaly detection results have shown that a One-Class Support Vector Machine with Radial Basis Function Kernel has an average Recall score of 0.95. Also, all anomalies can be detected before the boards stop working. "
86,86,Using Machine Learning in SC2,['23 Aug 2022'],https://pureportal.coventry.ac.uk/en/publications/using-machine-learning-in-sc2,"['del Río, T.']",['https://pureportal.coventry.ac.uk/en/persons/tereso-del-r%C3%ADo-almajano'],"This talk exposes many possible uses of Machine Learning (ML) in the context of SC2, and how this approach differs from human-made heuristics. Different ML paradigms are presented and it is discussed how symbolic data could be encoded. This talk also intends to motivate a discussion about which datasets should be used for training and testing ML models."
87,87,Using multi-objective optimisation with ADM1 and measured data to improve the performance of an existing anaerobic digestion system,['Aug 2022'],https://pureportal.coventry.ac.uk/en/publications/using-multi-objective-optimisation-with-adm1-and-measured-data-to,"['Ashraf, R. J.', 'Nixon, J. D.', 'Brusey, J.']","['https://pureportal.coventry.ac.uk/en/persons/rjaa-jawad-ashraf', 'https://pureportal.coventry.ac.uk/en/persons/jonathan-nixon', 'https://pureportal.coventry.ac.uk/en/persons/james-brusey']","This paper presents a method to model and optimise the substrate feeding rate of an anaerobic digestion (AD) system. The method is demonstrated for a case study plant in Bangalore, India, using onsite kitchen waste to provide biogas for cooking. The AD system is modelled using Anaerobic Digestion Model No. 1 (ADM1) and a genetic algorithm (GA) is applied to control the substrate feeding rate in order to simultaneously minimise the volume of flared biogas, unmet gas demand and energy cost. Our results show that ADM1 can predict biogas yield from a continuously operated digester well with mean percentage error between daily predicted and measured data values of only 5.7% for March 2017 and 17.8% for July 2017. When biogas flaring and unmet gas demand were minimised, the amount of biogas flared reduced from 886.62 mp3p to 88.87 mp3p in March and from 73.79 mp3p to 68.49 mp3p in July. When the energy cost was also considered within an objective function, the biogas flared reduced from 886.62 mp3p to 281.27 mp3p for March, but increased from 73.79 mp3p to 180.11 mp3p for July. The amount of flaring increased in July as the energy cost function increased biogas yield without considering surplus gas production beyond demand and storage capacity. As AD systems are often operated to maximise biogas production, these results highlight the need for multi-objective optimisation, particularly for off-grid AD systems."
88,88,Using Physics-informed Neural Networks to Model the Hydro-morphodynamics of Mangrove Environments,['9 Dec 2022'],https://pureportal.coventry.ac.uk/en/publications/using-physics-informed-neural-networks-to-model-the-hydro-morphod,"['Fanous, M.']",['https://pureportal.coventry.ac.uk/en/persons/majdi-fanous'],"This paper presents a method to model and optimise the substrate feeding rate of an anaerobic digestion (AD) system. The method is demonstrated for a case study plant in Bangalore, India, using onsite kitchen waste to provide biogas for cooking. The AD system is modelled using Anaerobic Digestion Model No. 1 (ADM1) and a genetic algorithm (GA) is applied to control the substrate feeding rate in order to simultaneously minimise the volume of flared biogas, unmet gas demand and energy cost. Our results show that ADM1 can predict biogas yield from a continuously operated digester well with mean percentage error between daily predicted and measured data values of only 5.7% for March 2017 and 17.8% for July 2017. When biogas flaring and unmet gas demand were minimised, the amount of biogas flared reduced from 886.62 mp3p to 88.87 mp3p in March and from 73.79 mp3p to 68.49 mp3p in July. When the energy cost was also considered within an objective function, the biogas flared reduced from 886.62 mp3p to 281.27 mp3p for March, but increased from 73.79 mp3p to 180.11 mp3p for July. The amount of flaring increased in July as the energy cost function increased biogas yield without considering surplus gas production beyond demand and storage capacity. As AD systems are often operated to maximise biogas production, these results highlight the need for multi-objective optimisation, particularly for off-grid AD systems."
89,89,Word representation using refined contexts,['Sep 2022'],https://pureportal.coventry.ac.uk/en/publications/word-representation-using-refined-contexts,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"In this paper, inspired from the idea that the contextual distances and positions may have a substantial impact on distinguishing the relationships between words, a novel word association method with two weighting schemes for refining contexts, named as Weighted Point-wise Mutual Information with Contextual Distances and Positions (PMIDP), is proposed to eliminate the noisy and redundant information hidden in an imbalanced corpus. One weighting scheme, called PMIpdistp, revises the Point-wise Mutual Information (PMI) method by scaling the co-occurrence counts according to the distance between a word and the context. The second weighting scheme is a ratio that can measure the contextual position variation within the window of a given word. Then, the refined word association in PMIDP is defined as the multiplication of the two proposed weighting schemes, which essentially aims to flexibly adjust the word association when solving target-oriented similarity tasks. The proposed word association method has been applied on two widely known models, i.e., the positive PMI matrix with truncated Singular Vector Decomposition (PPMI-SVD) model and the Global Vectors (GloVe) model. Experimental results demonstrate that the PMIDP method can significantly improve the performances of the two models on both semantic and relational similarity tasks and show advantages when compared with other state-of-the-art models."
90,90,Access Point Selection Strategies for Indoor 5G Millimeter-Wave Distributed Antenna Systems,['27 Apr 2021'],https://pureportal.coventry.ac.uk/en/publications/access-point-selection-strategies-for-indoor-5g-millimeter-wave-d,"['Yoo, S. K.']",['https://pureportal.coventry.ac.uk/en/persons/seongki-yoo'],"In this paper, we study the use of three candidate Access Point (AP) selection mechanisms for use with indoor millimetre-wave (mmWave) Distributed Antenna Systems (DASs). These are per-sample random AP selection, one-shot AP selection and per-sample optimal AP selection. To facilitate our analysis, we used a customized measurement system operating at 60 GHz, to record the signal power time series simultaneously received at 9 ceiling mounted AP locations while a mobile user imitating a voice call application. Using the time series data, the localized cross correlation coefficient (CCC) was subsequently estimated from the raw received signal strength (RSS) using the Spearman's rank-order correlation. It was found that the resultant time series of the localized CCCs was well-described by the Gaussian distribution across all of the considered measurement scenarios. Moreover, it was observed that the line-of-sight (LOS) and quasi-LOS (QLOS) paths typically led to higher CCC values with broader spreads than the non-LOS (NLOS) scenarios. To study the potential for signal enhancement by using diversity combining in mmWave DASs, we applied selection combining, equal gain combining and maximal ratio combining before investigating the AP selection mechanisms. Finally, we provide some useful insights into the influence of differing AP numbers on the diversity gain when considering the aforementioned AP selection methods."
91,91,Adversarial Learning on Incomplete and Imbalanced Medical Data for Robust Survival Prediction of Liver Transplant Patients,['24 May 2021'],https://pureportal.coventry.ac.uk/en/publications/adversarial-learning-on-incomplete-and-imbalanced-medical-data-fo,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"The scarcity of liver transplants necessitates prioritizing patients based on their health condition to minimize deaths on the waiting list. Recently, machine learning methods have gained popularity for automatizing liver transplant allocation systems, which enables prompt and suitable selection of recipients. Nevertheless, raw medical data often contain complexities such as missing values and class imbalance that reduce the reliability of the constructed model. This paper aims at eliminating the respective challenges to ensure the reliability of the decision-making process. To this aim, we first propose a novel deep learning method to simultaneously eliminate these challenges and predict the patients' survival chance. Secondly, a hybrid framework is designed that contains three main modules for missing data imputation, class imbalance learning, and classification, each of which employing multiple advanced techniques for the given task. Furthermore, these two approaches are compared and evaluated using a real clinical case study. The experimental results indicate the robust and superior performance of the proposed deep learning method in terms of F-measure and area under the receiver operating characteristic curve (AUC). "
92,92,A full-parallel implementation of Self-Organizing Maps on hardware,['Nov 2021'],https://pureportal.coventry.ac.uk/en/publications/a-full-parallel-implementation-of-self-organizing-maps-on-hardwar,"['Gaura, E.']",['https://pureportal.coventry.ac.uk/en/persons/elena-gaura'],"Self-Organizing Maps (SOMs) are extensively used for data clustering and dimensionality reduction. However, if applications are to fully benefit from SOM based techniques, high-speed processing is demanding, given that data tends to be both highly dimensional and yet “big”. Hence, a fully parallel architecture for the SOM is introduced to optimize the system’s data processing time. Unlike most literature approaches, the architecture proposed here does not contain sequential steps - a common limiting factor for processing speed. The architecture was validated on FPGA and evaluated concerning hardware throughput and the use of resources. Comparisons to the state of the art show a speedup of 8.91x over a partially serial implementation, using less than 15% of hardware resources available. Thus, the method proposed here points to a hardware architecture that will not be obsolete quickly."
93,93,A hybrid framework for brain tissue segmentation in magnetic resonance images,['Dec 2021'],https://pureportal.coventry.ac.uk/en/publications/a-hybrid-framework-for-brain-tissue-segmentation-in-magnetic-reso,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Having a robust image segmentation strategy is very important in magnetic resonance image (MRI) processing for an effective and early disease detection and diagnosis. Since MRI can present tissues of interest in both morphological and functional images, various segmentation techniques have been employed for this. The algorithms based on Markov random field (MRF) have shown strong abilities in dealing with noisy image segmentation compared to other methods. In this article, inspired by the random drift particle swarm optimization (RDPSO) algorithm, we propose a novel hybrid framework based on a combination of the RDPSO with the hidden MRF model and the expectation–maximization algorithm (HMRF-EM), to be used for MRI segmentation in real-time environments. The proposed hybrid framework is compared with the standalone HMRF-EM method, two other MRF-based stochastic relaxation algorithms, and two widely used brain tissue segmentation toolboxes on both simulated and real MRI datasets. The experimental results prove that the proposed hybrid framework can obtain better segmentation results than most of its competitors and has faster convergence speed than the compared stochastic optimization algorithms."
94,94,A hybrid framework for detecting and eliminating cyber-attacks in power grids,['15 Sep 2021'],https://pureportal.coventry.ac.uk/en/publications/a-hybrid-framework-for-detecting-and-eliminating-cyber-attacks-in,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"The work described in this paper aims to detect and eliminate cyber-attacks in smart grids that disrupt the process of dynamic state estimation. This work makes use of an unsupervised learning method, called hierarchical clustering, in an attempt to create an artificial sensor to detect two different cyber-sabotage cases, known as false data injection and denial-of-service, during the dynamic behavior of the power system. The detection process is conducted by using an unsupervised learning-enhanced approach, and a decision tree regressor is then employed for removing the threat. The dynamic state estimation of the power system is done by Kalman filters, which provide benefits in terms of the speed and accuracy of the process. Measurement devices in utilities and buses are vulnerable to communication interruptions between phasor measurement units and operators, who can be easily manipulated by false data. While Kalman filters are incapable of detecting the majority of such cyber-attacks, this article proves that the proposed unsupervised machine learning method is able to detect more than 90 percent of the mentioned attacks. The simulation results on the IEEE 9-bus with 3-machines and IEEE 14-bus with 5-machines systems verify the efficiency of the proposed approach."
95,95,A Jump-Markov Regularized Particle Filter for the estimation of ambiguous sensor faults,['14 Apr 2021'],https://pureportal.coventry.ac.uk/en/publications/a-jump-markov-regularized-particle-filter-for-the-estimation-of-a,"['Horri, N.', 'Brusey, J.']","['https://pureportal.coventry.ac.uk/en/persons/nadjim-horri', 'https://pureportal.coventry.ac.uk/en/persons/james-brusey']","Sensor or actuator faults occurring on a Unmanned Aerial Vehicle (UAV) can compromise the system integrity.pFault diagnosis methods is then becoming a required feature for those systems.pIn this paper, the focus is on fault estimation for a fixed-wing UAVs in the presence of simultaneous sensor faults.pThe altitude measurements of a UAV are commonly obtained from the combination of two different types of sensors: a Global Navigation Satellite System (GNSS) receiver and a barometer.pBoth sensors are subject to additive abrupt faults.pTo deal with the multimodal nature of the faulty modes, a Jump-Markov Regularized Particle Filter (JMRPF) is proposed in this paper to estimate the barometric altitude and GNSS altitude measurement faults, including the case when both faults occur simultaneously.pThis method is based on a regularization step that improves the robustness thanks to the approximation of the conditional density by a kernel mixture.pIn addition, the new jump strategy estimates the correct failure mode in 100% of the 100 simulations performed in this paper.pThis approach is compared with an Interacting Multiple Model Kalman Filter (IMM-KF) and the results show that the JMRPF outperforms the IMM-KF approach, particularly in the ambiguous case when both sensors are simultaneously subject to additive abrupt faults."
96,96,Analysis of standalone solar streetlights for improved energy access in displaced settlements,['Nov 2021'],https://pureportal.coventry.ac.uk/en/publications/analysis-of-standalone-solar-streetlights-for-improved-energy-acc,"['Nixon, J.', 'Halford, A.', 'Gaura, E.']","['https://pureportal.coventry.ac.uk/en/persons/jonathan-nixon', 'https://pureportal.coventry.ac.uk/en/persons/alison-halford', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura']","This paper examines the gap between the design and in-situ performance of solar streetlight interventions in two humanitarian settings. Displaced settlements often lack street lighting and electricity. Given that off-grid solar streetlights produce surplus energy, we hypothesized that this energy could be made available for daily usage, to improve system performance and provide further energy access to displaced populations. We recognize, however, that solar streetlight performance and longevity have typically been poor in remote and refugee settings. Eleven solar streetlights were fitted with ground-level sockets and their performance monitored, in two displaced settlements: a refugee camp in Rwanda and an internally displaced population settlement in Nepal. Considerable performance gaps were found across all eleven systems. Inefficient lights and mismatching system components were major issues at both sites, reducing targeted designed performance ratios by 33% and 53% on average in Rwanda and Nepal, respectively. The challenges of deploying these types of systems in temporary settlements are outlined and a number of suggestions are made to guide future developments in the design and implementation of sustainable solar streetlight interventions."
97,97,An Empirical Study of Span Modeling in Science NER,['7 Sep 2021'],https://pureportal.coventry.ac.uk/en/publications/an-empirical-study-of-span-modeling-in-science-ner,"['Jiang, X.']",['https://pureportal.coventry.ac.uk/en/persons/xiaorui-jiang'],"Little evaluation has been performed on the many modeling options for span-based approaches. This paper investigates the performances of a wide range of span and context representation methods and their combinations with a focus on scientific named entity recognition (science NER). While some most common classical span encodings and their combination prove to be effective, few conclusions can be derived to context representations."
98,98,A New Fuzzy Knowledge-Based Optimisation System for Management of Container Yard Operations,['26 Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/a-new-fuzzy-knowledge-based-optimisation-system-for-management-of,"['Al Bazi, A.', 'Palade, V.']","['https://pureportal.coventry.ac.uk/en/persons/ammar-al-bazi', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade']","Managing the container yard operations can be challenging as a result of various uncertainties associated with storing and retrieving containers from the yard. These associated uncertainties occur because the arrival of a truck to pick up the container is random, so the departure time of the container is unknown. The problem investigated in this paper emerges when newly arrived containers of different sizes, types and weights require storage operation in the same yard where other containers have already been stored. This situation becomes more challenging when the time of departure of existing container is not known. This study develops a new Fuzzy Knowledge-Based optimisation system named ‘FKB_GA’ for optimal storage and retrieval of containers in a yard that contains long stay pre-existing containers. The containers’ duration of stay factor is considered along with two other factors such as the similarity (containers with same customer) and the quantity of containers per stack.pA new Multi-Layered Genetic Algorithm module is proposed which identifies the optimal fuzzy rules required for each set of fired rules to achieve a minimum number of container re-handlings when selecting a stack. An industrial case study is used to demonstrate the applicability and practicability of the developed system. "
99,99,A New Method for Semi-Supervised Segmentation of Satellite Images,['Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/a-new-method-for-semi-supervised-segmentation-of-satellite-images,"['Sharifzadeh, S.']",['https://pureportal.coventry.ac.uk/en/persons/sara-sharifzadeh'],"Satellite image segmentation is an important topic in many domains. This paper introduces a novel semi-supervised image segmentation method for satellite image segmentation. Unlike the semantic segmentation strategies, this method requires only limited labelled data from small local patches of satellite images. Due to the complexity and large number of land cover objects in satellite images, a fixed-size square window is used for feature extraction from 7 different local areas. The local features are extracted by spectral domain analysis. Then, classification is performed based on similarity of the local features to those of thep7 labelled patches. This also allows efficient selection of the suitable window scale. Furthermore, the labeled features remove the need for iterative clustering for decision making about features. The labelled data also allows learning a subspace of transformed features for segmentation of water and green area based on simple thresholding. Comparison of the segmentation results using thepproposed strategy compared to unsupervised techniques such as k-means clustering and Superpixel-based Fast Fuzzy C-Means Clustering (SFFCM) shows the superiority of the proposed strategy in terms of content-based segmentation."
100,100,An Improved Fuzzy Knowledge-Based Model For Long Stay Container Yards,['10 Jun 2021'],https://pureportal.coventry.ac.uk/en/publications/an-improved-fuzzy-knowledge-based-model-for-long-stay-container-y,"['Al Bazi, A.', 'Palade, V.']","['https://pureportal.coventry.ac.uk/en/persons/ammar-al-bazi', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade']","This paper considers the problem of allocating newly arrived containers to stacks of existing containers in a yard  when the departure date/time for containers is unknown. Many factors and constraints need to be considered  when modelling this storage allocation problem. These constraints include the size, type and weight of the  containers. The factors are the number of containers in a stack and the duration of stay of the topmost container  in the stack. This paper aims to develop an improved Fuzzy Knowledge-Based ‘FKB’ model for best allocation ppractice of long-stay containers in a yard. In this model, the duration of stay factor does not need to be considered  in the allocation decision if the duration of stay for the topmost containers in a stack is similar; hence, a new  ‘ON/OFF’ strategy is proposed within the Fuzzy Knowledge-Based model to activate/deactivate this factor in the  stacking algorithm whenever is required. Discrete Event Simulation and Fuzzy Knowledge-Based techniques are used to develop the proposed model. The model’s behaviour is tested using three real-life scenarios, including  allocating containers in busy, moderately busy and quiet yards. The total number of re-handlings, the number of re-handlings per stack, and the number of re-handlings for containers were considered KPIs in each scenario. "
101,101,A probabilistic predictive model for assessing the economic reusability of load-bearing building components: Developing a Circular Economy framework,['Jul 2021'],https://pureportal.coventry.ac.uk/en/publications/a-probabilistic-predictive-model-for-assessing-the-economic-reusa,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"The reuse of load-bearing building components has the potential to promote the circular economy in the building sector. One recent aspect of the efforts to improve reuse rates in buildings is estimating the reusability of the structural elements. This study develops a probabilistic predictive model using advanced supervised machine learning methods to evaluate the economic reusability of the load-bearing building elements. The results of sensitivity analysis and visualization techniques used in this study reveal that the most important economic factor is the need to purchase reused elements early in a project, which could have cash flow implications. The other most important factors are the potential financial risks, the procurement process, and the labour cost. This study unveils that the relationship between variables is not linear, and none of the identified factors could alone determine if an element is reusable or not. This study concludes that the complex interdependencies of factors affecting reuse cause a high level of uncertainty about the feasibility of reusing the load-bearing building structural components from an economic aspect. Nonetheless, this paper reveals that by using the probability theory foundations and combining it with advanced supervised machine learning methods, it is possible to develop tools that could reliably estimate the economic reusability of these elements based on affecting variables. Therefore, the authors suggest utilizing the approach developed in this research to promote the circularity of materials in different subsectors of the construction industry."
102,102,A Quaternion Gated Recurrent Unit Neural Network for Sensor Fusion,['9 Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/a-quaternion-gated-recurrent-unit-neural-network-for-sensor-fusio,"['Palade, V.', 'Christopoulos, S.']","['https://pureportal.coventry.ac.uk/en/persons/vasile-palade', 'https://pureportal.coventry.ac.uk/en/persons/stavros-christopoulos']","Recurrent Neural Networks (RNNs) are known for their ability to learn relationships within temporal sequences. Gated Recurrent Unit (GRU) networks have found use in challenging time-dependent applications such as Natural Language Processing (NLP), financial analysis and sensor fusion due to their capability to cope with the vanishing gradient problem. GRUs are also known to be more computationally efficient than their variant, the Long Short-Term Memory neural network (LSTM), due to their less complex structure and as such, are more suitable for applications requiring more efficient management of computational resources. Many of such applications require a stronger mapping of their features to further enhance the prediction accuracy. A novel Quaternion Gated Recurrent Unit (QGRU) is proposed in this paper, which leverages the internal and external dependencies within the quaternion algebra to map correlations within and across multidimensional features. The QGRU can be used to efficiently capture the inter- and intra-dependencies within multidimensional features unlike the GRU, which only captures the dependencies within the sequence. Furthermore, the performance of the proposed method is evaluated on a sensor fusion problem involving navigation in Global Navigation Satellite System (GNSS) deprived environments as well as a human activity recognition problem. The results obtained show that the QGRU produces competitive results with almost 3.7 times fewer parameters compared to the GRU. The QGRU code is available at https://github.com/onyekpeu/Quarternion-Gated-Recurrent-Unit."
103,103,A Review on Collision Avoidance Systems for Unmanned Aerial Vehicles,['7 Dec 2021'],https://pureportal.coventry.ac.uk/en/publications/a-review-on-collision-avoidance-systems-for-unmanned-aerial-vehic,"['Yoo, S.']",['https://pureportal.coventry.ac.uk/en/persons/seongki-yoo'],"The unmanned Aerial Vehicles (UAV) concept has attracted the attention of both academia and industry as an alternative to reduce the traffic congestion limitation. To coordinate the UAVs located in the sky, also called drones, the concept of the Internet of Drones (IoD) was introduced as overall coordination of UAVs in the sky. IoD paradigm offers a wide range of applications mainly targeting the military and civilian environments. Some of those applications include transportation, agriculture-based systems, entertainment, weather monitoring, healthcare systems, and road hazards monitoring. However, once an area is highly congested by a various number of drones, dynamic or statics obstacles can hinder the overall performance of drones. In order to avoid those obstacles, one of the proposed solutions is to apply collision avoidance techniques while the drones are on duty. In this paper, we present a brief survey of collision avoidance systems for the internet of drones. We have reviewed the current literature review ranging from the year 2010 to 2021. This work has taken into consideration two main frequently used databases in academia: Xplore for IEEE and ScienceDirect for Elsevier. After article selection, some articles were retained and discussed. A detailed discussion and analysis of selected articles were made while most of the techniques used in collision avoidance systems include video-based systems and swarm-based intelligence approaches. Furthermore, the paper discusses the different approaches which are used to design collision avoidance systems. Finally, this paper provides concluding remarks and future research orientation that will mainly focus on AI-based algorithms applied in collision avoidance systems."
104,104,A survey of empirical performance evaluation of permissioned blockchain platforms: Challenges and opportunities,['25 Jan 2021'],https://pureportal.coventry.ac.uk/en/publications/a-survey-of-empirical-performance-evaluation-of-permissioned-bloc,[],[],"Blockchain-based platforms, particularly those based on permissioned blockchain, are increasingly popular in a broad range of settings. In addition to security and privacy concerns, organizations seeking to implement such platforms also need to consider performance, especially in latency- or delay-sensitive applications. Performance is generally less studied in comparison to security and privacy, and therefore in this paper we survey existing empirical performance evaluations of different permissioned blockchain platforms published between 2015 and 2019, using a comparative framework. The framework comprises ten criteria. We then conclude the paper with a number of potential future research directions."
105,105,"A Time Series Based Study of Correlation, Channel Power Imbalance and Diversity Gain in Indoor Distributed Antenna Systems at 60 GHz",['1 Nov 2021'],https://pureportal.coventry.ac.uk/en/publications/a-time-series-based-study-of-correlation-channel-power-imbalance-,"['Yoo, S. K.']",['https://pureportal.coventry.ac.uk/en/persons/seongki-yoo'],"In this article, we investigate the potential enhancements in signal reliability which can be achieved using a millimeter-wave distributed antenna system (DAS) within an indoor environment. To achieve this, we measured the signal power simultaneously received at nine ceiling-mounted access point (AP) locations likely to be used in future indoor DAS deployments while a mobile user imitated making a voice call on a hypothetical user equipment. Key metrics, associated with the performance of multiple antenna systems, such as the cross correlation coefficient (CCC) and channel power imbalance (CPI) are determined. It was found that line-of-sight (LOS) and quasi-LOS (QLOS) links with the APs typically led to higher CCC values than the non-LOS (NLOS) cases. Similarly, LOS and QLOS links typically produced higher CPI values between APs than the NLOS case. To enable the reproduction of our results, we have successfully applied autoregressive moving average and autoregressive integrated moving average modeling to the CCC and CPI time series. The performance improvement that can be achieved using a DAS instead of a single AP was evaluated using three commonly deployed diversity combining schemes, namely, selection combining, equal gain combining, and maximal ratio combining along with three AP selection mechanisms, namely, per-sample random AP selection, one-shot AP selection, and per-sample optimal AP selection. Finally, we have provided some useful insight into the influence of differing AP numbers on the diversity gain when considering the aforementioned AP selection methods."
106,106,Bispectrum-based Cross-frequency Functional Connectivity: A Study of Alzheimer’s Disease,['8 Aug 2021'],https://pureportal.coventry.ac.uk/en/publications/bispectrum-based-cross-frequency-functional-connectivity-a-study-,"['Klepl, D.', 'He, F.']","['https://pureportal.coventry.ac.uk/en/persons/dominik-klepl', 'https://pureportal.coventry.ac.uk/en/persons/fei-he']","Alzheimer’s disease (AD) is a neurodegenerative disorder known to affect functional connectivity (FC) across many brain regions. Linear FC measures have been applied to study the differences in AD by splitting neurophysiological signals such as electroencephalography (EEG) recordings into discrete frequency bands and analysing them in isolation from each other. We address this limitation by quantifying cross-frequency FC in addition to the traditional within-band approach. Cross-bispectrum, a higher-order spectral analysis approach, is used to measure the nonlinear FC and is compared with the cross-spectrum, which only measures the linear FC within bands. This work reports the first use of cross-bispectrum to reconstruct a cross-frequency FC network where each frequency band is treated as a layer in a multilayer network with both inter- and intra-layer edges. An increase of within-band FC in AD is observed in low-frequency bands using both methods. Bispectrum also detects multiple cross-frequency differences, mainly increased FC in AD in delta-theta coupling. An increased importance of low-frequency coupling and decreased importance of high-frequency coupling is observed in AD. Integration properties of AD networks are more vulnerable than HC, while the segregation property is maintained in AD. Moreover, the segregation property of γ is less vulnerable in AD, suggesting the shift of importance from high-frequency activity towards low-frequency components. The results highlight the importance of studying nonlinearity and including cross-frequency FC in characterising AD. Moreover, the results demonstrate the advantages and limitations of using bispectrum to reconstruct FC networks."
107,107,"Blockchain and smart contract for access control in healthcare: A survey, issues and challenges, and open issues",['15 Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/blockchain-and-smart-contract-for-access-control-in-healthcare-a-,[],[],"Emerging technologies are playing a critical role in the evolution of healthcare systems by presenting eHealth to provide high-quality services and better health to wide-range of patients. Achieving the eHealth goals highly depends on employing modern information and communication technologies (ICTs) to securely and efficiently collect and transmit electronic health records (EHRs) and make them accessible to authorized users and healthcare providers. However, the adoption of EHRs in healthcare providers puts the patients’ privacy and their information security at risk of data breaches. The advent of smart contracts and blockchain technology paves a way for developing efficient EHR access control methods to support secure identification, authentication, and authorization of the clients. This paper delineates an extensive survey on the state-of-the-art blockchain-based access control methods in healthcare domain as a basis for categorizing the existing and future developments in access control area. A thematic taxonomy of the blockchain-based access control methods is also presented to recognize the security issues of the existing methods and highlight the fundamental security requirements to design a granular access control method. This paper also aims for examining the similarities and differences of the traditional access control methods and describes some substantial and outstanding issues and challenges as further directions."
108,108,Building Capacity: HEED Skills Audit and Recommendations:  HEED Skills Audit and Recommendations,['24 Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/building-capacity-heed-skills-audit-and-recommendations-heed-skil,"['Halford, A.']",['https://pureportal.coventry.ac.uk/en/persons/alison-halford'],"This report aims to explore how HEED approached and delivered capacity building for the research team, project partners and the communities the team worked within Rwanda and Nepal.[i] This report’s purpose is threefold: first, to be evidential on how HEED planned, delivered and captured impact around capacity building so similar projects can develop best practice when skills development is a key deliverable. Second, to encourage other energy projects to document the impact produced by researchers and practitioners’ involvement while working with communities. Therefore, to recognise the tacit and dynamic aspects of knowledge production, not only the more explicit aspects. Third, suggest recommendations to support a skills-led approach to capacity building that provides personal and professional development opportunities to deepen knowledge production and impact."
109,109,Cell site analysis; use and reliability of survey methods,['Sep 2021'],https://pureportal.coventry.ac.uk/en/publications/cell-site-analysis-use-and-reliability-of-survey-methods,"['Tart, M. S.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-stephen-tart'],"An RF Survey may form part of a wider forensic strategy. The purpose of a survey within this strategy, and the manner in which survey data may be used to better inform evaluative or investigative opinion, is discussed. Hazards of using survey results in isolation of other information to produce a series of piecemeal technical observations (in isolation of each other and the wider purpose of the examination) are explored. Technical issues concerning measuring a complex radio environment, and methods to address those issues, are presented. Experiments comparing CDR (“ground truth” data) from a known location is compared to survey measurements focussed on that location. The performance of methods using engineering handset survey devices (Anite Nemo) is compared with that of Software Controlled Radio (QRC ICS-500) for these trial data. Assessments of uncertainty within the methods tested are made, including accuracy, precision and reliability."
110,110,Centralised and decentralised sensor fusion‐based emergency brake assist,['11 Aug 2021'],https://pureportal.coventry.ac.uk/en/publications/centralised-and-decentralised-sensor-fusionbased-emergency-brake-,"['Deo, A.', 'Palade, V.']","['https://pureportal.coventry.ac.uk/en/persons/ankur-deo', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade']","Many advanced driver assistance systems (ADAS) are currently trying to utilise multi-sensor architectures, where the driver assistance algorithm receives data from a multitude of sen-sors. As mono‐sensor systems cannot provide reliable and consistent readings under all circum-stances because of errors and other limitations, fusing data from multiple sensors ensures that the environmental parameters are perceived correctly and reliably for most scenarios, thereby substan-tially improving the reliability of the multi‐sensor‐based automotive systems. This paper first high-lights the significance of efficiently fusing data from multiple sensors in ADAS features. An emergency brake assist (EBA) system is showcased using multiple sensors, namely, a light detection and ranging (LiDAR) sensor and camera. The architectures of the proposed ‘centralised’ and ‘decentral-ised’ sensor fusion approaches for EBA are discussed along with their constituents, i.e., the detection algorithms, the fusion algorithm, and the tracking algorithm. The centralised and decentralised architectures are built and analytically compared, and the performance of these two fusion architectures for EBA are evaluated in terms of speed of execution, accuracy, and computational cost. While both fusion methods are seen to drive the EBA application at an acceptable frame rate (~20fps or higher) on an Intel i5‐based Ubuntu system, it was concluded through the experiments and analyt-ical comparisons that the decentralised fusion‐driven EBA leads to higher accuracy; however, it has the downside of a higher computational cost. The centralised fusion‐driven EBA yields compara-tively less accurate results, but with the benefits of a higher frame rate and lesser computational cost."
111,111,Characterising Alzheimer's Disease with EEG-based Energy Landscape Analysis,['19 Feb 2021'],https://pureportal.coventry.ac.uk/en/publications/characterising-alzheimers-disease-with-eeg-based-energy-landscape,"['Klepl, D.', 'He, F.']","['https://pureportal.coventry.ac.uk/en/persons/dominik-klepl', 'https://pureportal.coventry.ac.uk/en/persons/fei-he']","Alzheimer's disease (AD) is one of the most common neurodegenerative diseases, with around 50 million patients worldwide. Accessible and non-invasive methods of diagnosing and characterising AD are therefore urgently required. Electroencephalography (EEG) fulfils these criteria and is often used when studying AD. Several features derived from EEG were shown to predict AD with high accuracy, e.g. signal complexity and synchronisation. However, the dynamics of how the brain transitions between stable states have not been properly studied in the case of AD and EEG data. Energy landscape analysis is a method that can be used to quantify these dynamics. This work presents the first application of this method to both AD and EEG. Energy landscape assigns energy value to each possible state, i.e. pattern of activations across brain regions. The energy is inversely proportional to the probability of occurrence. By studying the features of energy landscapes of 20 AD patients and 20 healthy age-matched counterparts, significant differences were found. The dynamics of AD patients' brain networks were shown to be more constrained - with more local minima, less variation in basin size, and smaller basins. We show that energy landscapes can predict AD with high accuracy, performing significantly better than baseline models. "
112,112,Critical behavior of magnetic polymers in two and three dimensions,['16 Aug 2021'],https://pureportal.coventry.ac.uk/en/publications/critical-behavior-of-magnetic-polymers-in-two-and-three-dimension,[],[],"We explore the critical behavior of two- and three-dimensional lattice models of polymers in dilute solution where the monomers carry a magnetic moment which interacts ferromagnetically with near-neighbor monomers. Specifically, the model explored consists of a self-avoiding walk on a square or cubic lattice with Ising spins on the visited sites. In three dimensions we confirm and extend previous numerical work, showing clearly the first-order character of both the magnetic transition and the polymer collapse, which happen together. We present results in two dimensions, where the transition is seen to be continuous. Finite-size scaling is used to extract estimates for the critical exponents and the transition temperature in the absence of an external magnetic field."
113,113,CSI-COP Policy Brief 1: How Citizen Science Can Add Value to Investigate Compliance of the General Data Protection Regulation (GDPR). ,['30 Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/csi-cop-policy-brief-1-how-citizen-science-can-add-value-to-inves,"['Shah, H.']",['https://pureportal.coventry.ac.uk/en/persons/huma-shah'],"Online tracking is out of control. The first policy brief in the EU Horizon2020 funded CSI-COP project recommends that EU funded projects should be required to set-up privacy-by design project websites and/or apps with tracking made transparent, especially by any third-party."
114,114,CSI-COP - 'Your Right to Privacy Online',['2021'],https://pureportal.coventry.ac.uk/en/publications/csi-cop-your-right-to-privacy-online,"['Shah, H.', 'Winter, J.']","['https://pureportal.coventry.ac.uk/en/persons/huma-shah', 'https://pureportal.coventry.ac.uk/en/persons/jaimz-winter']","Online tracking is out of control. The first policy brief in the EU Horizon2020 funded CSI-COP project recommends that EU funded projects should be required to set-up privacy-by design project websites and/or apps with tracking made transparent, especially by any third-party."
115,115,Deciding the consistency of non-linear real arithmetic constraints with a conflict driven search using cylindrical algebraic coverings,['Feb 2021'],https://pureportal.coventry.ac.uk/en/publications/deciding-the-consistency-of-non-linear-real-arithmetic-constraint,"['England, M.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-england'],"We present a new algorithm for determining the satisfiability of conjunctions of non-linear polynomial constraints over the reals, which can be used as a theory solver for satisfiability modulo theory (SMT) solving for non-linear real arithmetic. The algorithm is a variant of Cylindrical Algebraic Decomposition (CAD) adapted for satisfiability, where solution candidates (sample points) are constructed incrementally, either until a satisfying sample is found or sufficient samples have been sampled to conclude unsatisfiability. The choice of samples is guided by the input constraints and previous conflicts. The key idea behind our new approach is to start with a partial sample; demonstrate that it cannot be extended to a full sample; and from the reasons for that rule out a larger space around the partial sample, which build up incrementally into a cylindrical algebraic covering of the space. There are similarities with the incremental variant of CAD, the NLSAT method of Jovanović and de Moura, and the NuCAD algorithm of Brown; but we present worked examples and experimental results on a preliminary implementation to demonstrate the differences to these, and the benefits of the new approach."
116,116,Diversity collaboratively guided random drift particle swarm optimization,['13 Jul 2021'],https://pureportal.coventry.ac.uk/en/publications/diversity-collaboratively-guided-random-drift-particle-swarm-opti,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"The random drift particle swarm optimization (RDPSO) algorithm is an effective random search technique inspired by the trajectory analysis of the canonical PSO and the free electron model in metal conductors placed in an external electric field. However, like other PSO variants, the RDPSO algorithm also inevitably encounters premature convergence when solving multimodal problems. To address this issue, this paper proposes a novel diversity collaboratively guided (DCG) strategy for the RDPSO algorithm that enhances the search ability of the algorithm. In this strategy, two kinds of diversity measures are defined and modified in a collaborative manner. Specifically, the whole search process of the RDPSO is divided into three phases based on the changes in the two diversity measures. In each phase, different values are selected for the key parameters of the update equation in the RDPSO to make the particle swarm perform different search modes. Consequently, the improved RDPSO algorithm with the DCG strategy (DCG-RDPSO) can maintain its diversity dynamically at a certain level, and thus can search constantly without stagnation until the search process terminates. The performance evaluation of the proposed algorithm is done on the CEC-2013 benchmark suite, in comparison with several versions of RDPSO, different variants of PSO and several non-PSO evolutionary algorithms. Experimental results show that the proposed DCG strategy can significantly improve the performance and robustness of the RDPSO algorithm for most of the multimodal problems. Further experiments on economic dispatch problems also verify the effectiveness of the DCG strategy."
117,117,DMO-QPSO: A multi-objective quantum-behaved particle swarm optimization algorithm based on decomposition with diversity control,['16 Aug 2021'],https://pureportal.coventry.ac.uk/en/publications/dmo-qpso-a-multi-objective-quantum-behaved-particle-swarm-optimiz,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"The decomposition-based multi-objective evolutionary algorithm (MOEA/D) has shown remarkable effectiveness in solving multi-objective problems (MOPs). In this paper, we integrate the quantum-behaved particle swarm optimization (QPSO) algorithm with the MOEA/D framework in order to make the QPSO be able to solve MOPs effectively, with the advantage of the QPSO being fully used. We also employ a diversity controlling mechanism to avoid the premature convergence especially at the later stage of the search process, and thus further improve the performance of our proposed algorithm. In addition, we introduce a number of nondominated solutions to generate the global best for guiding other particles in the swarm. Experiments are conducted to compare the proposed algorithm, DMO-QPSO, with four multi-objective particle swarm optimization algorithms and one multi-objective evolutionary algorithm on 15 test functions, including both bi-objective and tri-objective problems. The results show that the performance of the proposed DMO-QPSO is better than other five algorithms in solving most of these test problems. Moreover, we further study the impact of two different decomposition approaches, i.e., the penalty-based boundary intersection (PBI) and Tchebycheff (TCH) approaches, as well as the polynomial mutation operator on the algorithmic performance of DMO-QPSO."
118,118,Economic Evaluation of Mental Health Effects of Flooding Using Bayesian Networks,['13 Jul 2021'],https://pureportal.coventry.ac.uk/en/publications/economic-evaluation-of-mental-health-effects-of-flooding-using-ba,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"The appraisal of appropriate levels of investment for devising flooding mitigation and to support recovery interventions is a complex and challenging task. Evaluation must account for social, political, environmental and other conditions, such as flood state expectations and local priorities. The evaluation method should be able to quickly identify evolving investment needs as the incidence and magnitude of flood events continue to grow. Quantification is essential and must consider multiple direct and indirect effects on flood related outcomes. The method proposed is this study is a Bayesian network, which may be used ex-post for evaluation, but also ex-ante for future assessment, and near real-time for the reallocation of investment into interventions. The particular case we study is the effect of flood interventions upon mental health, which is a gap in current investment analyses. Natural events such as floods expose people to negative mental health disorders including anxiety, distress and post-traumatic stress disorder. Such outcomes can be mitigated or exacerbated not only by state funded interventions, but by individual and community skills and experience. Success is also dampened when vulnerable and previously exposed victims are affected. Current measures evaluate solely the effectiveness of interventions to reduce physical damage to people and assets. This paper contributes a design for a Bayesian network that exposes causal pathways and conditional probabilities between interventions and mental health outcomes as well as providing a tool that can readily indicate the level of investment needed in alternative interventions based on desired mental health outcomes."
119,119,Efficient activity recognition using lightweight CNN and DS-GRU network for surveillance applications,['May 2021'],https://pureportal.coventry.ac.uk/en/publications/efficient-activity-recognition-using-lightweight-cnn-and-ds-gru-n,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Recognizing human activities has become a trend in smart surveillance that contains several challenges, such as performing effective analyses of huge video data streams, while maintaining low computational complexity, and performing this task in real-time. Current activity recognition techniques are using convolutional neural network (CNN) models with computationally complex classifiers, creating hurdles in obtaining quick responses for abnormal activities. To address these challenges in real-time surveillance, this paper proposes a lightweight deep learning-assisted framework for activity recognition. First, we detect a human in the surveillance stream using an effective CNN model, which is trained on two surveillance datasets. The detected individual is tracked throughout the video stream via an ultra-fast object tracker called the ‘minimum output sum of squared error’ (MOSSE). Next, for each tracked individual, pyramidal convolutional features are extracted from two consecutive frames using the efficient LiteFlowNet CNN. Finally, a novel deep skip connection gated recurrent unit (DS-GRU) is trained to learn the temporal changes in the sequence of frames for activity recognition. Experiments are conducted over five benchmark activity recognition datasets, and the results indicate the efficiency of the proposed technique for real-time surveillance applications compared to the state-of-the-art."
120,120,Efimov-DNA Phase diagram: three stranded DNA on a cubic lattice,['12 Aug 2021'],https://pureportal.coventry.ac.uk/en/publications/efimov-dna-phase-diagram-three-stranded-dna-on-a-cubic-lattice,[],[],"We define a generalized model for three-stranded DNA consisting of two chains of one type and a third chain of a different type. The DNA strands are modeled by random walks on the three-dimensional cubic lattice with different interactions between two chains of the same type and two chains of different types. This model may be thought of as a classical analog of the quantum three-body problem. In the quantum situation, it is known that three identical quantum particles will form a triplet with an infinite tower of bound states at the point where any pair of particles would have zero binding energy. The phase diagram is mapped out, and the different phase transitions are examined using finite-size scaling. We look particularly at the scaling of the DNA model at the equivalent Efimov point for chains up to 10 000 steps in length. We find clear evidence of several bound states in the finite-size scaling. We compare these states with the expected Efimov behavior."
121,121,EnSuRe: Energy & Accuracy Aware Fault-tolerant Scheduling on Real-time Heterogeneous Systems,['26 Jul 2021'],https://pureportal.coventry.ac.uk/en/publications/ensure-energy-amp-accuracy-aware-fault-tolerant-scheduling-on-rea,"['Kasap, S.']",['https://pureportal.coventry.ac.uk/en/persons/server-kasap'],"This paper proposes an energy efficient real-time scheduling strategy called EnSuRe, which (i) executes real-time tasks on low power consuming primary processors to enhance the system accuracy by maintaining the deadline and (ii) provides reliability against a fixed number of transient faults by selectively executing backup tasks on high power consuming backup processor. Simulation results reveal that EnSuRe consumes nearly 25% less energy, compared to existing techniques, while satisfying the fault tolerance requirements. EnSuRe is also able to achieve 75% system accuracy with 50% system utilisation. Further, the obtained simulation outcomes are validated on benchmark tasks via a fault injection framework on Xilinx ZYNQ APSoC heterogeneous dual core platform."
122,122,Evaluation of a Switched Combining Based Distributed Antenna System (DAS) for Pedestrian-to-Vehicle Communications,['5 Aug 2021'],https://pureportal.coventry.ac.uk/en/publications/evaluation-of-a-switched-combining-based-distributed-antenna-syst,"['Yoo, S.']",['https://pureportal.coventry.ac.uk/en/persons/seongki-yoo'],"The safety of vulnerable road users is paramount, particularly as we move towards the widespread adoption of autonomous and self-driving vehicles. In this study, we investigate the use of a six-element distributed antenna system (DAS), operating at 5.8 GHz and mounted on the exterior (i.e., roof and wing mirrors) of an automobile, to enhance signal reliability for pedestrian-to-vehicle (P2V) communications. Due to its low complexity and ease of implementation, we consider the use of a switch-and-examine combining with post-examining selection (SECps) scheme to combine the signal received by the DAS. During our experiments, a pedestrian wearing a wireless device on their chest either stood stationary or walked by the side of a road. It was found that the overall signal reliability depends on not only the number, but also different groupings of the antennas which are selected. The goodness-of-fit results have shown that the temporal behavior of the diversity gain was adequately described by the Gaussian distribution. Building upon this, we also provide some useful insights into the antenna selection through the comparison of three different antenna selection mechanisms, namely per-sample random antenna selection, one-shot antenna selection and per-sample optimal antenna selection."
123,123,Finding the Uncomfortable Solution: Responsible Innovation in Humanitarian Energy,['5 Oct 2021'],https://pureportal.coventry.ac.uk/en/publications/finding-the-uncomfortable-solution-responsible-innovation-in-huma,"['Halford, A.', 'Gaura, E.']","['https://pureportal.coventry.ac.uk/en/persons/alison-halford', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura']","In response to the increasing number of displaced people, the humanitarian sector is exploring innovation as a framework to improve the delivery of the Sustainable Development Goals (SDGs). Traditionally, the focus on camp settings and short term solutions have resulted in a humanitarian response that is slow to adapt to the rapidity of technological innovation (Betts and Bloom, 2014). For example, 87.8% of African’s in Sub-Saharan Africa have a mobile phone (World Bank, 2019), yet 80% of displaced people living in camps in this same region still cook over open fires which are linked to long term health and environmental effects (Grafham and Lahn, 2018).pAs a result of the lessons learned from the Humanitarian Engineering and Energy for Displacement (HEED) project around the different perceptions of innovation between key energy stakeholders, this paper looks to engage with questions around ensuring innovation in the humanitarian sector, and more specifically humanitarian energy, is responsible. How can we define responsible? Is responsible innovation a theoretical nicety or can it ensure a just energy transition as outlined by the SDGs? What does responsible innovation look like in reality? Building to our underlying research question: what is the state-of-the-art in responsible innovation for humanitarian energy and how is it implemented at project level?"
124,124,Generation of Pedestrian Crossing Scenarios Using Ped-Cross Generative Adversarial Network,['6 Jan 2021'],https://pureportal.coventry.ac.uk/en/publications/generation-of-pedestrian-crossing-scenarios-using-ped-cross-gener,"['Palade, V.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/vasile-palade', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","The safety of vulnerable road users is of paramount importance as transport moves towards fully automated driving. The richness of real-world data required for testing autonomous vehicles is limited and furthermore, available data do not present a fair representation of different scenarios and rare events. Before deploying autonomous vehicles publicly, their abilities must reach a safety threshold, not least with regards to vulnerable road users, such as pedestrians. In this paper, we present a novel Generative Adversarial Networks named the Ped-Cross GAN. Ped-Cross GAN is able to generate crossing sequences of pedestrians in the form of human pose sequences. The Ped-Cross GAN is trained with the Pedestrian Scenario dataset. The novel Pedestrian Scenario dataset, derived from existing datasets, enables training on richer pedestrian scenarios. We demonstrate an example of its use through training and testing the Ped-Cross GAN. The results show that the Ped-Cross GAN is able to generate new crossing scenarios that are of the same distribution from those contained in the Pedestrian Scenario dataset. Having a method with these capabilities is important for the future of transport, as it will allow for the adequate testing of Connected and Autonomous Vehicles on how they correctly perceive the intention of pedestrians crossing the street, ultimately leading to fewer pedestrian casualties on our roads. "
125,125,Generative adversarial network-based scheme for diagnosing faults in cyber-physical power systems,['30 Jul 2021'],https://pureportal.coventry.ac.uk/en/publications/generative-adversarial-network-based-scheme-for-diagnosing-faults,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"This paper presents a novel diagnostic framework for distributed power systems that is based on using generative adversarial networks for generating artificial knockoffs in the power grid. The proposed framework makes use of the raw data measurements including voltage, frequency, and phase-angle that are collected from each bus in the cyber-physical power systems. The collected measurements are firstly fed into a feature selection module, where multiple state-of-the-art techniques have been used to extract the most informative features from the initial set of available features. The selected features are inputs to a knockoff generation module, where the generative adversarial networks are employed to generate the corresponding knockoffs of the selected features. The generated knockoffs are then fed into a classification module, in which two different classification models are used for the sake of fault diagnosis. Multiple experiments have been designed to investigate the effect of noise, fault resistance value, and sampling rate on the performance of the proposed framework. The effectiveness of the proposed framework is validated through a comprehensive study on the IEEE 118-bus system."
126,126,Guest Editorial: Special Issue on Deep Representation and Transfer Learning for Smart and Connected Health,['4 Feb 2021'],https://pureportal.coventry.ac.uk/en/publications/guest-editorial-special-issue-on-deep-representation-and-transfer,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Deep neural networks (NNs) have been proved to be efficient learning systems for supervised and unsupervised tasks. However, learning complex data representations using deep NNs can be difficult due to problems such as lack of data, exploding or vanishing gradients, high computational cost, or incorrect parameter initialization, among others. Deep representation and transfer learning (RTL) can facilitate the learning of data representations by taking advantage of transferable features learned by an NN model in a source domain, and adapting the model to a new domain."
127,127,Improving Algebraic Tools to Study Bifurcation Sequences of Population Models,['14 Sep 2021'],https://pureportal.coventry.ac.uk/en/publications/improving-algebraic-tools-to-study-bifurcation-sequences-of-popul,"['Sadeghimanesh, A.', 'England, M.']","['https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh', 'https://pureportal.coventry.ac.uk/en/persons/matthew-england']","Since being introduced by Collins in the 1970s Cylindrical Algebraic Decomposition has found many applications. We focus on its use to decomposition the parameter space of a parametric system of polynomial equations, and possibly some polynomial inequality constraints, with respect to the number of real solutions that the system attains.  Previous studies simplify the CAD computation by first computing the discriminant variety of the system, which usually involves Gr¨obner Basis computation. However, on some even very small applied examples this itself can become expensive. Thus we consider development of new algorithms to reduce the complexity of this approach, by adopting numerical ideas and some recent technical developments in CAD theory. In this extended abstract we outline our recent progress as evaluated on an example from population dynamics with the Allee effect."
128,128,Improving skin cancer classification using heavy-tailed student t-distribution in generative adversarial networks (Ted-gan),['19 Nov 2021'],https://pureportal.coventry.ac.uk/en/publications/improving-skin-cancer-classification-using-heavy-tailed-student-t,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Deep learning has gained immense attention from researchers in medicine, especially in medical imaging. The main bottleneck is the unavailability of sufficiently large medical datasets required for the good performance of deep learning models. This paper proposes a new framework consisting of one variational autoencoder (VAE), two generative adversarial networks, and one auxiliary classifier to artificially generate realistic-looking skin lesion images and improve classification performance. We first train the encoder-decoder network to obtain the latent noise vector with the image manifold’s information and let the generative adversarial network sample the input from this informative noise vector in order to generate the skin lesion images. The use of informative noise allows the GAN to avoid mode collapse and creates faster convergence. To improve the diversity in the generated images, we use another GAN with an auxiliary classifier, which samples the noise vector from a heavy-tailed student t-distribution instead of a random noise Gaussian distribution. The proposed framework was named TED-GAN, with T from the t-distribution and ED from the encoder-decoder network which is part of the solution. The proposed framework could be used in a broad range of areas in medical imaging. We used it here to generate skin lesion images and have obtained an improved classification performance on the skin lesion classification task, rising from 66% average accuracy to 92.5%. The results show that TED-GAN has a better impact on the classification task because of its diverse range of generated images due to the use of a heavy-tailed t-distribution."
129,129,Investigating the effects of two fragrances on comfort in the automotive context,['8 Jan 2021'],https://pureportal.coventry.ac.uk/en/publications/investigating-the-effects-of-two-fragrances-on-comfort-in-the-aut,"['Brusey, J.']",['https://pureportal.coventry.ac.uk/en/persons/james-brusey'],"What is this the impact of olfactory and visual factors on overall comfort? Can these factors have an effect on the perception of thermal comfort? These questions are particularly interesting in the context of a vehicle car cabin, since it leads to the possibility of visual or olfactory cues being used to maintain passenger thermal comfort at a lower energy cost. In this work, human subject trials (n=47) were performed in a temperature-controlled environ-ment varying air temperature, ambient light (none, yellow, blue) and scent (neutral, peppermint, orange & cinna-mon). Multiple linear regression shows olfactory factors to have a larger effect on overall comfort perception than visual factors. Either scent improved thermal perception in a slightly cold environment, while only peppermint im-proved thermal perception in a slightly warm environment. These results suggest that the use of visual and olfac-tory factors have the potential to increase car cabin comfort and / or improve the energy efficiency of the car cli-mate system."
130,130,IoT-Enabled Light Intensity-Controlled Seamless Highway Lighting System,['Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/iot-enabled-light-intensity-controlled-seamless-highway-lighting-,"['Kurniawan, I. F.']",['https://pureportal.coventry.ac.uk/en/persons/ibnu-febry-kurniawan'],"Motivated by enormous highway-lighting energy consumption, smart lighting development is crucial to better manage available resources. While existing literature focused on ensuring cost-effective lighting, an equally important requirement, namely the visual comfort of motorists, is almost disregarded. This article proposes a novel Internet of Things-enabled system that can be intelligently controlled according to the traffic demand. Cooperative relay-network architecture is the central element that leverages upon placement of cyber-enabled lampposts to allow for sensing-exchanging highway traffic information. Data accumulation is exploited to automate adaptive switching on/off the lighting and provide backtracking detection of faulty lampposts. From the service provider's perspective, we envision to deploy low-cost highly durable sensing and network components to significantly cut down the operating cost. From the road user's perspective, the relay-network is envisaged to provide seamless driving experience where sufficient lighting is always perceived along the road. A critical analysis quantitatively evaluates the seamless driving experience considering car arrival rate, outage probability, and device malfunction probability. A road occupancy-based cost estimation analysis demonstrates the effective cost reduction of the proposal compared to existing systems. Furthermore, the performance of chosen communication modules under different setups is assessed through simulation, suggesting appropriate protocol for different highway traffic conditions."
131,131,IO-VNBD: Inertial and Odometry benchmark dataset for ground vehicle positioning,['Apr 2021'],https://pureportal.coventry.ac.uk/en/publications/io-vnbd-inertial-and-odometry-benchmark-dataset-for-ground-vehicl-2,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Low-cost Inertial Navigation Sensors (INS) can be exploited for a reliable solution for tracking autonomous vehicles in the absence of GPS signals. However, position errors grow exponentially over time due to noises in the sensor measurements. The lack of a public and robust benchmark dataset has however hindered the advancement in the research, comparison and adoption of recent machine learning techniques such as deep learning techniques to learn the error in the INS for a more accurate positioning of the vehicle. In order to facilitate the benchmarking, fast development and evaluation of positioning algorithms, we therefore present the first of its kind large-scale and information-rich inertial and odometry focused public dataset called IO-VNBD (Inertial Odometry Vehicle Navigation Benchmark Dataset). The vehicle tracking dataset was recorded using a research vehicle equipped with ego-motion sensors on public roads in the United Kingdom, Nigeria, and France. The sensors include a GPS receiver, inertial navigation sensors, wheel-speed sensors amongst other sensors found in the car, as well as the inertial navigation sensors and GPS receiver in an Android smart phone sampling at 10 Hz. A diverse number of driving scenarios were captured such as traffic congestion, round-abouts, hard-braking, etc. on different road types (e.g. country roads, motorways, etc.) and with varying driving patterns. The dataset consists of a total driving time of about 40 h over 1,300 km for the vehicle extracted data and about 58 h over 4,400 km for the smartphone recorded data. We hope that this dataset will prove valuable in furthering research on the correlation between vehicle dynamics and dependable positioning estimation based on vehicle ego-motion sensors, as well as other related studies."
132,132,Learning to localise automated vehicles in challenging environments using inertial navigation systems (INS),['30 Jan 2021'],https://pureportal.coventry.ac.uk/en/publications/learning-to-localise-automated-vehicles-in-challenging-environmen,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"An approach based on Artificial Neural Networks is proposed in this paper to improve the localisation accuracy of Inertial Navigation Systems (INS)/Global Navigation Satellite System (GNSS) based aided navigation during the absence of GNSS signals. The INS can be used to continuously position autonomous vehicles during GNSS signal losses around urban canyons, bridges, tunnels and trees, however, it suffers from unbounded exponential error drifts cascaded over time during the multiple integrations of the accelerometer and gyroscope measurements to position. More so, the error drift is characterised by a pattern dependent on time. This paper proposes several efficient neural network-based solutions to estimate the error drifts using Recurrent Neural Networks, such as the Input Delay Neural Network (IDNN), Long Short-Term Memory (LSTM), Vanilla Recurrent Neural Network (vRNN), and Gated Recurrent Unit (GRU). In contrast to previous papers published in literature, which focused on travel routes that do not take complex driving scenarios into consideration, this paper investigates the performance of the proposed methods on challenging scenarios, such as hard brake, roundabouts, sharp cornering, successive left and right turns and quick changes in vehicular acceleration across numerous test sequences. The results obtained show that the Neural Network-based approaches are able to provide up to 89.55% improvement on the INS displacement estimation and 93.35% on the INS orientation rate estimation."
133,133,Learning Uncertainties in Wheel Odometry for Vehicular Localisation in GNSS Deprived Environments,['Feb 2021'],https://pureportal.coventry.ac.uk/en/publications/learning-uncertainties-in-wheel-odometry-for-vehicular-localisati,"['Palade, V.', 'Christopoulos, S.']","['https://pureportal.coventry.ac.uk/en/persons/vasile-palade', 'https://pureportal.coventry.ac.uk/en/persons/stavros-christopoulos']","Inertial Navigation Systems (INS) are commonly used to localise vehicles in the absence of Global Navigation Satellite Systems (GNSS) signals. However, they are plagued by noises, which grow exponentially over time during the triple integration computation, leading to a poor navigation solution. We explore the wheel encoder as an alternative to the accelerometer of the INS for positional tracking, and for the first time investigate the capability of deep learning using the Long Short-Term Memory (LSTM) neural network to learn the uncertainty inherent in the wheel speed measurements. These uncertainties could be manifested as changes in the tyre size or pressure, or wheel slips as a result of worn out tyres or wet/muddy road drive. The proposed solution has less integration steps in its computation, therefore providing the potential for a more accurate positioning estimation. Through a performance evaluation on several challenging scenarios for vehicular driving, such as hard braking, quick changes in vehicular acceleration, and wet/muddy road driving, we show that the wheel speed-based positioning approach is able to achieve up to 81.46 % improvement compared to the INS accelerometer approach."
134,134,Measuring local sensitivity in Bayesian inference using a new class of metrics,['16 Sep 2021'],https://pureportal.coventry.ac.uk/en/publications/measuring-local-sensitivity-in-bayesian-inference-using-a-new-cla,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"The local sensitivity analysis is recognized for its computational simplicity, and potential use in multi-dimensional and complex problems. Unfortunately, its major drawback is its asymptotic behavior where the prior to posterior convergence in terms of the standard metrics (and also computed by Fréchet derivative) used as a local sensitivity measure is not appropriate. The constructed local sensitivity measures do not converge to zero, and even diverge for the most multidimensional classes of prior distributions. Restricting the classes of priors or using other (Formula presented.) -divergence metrics have been proposed as the ways to resolve this issue which were not successful. We overcome this issue, by proposing a new flexible class of metrics so-called credible metrics whose asymptotic behavior is far more promising and no restrictions are required to impose. Using these metrics, the stability of Bayesian inference to the structure of the prior distribution will be then investigated. Under appropriate condition, we present a uniform bound in a sense that a close credible metric a priori will give a close credible metric a posteriori. As a result, we do not get the sort of divergence based on other metrics. We finally show that the posterior predictive distributions are more stable and robust."
135,135,Mobile computing and communications-driven fog-assisted disaster evacuation techniques for context-aware guidance support: A survey,['1 Nov 2021'],https://pureportal.coventry.ac.uk/en/publications/mobile-computing-and-communications-driven-fog-assisted-disaster-,"['Kurniawan, I. F.', 'He, F.']","['https://pureportal.coventry.ac.uk/en/persons/ibnu-febry-kurniawan', 'https://pureportal.coventry.ac.uk/en/persons/fei-he']","The importance of an optimal solution for disaster evacuation has recently raised attention from researchers across multiple disciplines. This is not only a serious, but also a challenging task due to the complexities of the evacuees’ behaviors, route planning, and demanding coordination services. Although existing studies have addressed these challenges to some extent, mass evacuation in natural disasters tends to be difficult to predict and manage due to the limitation of the underlying models to capture realistic situations. It is therefore desirable to have on-demand mechanisms of locally-driven computing and data exchange services in order to enable near real-time capture of the disaster area during the evacuation. For this purpose, this paper comprehensively surveys recent advances in information and communication technology-enabled disaster evacuations, with the focus on fog computation and communication services to support a massive evacuation process. A numerous variety of tools and techniques are encapsulated within a coordinated on-demand strategy of an evacuation platform, which is aimed to provide a situational awareness and response. Herein fog services appear to be one of the viable options for responsive mass evacuation because they enable low latency data processing and dissemination. They can additionally provide data analytics support for autonomous learning for both the short-term guidance supports and long-term usages. This work extends the existing data-oriented framework by outlining comprehensive functionalities and providing seamless integration. We review the principles, challenges, and future direction of the state-of-the-art strategies proposed to sit within each functionality. Taken together, this survey highlights the importance of adaptive coordination and reconfiguration within the fog services to facilitate responsive mass evacuations as well as open up new research challenges associated with analytics-embedding network and computation, which is critical for any disaster recovery activities."
136,136,Modelling the effect of market forces on the impact of introducing human immunodeficiency virus pre‐exposure prophylaxis among female sex workers,['Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/modelling-the-effect-of-market-forces-on-the-impact-of-introducin,[],[],"Pre-exposure prophylaxis (PrEP) to prevent human immunodeficiency virus (HIV) enables female sex workers (FSWs) to protect themselves from HIV without relying on clients using condoms. Yet, because PrEP reduces HIV risk, financial incentives to not use condoms may lead to risk compensation: reductions in condom use and/or increases in commercial sex, and may reduce the price of unprotected sex. In this analysis, we integrate market forces into a dynamic HIV transmission model to assess how risk compensation could change the impact of PrEP among FSWs and clients. We parameterise how sexual behavior may change with PrEP use among FSWs using stated preference data combined with economic theory. Our projections suggest the impact of PrEP is sensitive to risk compensatory behaviors driven by changes in the economics of sex work. Condom substitution could reduce the impact of PrEP on HIV incidence by 55%, while increases in the frequency of commercial sex to counter decreases in the price charged for unprotected sex among PrEP users could entirely mitigate the impact of PrEP. Accounting for competition between PrEP users and nonusers exacerbates this further. Alternative scenarios where increases in unprotected sex among PrEP users are balanced by decreases in non-PrEP users have the opposite effect, resulting in PrEP having much greater impact. Intervention studies need to determine how HIV prevention products may change the economics of sex work and provision of unprotected sex to enable a better understanding of their impact."
137,137,MSLDOCK: Multi-Swarm Optimization for Flexible Ligand Docking and Virtual Screening,['22 Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/msldock-multi-swarm-optimization-for-flexible-ligand-docking-and-,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Autodock and its various variants are widely utilized docking approaches, which adopt optimization methods as search algorithms for flexible ligand docking and virtual screening. However, many of them have their limitations, such as poor accuracy for dockings with highly flexible ligands and low docking efficiency. In this paper, a multi-swarm optimization algorithm integrated with Autodock environment is proposed to design a high-performance and high-efficiency docking program, namely, MSLDOCK. The search algorithm is a combination of the random drift particle swarm optimization with a novel multi-swarm strategy and the Solis and Wets local search method with a modified implementation. Due to the algorithm's structure, MSLDOCK also has a multithread mode. The experimental results reveal that MSLDOCK outperforms other two Autodock-based approaches in many aspects, such as self-docking, cross-docking, and virtual screening accuracies as well as docking efficiency. Moreover, compared with three non-Autodock-based docking programs, MSLDOCK can be a reliable choice for self-docking and virtual screening, especially for dealing with highly flexible ligand docking problems. The source code of MSLDOCK can be downloaded for free from https://github.com/lcmeteor/MSLDOCK."
138,138,Multi-Phase Locking Value: A Generalized Method for Determining Instantaneous Multi-frequency Phase Coupling,['20 Feb 2021'],https://pureportal.coventry.ac.uk/en/publications/multi-phase-locking-value-a-generalized-method-for-determining-in,"['He, F.']",['https://pureportal.coventry.ac.uk/en/persons/fei-he']," Many physical, biological and neural systems behave as coupled oscillators, with characteristic phase coupling across different frequencies. Methods such as $n:m$ phase locking value and bi-phase locking value have previously been proposed to quantify phase coupling between two resonant frequencies (e.g. f, 2f/3) and across three frequencies (e.g. f_1, f_2, f_1+f_2), respectively. However, the existing phase coupling metrics have their limitations and limited applications. They cannot be used to detect or quantify phase coupling across multiple frequencies (e.g. f_1, f_2, f_3, f_4, f_1+f_2+f_3-f_4), or coupling that involves non-integer multiples of the frequencies (e.g. f_1, f_2, 2f_1/3+f_2/3). To address the gap, this paper proposes a generalized approach, named multi-phase locking value (M-PLV), for the quantification of various types of instantaneous multi-frequency phase coupling. Different from most instantaneous phase coupling metrics that measure the simultaneous phase coupling, the proposed M-PLV method also allows the detection of delayed phase coupling and the associated time lag between coupled oscillators. The M-PLV has been tested on cases where synthetic coupled signals are generated using white Gaussian signals, and a system comprised of multiple coupled Rossler oscillators. Results indicate that the M-PLV can provide a reliable estimation of the time window and frequency combination where the phase coupling is significant, as well as a precise determination of time lag in the case of delayed coupling. This method has the potential to become a powerful new tool for exploring phase coupling in complex nonlinear dynamic systems. "
139,139,Nonlinear Estimation of Sensor Faults With Unknown Dynamics for a Fixed Wing Unmanned Aerial Vehicle,['19 Jul 2021'],https://pureportal.coventry.ac.uk/en/publications/nonlinear-estimation-of-sensor-faults-with-unknown-dynamics-for-a,"['Horri, N.', 'Brusey, J.']","['https://pureportal.coventry.ac.uk/en/persons/nadjim-horri', 'https://pureportal.coventry.ac.uk/en/persons/james-brusey']","In this paper, the estimation of additive inertial navigation sensor faults with unknown dynamics is considered with application to the longitudinal navigation and control of a fixed wing unmanned aerial vehicle. The faulty measurement is on the pitch angle.pA jump Markov regularized particle filter is proposed for fault and state estimation of the nonlinear aircraft dynamics, with a Markovian jump strategy to manage the probabilistic transitions between the fault free and faulty modes. The jump strategy uses a small number of sentinel particles to continue testing the alternate hypothesis under both fault free and faulty modes. The proposed filter is shown to outperform the regularized particle filter for this application in terms of fault estimation accuracy and convergence time for scenarios involving both abrupt and incipient faults, without prior knowledge of the fault models. The state estimation is also more accurate and robust to faults using the proposed approach. The root-mean-square error for the altitude is reduced by 77% using the jump Markov regularized particle filter under a pitch sensor fault amplitude of up to 10 degrees. Performance enhancement compared to the regularized particle filter was found to be more pronounced when fault amplitudes increase."
140,140,Nonlinear System Identification of Neural Systems from Neurophysiological Signals,['15 Mar 2021'],https://pureportal.coventry.ac.uk/en/publications/nonlinear-system-identification-of-neural-systems-from-neurophysi-2,"['He, F.']",['https://pureportal.coventry.ac.uk/en/persons/fei-he'],"The human nervous system is one of the most complicated systems in nature. Complex nonlinear behaviours have been shown from the single neuron level to the system level. For decades, linear connectivity analysis methods, such as correlation, coherence and Granger causality, have been extensively used to assess the neural connectivities and input–output interconnections in neural systems. Recent studies indicate that these linear methods can only capture a certain amount of neural activities and functional relationships, and therefore cannot describe neural behaviours in a precise or complete way. In this review, we highlight recent advances in nonlinear system identification of neural systems, corresponding time and frequency domain analysis, and novel neural connectivity measures based on nonlinear system identification techniques. We argue that nonlinear modelling and analysis are necessary to study neuronal processing and signal transfer in neural systems quantitatively. These approaches can hopefully provide new insights to advance our understanding of neurophysiological mechanisms underlying neural functions. These nonlinear approaches also have the potential to produce sensitive biomarkers to facilitate the development of precision diagnostic tools for evaluating neurological disorders and the effects of targeted intervention."
141,141,Novel lockstep-based fault mitigation approach for SoCs with roll-back and roll-forward recovery,['Sep 2021'],https://pureportal.coventry.ac.uk/en/publications/novel-lockstep-based-fault-mitigation-approach-for-socs-with-roll,"['Kasap, S.']",['https://pureportal.coventry.ac.uk/en/persons/server-kasap'],"All-Programmable System-on-Chips (APSoCs) constitute a compelling option for employing applications in radiation environments thanks to their high-performance computing and power efficiency merits. Despite these advantages, APSoCs are sensitive to radiation like any other electronic device. Processors embedded in APSoCs, therefore, have to be adequately hardened against ionizing-radiation to make them a viable choice of design for harsh environments. This paper proposes a novel lockstep-based approach to harden the dual-core ARM Cortex-A9 processor in the Xilinx Zynq-7000 APSoC against radiation-induced soft errors by coupling it with a MicroBlaze TMR subsystem in the programmable logic (PL) layer of the Zynq. The proposed technique uses the concepts of checkpointing along with roll-back and roll-forward mechanisms at the software level, i.e. software redundancy, as well as processor replication and checker circuits at the hardware level (i.e. hardware redundancy). Results of fault injection experiments show that the proposed approach achieves high levels of protection against soft errors by mitigating around 98% of bit-flips injected into the register files of both ARM cores while keeping timing performance overhead as low as 25% if block and application sizes are adjusted appropriately. Furthermore, the incorporation of the roll-forward recovery operation in addition to the roll-back operation improves the Mean Workload between Failures (MWBF) of the system by up to ≈19% depending on the nature of the running application, since the application can proceed faster, in a scenario where a fault occurs, when treated with the roll-forward operation rather than roll-back operation. Thus, relatively more data can be processed before the next error occurs in the system."
142,142,Optimising feedstock flowrate to improve the performance of an existing anaerobic digestion system.,['24 Jun 2021'],https://pureportal.coventry.ac.uk/en/publications/optimising-feedstock-flowrate-to-improve-the-performance-of-an-ex,"['Ashraf, R. J.', 'Nixon, J. D.', 'Brusey, J.']","['https://pureportal.coventry.ac.uk/en/persons/rjaa-jawad-ashraf', 'https://pureportal.coventry.ac.uk/en/persons/jonathan-nixon', 'https://pureportal.coventry.ac.uk/en/persons/james-brusey']","This paper presents an approach to model and optimise the feedstock flowrate of an anaerobic digestion (AD) cooking system by simultaneously minimising the volume of flared biogas, the unmet cooking demand and the energy cost. As research has typically focused on optimising the digester and its associated parameters to maximise the biogas yield; this research examines how different objectives can influence how one might want to control the system. The system is initially modelled and validated with measured data and an optimisation algorithm is then applied to control the feedstock flow rate. The results show that the performance of first order AD models, in predicting the biogas yield, only differs from measured data by 9% and that by controlling the feeding rate, the amount of flared biogas and unmet cooking demand can be reduced by 100% and approximately 87%, respectively when they are the only objective functions considered. If the energy cost is also added an objective function, then more precise control of feeding rate is needed to ensure that all three conflicting objectives are equally minimised. This result highlights the importance of using the correct feeding rate in the system and considering the overall system during optimisation as producing more biogas might not result in the most cost-effectivesystem."
143,143,Pedestrian and Vehicle Detection in Autonomous Vehicle Perception Systems—A Review,['Nov 2021'],https://pureportal.coventry.ac.uk/en/publications/pedestrian-and-vehicle-detection-in-autonomous-vehicle-perception,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Autonomous Vehicles (AVs) have the potential to solve many traffic problems, such as accidents, congestion and pollution. However, there are still challenges to overcome, for instance, AVs need to accurately perceive their environment to safely navigate in busy urban scenarios. The aim of this paper is to review recent articles on computer vision techniques that can be used to build an AV perception system. AV perception systems need to accurately detect non-static objects and predict their behaviour, as well as to detect static objects and recognise the information they are providing. This paper, in particular, focuses on the computer vision techniques used to detect pedestrians and vehicles. There have been many papers and reviews on pedestrians and vehicles detection so far. However, most of the past papers only reviewed pedestrian or vehicle detection separately. This review aims to present an overview of the AV systems in general, and then review and investigate several detection computer vision techniques for pedestrians and vehicles. The review concludes that both traditional and Deep Learning (DL) techniques have been used for pedestrian and vehicle detection; however, DL techniques have shown the best results. Although good detection results have been achieved for pedestrians and vehicles, the current algorithms still struggle to detect small, occluded, and truncated objects. In addition, there is limited research on how to improve detection performance in difficult light and weather conditions. Most of the algorithms have been tested on well-recognised datasets such as Caltech and KITTI; however, these datasets have their own limitations. Therefore, this paper recommends that future works should be implemented on more new challenging datasets, such as PIE and BDD100K."
144,144,"Predicting mortality, duration of treatment, pulmonary embolism and required ceiling of ventilatory support for COVID-19 inpatients: A Machine-Learning Approach",['20 Feb 2021'],https://pureportal.coventry.ac.uk/en/publications/predicting-mortality-duration-of-treatment-pulmonary-embolism-and,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Introduction Within the UK, COVID-19 has contributed towards over 103,000 deaths. Multiple risk factors for COVID-19 have been identified including various demographics, co-morbidities, biochemical parameters, and physical assessment findings. However, using this vast data to improve clinical care has proven challenging.
Aims to develop a reliable, multivariable predictive model for COVID-19 in-patient outcomes, to aid risk-stratification and earlier clinical decision-making.
Methods Anonymized data regarding 44 independent predictor variables of 355 adults diagnosed with COVID-19, at a UK hospital, was manually extracted from electronic patient records for retrospective, case-controlled analysis. Primary outcomes included inpatient mortality, level of ventilatory support and oxygen therapy required, and duration of inpatient treatment. Secondary pulmonary embolism was the only secondary outcome. After balancing data, key variables were feature selected for each outcome using random forests. Predictive models were created using Bayesian Networks, and cross-validated.

Results Our multivariable models were able to predict, using feature selected risk factors, the probability of inpatient mortality (F1 score 83.7%, PPV 82%, NPV 67.9%); level of ventilatory support required (F1 score varies from 55.8% “High-flow Oxygen level” to 71.5% “ITU-Admission level”); duration of inpatient treatment (varies from 46.7% for “≥ 2 days but < 3 days” to 69.8% “≤ 1 day”); and risk of pulmonary embolism sequelae (F1 score 85.8%, PPV of 83.7%, and NPV of 80.9%).
Conclusion Overall, our findings demonstrate reliable, multivariable predictive models for 4 outcomes, that utilize readily available clinical information for COVID-19 adult inpatients. Further research is required to externally validate our models and demonstrate their utility as clinical decision-making tools."
145,145,Predicting the technical reusability of load-bearing building components: A probabilistic approach towards developing a Circular Economy framework,['1 Oct 2021'],https://pureportal.coventry.ac.uk/en/publications/predicting-the-technical-reusability-of-load-bearing-building-com,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"The construction sector is the largest consumer of raw materials and accounts for 25%–40% of the total CO2 emissions globally. Besides, construction activities produce the highest amount of waste among all other sectors. According to the waste hierarchies, reuse is preferred to recycling; however, most of the recovery of construction and demolition wastes happens in the form of recycling and not reuse. Part of the recent efforts to promote the reuse rates includes estimating the reusability of the load-bearing building components to assist the stakeholders in making sound judgements of the reuse potentials at the end-of-life of a building and alleviate the uncertainties and perceived risks. This study aims to develop a probabilistic model using advanced supervised machine learning techniques (including random forest, K-Nearest Neighbours algorithm, Gaussian process, and support vector machine) to predict the reuse potential of structural elements at the end-of-life of a building. For this purpose, using an online questionnaire, this paper seeks the experts’ opinions with actual reuse experience in the building sector to assess the identified barriers by the authors in an earlier study. Furthermore, the results of the survey are used to develop an easy-to-understand learner for assessing the technical reusability of the structural elements at the end-of-life of a building. The results indicate that the most significant factors affecting the reuse of building structural components are design-related including, matching the design of the new building with the strength of the recovered element."
146,146,Proving UNSAT in SMT: The Case of Quantifier Free Non-Linear Real Arithmetic,['16 Jul 2021'],https://pureportal.coventry.ac.uk/en/publications/proving-unsat-in-smt-the-case-of-quantifier-free-non-linear-real-,"['England, M.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-england'],"We discuss the topic of unsatisfiability proofs in SMT, particularly with reference to quantifier free non-linear real arithmetic. We outline how the methods here do not admit trivial proofs and how past formalisation attempts are not sufficient. We note that the new breed of local search based algorithms for this domain may offer an easier path forward."
147,147,Real-time registration of 3D echo to X-ray fluoroscopy based on cascading classifiers and image registration,['25 Feb 2021'],https://pureportal.coventry.ac.uk/en/publications/real-time-registration-of-3d-echo-to-x-ray-fluoroscopy-based-on-c,"['Ma, Y.']",['https://pureportal.coventry.ac.uk/en/persons/yingliang-ma'],"Three-dimensional (3D) transesophageal echocardiography (TEE) is one of the most significant advances in cardiac imaging. Although TEE provides real-time 3D visualization of heart tissues and blood vessels and has no ionizing radiation, X-ray fluoroscopy still dominates in guidance of cardiac interventions due to TEE having a limited field of view and poor visualization of surgical instruments. Therefore, fusing 3D echo with live X-ray images can provide a better guidance solution. This paper proposes a novel framework for image fusion by detecting the pose of the TEE probe in X-ray images in real-time. The framework does not require any manual initialization. Instead it uses a cascade classifier to compute the position and in-plane rotation angle of the TEE probe. The remaining degrees of freedom are determined by fast marching against a template library. The proposed framework is validated on phantoms and patient data. The target registration error for the phantom was 2.1 mm. In addition, 10 patient datasets, seven of which were acquired from cardiac electrophysiology procedures and three from trans-catheter aortic valve implantation procedures, were used to test the clinical feasibility as well as accuracy. A mean registration error of 2.6 mm was achieved, which is well within typical clinical requirements."
148,148,Scenario Optimisation and Sensitivity Analysis for Safe Automated Driving Using Gaussian Processes,['15 Jan 2021'],https://pureportal.coventry.ac.uk/en/publications/scenario-optimisation-and-sensitivity-analysis-for-safe-automated,"['Daneshkhah, A.', 'Palade, V.']","['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah', 'https://pureportal.coventry.ac.uk/en/persons/vasile-palade']","Assuring the safety of automated vehicles is essential for their timely introduction and acceptance by policymakers and the public. To assess their safe design and robust decision making in response to all possible scenarios, new methods that use a scenario-based testing approach are needed, as testing on public roads in normal traffic would require driving millions of kilometres. We make use of the scenario-based testing approach and propose a method to model simulated scenarios using Gaussian Process based models to predict untested scenario outcomes. This enables us to efficiently determine the performance boundary, where the safe and unsafe scenarios can be evidently distinguished from each other. We present an iterative method that optimises the parameter space of a logical scenario towards the most critical scenarios on this performance boundary. Additionally, we conduct a novel probabilistic sensitivity analysis by efficiently computing several variance-based sensitivity indices using the Gaussian Process models and evaluate the relative importance of the scenario input parameters on the scenario outcome. We critically evaluate and investigate the usefulness of the proposed Gaussian Process based approach as a very efficient surrogate model, which can model the logical scenarios effectively in the presence of uncertainty. The proposed approach is applied on an exemplary logical scenario and shows viability in finding concrete critical scenarios. The reported results, derived from the proposed approach, could pave the way to more efficient testing of automated vehicles and instruct further physical tests on the determined critical scenarios."
149,149,Security Improvement for Energy Harvesting based Overlay Cognitive Networks with Jamming-Assisted Full-Duplex Destinations,['1 Nov 2021'],https://pureportal.coventry.ac.uk/en/publications/security-improvement-for-energy-harvesting-based-overlay-cognitiv,"['Yoo, S.']",['https://pureportal.coventry.ac.uk/en/persons/seongki-yoo'],"This work investigates the secrecy capability of energy harvesting based overlay cognitive networks (EHOCNs). To this end, we assume that a message by a licensed transmitter is relayed by an unlicensed sender. Critically, the unlicensed sender uses energy harvested from licensed signals, enhancing the overall energy efficiency and maintaining the integrity of licensed communications. To secure messages broadcast by the unlicensed sender against the wire-tapper, full-duplex destinations – unlicensed recipient and licensed receiver – jam the eavesdropper at the same time they receive signals from the unlicensed sender. To this effect, we derive closed-form formulas for the secrecy outagepprobability, which then quantify the security performance of both unlicensed and licensed communications for EHOCNs with jamming-assisted full-duplex destinations, namely EHOCNwFD. In addition, optimum operating parameters are established, which can serve as essential design guidelines of such systems."
150,150,Simultaneous Actuator and Sensor Faults Estimation for Aircraft Using a Jump-Markov Regularized Particle Filter,['7 Jun 2021'],https://pureportal.coventry.ac.uk/en/publications/simultaneous-actuator-and-sensor-faults-estimation-for-aircraft-u,"['Horri, N.', 'Brusey, J.']","['https://pureportal.coventry.ac.uk/en/persons/nadjim-horri', 'https://pureportal.coventry.ac.uk/en/persons/james-brusey']","The advances in aircraft autonomy have led to an increased demand for robust sensor and actuator fault detection and estimation methods in challenging situations including the onset of ambiguous faults. In this paper, we consider potential simultaneous fault on sensors and actuators of an Unmanned Aerial Vehicle. The faults are estimated using a Jump-Markov Regularized Particle Filter. The jump Markov decision process is used within a regularized particle filter structure to drive a small subset of particles to test the likelihood of the alternate hypothesis to the current fault mode. A prior distribution of the fault is updated using innovations based on predicted control and measurements. Fault scenarios were focused on cases when the impacts of the actuator and sensor faults are similar. Monte Carlo simulations illustrate the ability of the approach to discriminate between the two types of faults and to accurately and rapidly estimate them. The states are also accurately estimated."
151,151,SSF: Smart city Semantics Framework for reusability of semantic data,['7 Dec 2021'],https://pureportal.coventry.ac.uk/en/publications/ssf-smart-city-semantics-framework-for-reusability-of-semantic-da,"['Yoo, S.']",['https://pureportal.coventry.ac.uk/en/persons/seongki-yoo'],"Semantic data has semantic information about the relationship between information and resources of data collected in a smart city so that all different domains and data can be organically connected. Various services using semantic data such as public data integration of smart cities, semantic search, and linked open data are emerging, and services that open and freely use semantic data are also increasing. By using semantic data, it is possible to create a variety of services regardless of platform and resource characteristics. However, despite the many advantages of semantic data, it is not easy to use because it requires a high understanding of semantics such as SPARQL. Therefore, in this paper, we propose a semantic framework for users ofpsemantic data so that new services can be created without a high understanding of semantics. The semantics framework includes a template-based annotator that supports automatically generating semantic data based on user input and a semantic REST API that allows you to utilize semantic data without understanding SPARQL."
152,152,The challenges of community-based solar energy interventions: Lessons from two Rwandan Refugee Camps,['Dec 2021'],https://pureportal.coventry.ac.uk/en/publications/the-challenges-of-community-based-solar-energy-interventions-less,"['Nixon, J.', 'Halford, A.', 'Gaura, E.']","['https://pureportal.coventry.ac.uk/en/persons/jonathan-nixon', 'https://pureportal.coventry.ac.uk/en/persons/alison-halford', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura']","The paper presents evidence from the performance assessment of two solar energy interventions. Specifically, an evidence base was built around two community co-conceived standalone photovoltaic-battery systems, which were deployed in two refugee camps in Rwanda. We found that for both installations (a micro-grid and a community hall electrification system) energy consumption levels were low, showing that sizeable energy consumption gaps can still develop when co-conceived interventions are deployed. The consumption gap led to low performance ratios (33% and 25% respectively for the micro-grid and community hall system). To guide further work and improve the sustainability of community interventions, we draw a number of design principles for future energy interventions in similar contexts. To deliver sustainable energy transitions for refugees, there needs to be a move towards co-creating community interventions that promote self-governance to position communities as users, maintainers and suppliers of energy services, throughout an intervention's lifetime."
153,153,The DEWCAD project: pushing back the doubly exponential wall of cylindrical algebraic decomposition,['Sep 2021'],https://pureportal.coventry.ac.uk/en/publications/the-dewcad-project-pushing-back-the-doubly-exponential-wall-of-cy,"['England, M.', 'Sadeghimanesh, A.']","['https://pureportal.coventry.ac.uk/en/persons/matthew-england', 'https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh']","This abstract seeks to introduce the ISSAC community to the DEWCAD project, which is based at Coventry University and the University of Bath, in the United Kingdom.  The project seeks to push back the Doubly Exponential Wall of Cylindrical Algebraic Decomposition, through the integration of SAT/SMT technology, the extension of Lazard projection theory, and the development of new algorithms based on CAD technology but without producing CADs themselves.  The project also seeks to develop applications of CAD and will focus on applications in the domains of economics and bio-network analysis."
154,154,The epidemiological landscape of anemia in women of reproductive age in sub-Saharan Africa,['7 Jun 2021'],https://pureportal.coventry.ac.uk/en/publications/the-epidemiological-landscape-of-anemia-in-women-of-reproductive-,[],[],"The role of geographical disparities of health-related risk factors with anemia are poorly documented for women of reproductive age in sub-Saharan Africa (SSA). We aimed to determine the contribution of potential factors and to identify areas at higher risk of anemia for women in reproductive age in SSA. Our study population comprised 27 nationally representative samples of women of reproductive age (15–49) who were enrolled in the Demographic and Health Surveys and conducted between 2010 and 2019 in SSA. Overall, we found a positive association between being anemic and the ecological exposure to malaria incidence [adjusted odds ratio (AOR) = 1.02, 95% confidence interval (CI) 1.02–1.02], and HIV prevalence (AOR = 1.01, CI 1.01–1.02). Women currently pregnant or under deworming medication for the last birth had 31% (AOR = 1.31, CI 1.24–1.39) and 5% (AOR = 1.05, CI 1.01–1.10) higher odds of having anemia, respectively. Similarly, women age 25–34 years old with low education, low income and living in urban settings had higher odds of having anemia. In addition, underweight women had 23% higher odds of suffering anemia (AOR = 1.23, CI 1.15–1.31). Females with low levels of education and wealth index were consistently associated with anemia across SSA. Spatial distribution shows increased risk of anemia in Central and Western Africa. Knowledge about the contribution of known major drivers and the spatial distribution of anemia risk can mitigate operational constraints and help to design geographically targeted intervention programs in SSA."
155,155,"The Salience of Islam to Muslim Heritage Children’s Experiences of Identity, Family, and Well-Being in Foster Care",['25 May 2021'],https://pureportal.coventry.ac.uk/en/publications/the-salience-of-islam-to-muslim-heritage-childrens-experiences-of,"['Cheruvallil-Contractor, S.', 'Halford, A.']","['https://pureportal.coventry.ac.uk/en/persons/sariya-cheruvallil-contractor', 'https://pureportal.coventry.ac.uk/en/persons/alison-halford']","All children need permanent and secure homes in which they can explore their identities and evolve as human beings, citizens, and family members, and within which can they have a sense of security, continuity, stability, and belonging. There are approximately 4500 children of Muslim heritage in the care system in England and Wales, and this number is increasing. Using case studies that emerged from qualitative fieldwork, this article examines the role and impact of religion on children’s journeys through the care system, particularly in foster care. This article concludes that irrespective of the level of engagement Muslim heritage children in the care system have with their religious heritage, Islam has an enduring impact on how they perceive their identities. As a result, there is a pressing need for social workers and foster carers who care for these children to gain greater insights into Islam and Muslim culture. Such insights and understandings will help children settle faster and form stronger bonds of attachment with their foster carers, and in the long term, this will enhance life outcomes for these children."
156,156,Topic modelling in precision medicine with its applications in personalized diabetes management,['18 Jul 2021'],https://pureportal.coventry.ac.uk/en/publications/topic-modelling-in-precision-medicine-with-its-applications-in-pe,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Advances in Internet of Things (IoT) and analytic-based systems in the past decade have found several applications in medical informatics, and have significantly facilitated healthcare decision making. Patients' data are collected through a variety of means, including IoT sensory systems, and require efficient, and accurate processing. Topic Modelling is an unsupervised machine learning algorithm for Natural Language Processing (NLP) that identifies relationships and associations within textual data. The application of Topic Modelling has been widely used on raw text data, where meaningful clusters (topics) are generated by the model. The purpose of this paper is to explore the varying methods of Topic Modelling, mostly the Latent Dirichlet allocation (LDA) model, and its applicability on personalized diabetes management. The proposed study evaluates the possibility of applying topic modelling methods on diabetes literature and genomic data in order to achieve precision medicine."
157,157,Towards algorithm-free physical equilibrium model of computing,['Dec 2021'],https://pureportal.coventry.ac.uk/en/publications/towards-algorithm-free-physical-equilibrium-model-of-computing,"['Mousavi, S.']",['https://pureportal.coventry.ac.uk/en/persons/seyed-mousavi-mousavi'],"Our computers today, from sophisticated servers to small smartphones, operate based on the same computing model, which requires running a sequence of discrete instructions, specified as an algorithm. This sequential computing paradigm has not yet led to a fast algorithm for an NP-complete problem despite numerous attempts over the past half a century. Unfortunately, even after the introduction of quantum mechanics to the world of computing, we still followed a similar sequential paradigm, which has not yet helped us obtain such an algorithm either. Here a completely different model of computing is proposed to replace the sequential paradigm of algorithms with inherent parallelism of physical processes. Using the proposed model, instead of writing algorithms to solve NP-complete problems, we construct physical systems whose equilibrium states correspond to the desired solutions and let them evolve to search for the solutions. The main requirements of the model are identified and quantum circuits are proposed for its potential implementation."
158,158,Understanding HIV and associated risk factors among religious groups in Zimbabwe,['17 Feb 2021'],https://pureportal.coventry.ac.uk/en/publications/understanding-hiv-and-associated-risk-factors-among-religious-gro,[],[],"BackgroundpThe influence of religion and belief systems is widely recognized as an important factor in understanding of health risk perception and myths in the general fight against the HIV pandemic. This study compares the understanding of HIV risk factors and utilization of some HIV services among religious groups in Zimbabwe.pMethodspWe conducted secondary data statistical analysis to investigate the understanding of HIV and associated risk factors among religious groups in Zimbabwe using 2015–2016 Zimbabwe Demographic and Health Survey (ZDHS) data. We began by investigating associations between understanding of HIV and associated risk factors among religious groups. A multivariate stepwise backward elimination method was carried out to explore factors determining understanding of HIV risk after controlling for confounding factors using the most recent ZDHS data (2015–2016).pResultspThe results from the three surveys showed that, in general apostolic sector had low understanding of HIV and associated risk factors compared to other religious groups. Analysis of the 2015–2016 ZDHS data showed that women belonging to the apostolic sector were less likely to know where to get an HIV test odds ratio (OR) and 95% confidence interval, 0.665 (0.503–0.880) and to know that male circumcision reduces HIV transmission OR 0.863 (0.781–0.955). Women from this group had no knowledge that circumcised men can be infected if they do not use condoms OR 0.633 (0.579–0.693), nor that it is possible for a healthy-looking person to have HIV, OR 0.814 (0.719–0.921). They would not buy vegetables from a vendor with HIV OR 0.817 (0.729–0.915) and were less likely to support that HIV positive children should be allowed to attend school with HIV negative children OR 0.804 (0.680–0.950). Similar results were obtained for men in the apostolic sector. These men also did not agree that women were justified to use condoms if the husband has an Sexually Transmitted Infection (STI) OR 0.851 (0.748–0.967).pConclusionspOur results suggest that apostolic sector lack adequate knowledge of HIV and associated risk factors than other religious groups. Targeting HIV prevention programmes by religious groups could be an efficient approach for controlling HIV in Zimbabwe."
159,159,Unpacking Gender and Sexuality in Contemporary Mormonism,['1 Oct 2021'],https://pureportal.coventry.ac.uk/en/publications/unpacking-gender-and-sexuality-in-contemporary-mormonism,"['Halford, A.']",['https://pureportal.coventry.ac.uk/en/persons/alison-halford'],"BackgroundpThe influence of religion and belief systems is widely recognized as an important factor in understanding of health risk perception and myths in the general fight against the HIV pandemic. This study compares the understanding of HIV risk factors and utilization of some HIV services among religious groups in Zimbabwe.pMethodspWe conducted secondary data statistical analysis to investigate the understanding of HIV and associated risk factors among religious groups in Zimbabwe using 2015–2016 Zimbabwe Demographic and Health Survey (ZDHS) data. We began by investigating associations between understanding of HIV and associated risk factors among religious groups. A multivariate stepwise backward elimination method was carried out to explore factors determining understanding of HIV risk after controlling for confounding factors using the most recent ZDHS data (2015–2016).pResultspThe results from the three surveys showed that, in general apostolic sector had low understanding of HIV and associated risk factors compared to other religious groups. Analysis of the 2015–2016 ZDHS data showed that women belonging to the apostolic sector were less likely to know where to get an HIV test odds ratio (OR) and 95% confidence interval, 0.665 (0.503–0.880) and to know that male circumcision reduces HIV transmission OR 0.863 (0.781–0.955). Women from this group had no knowledge that circumcised men can be infected if they do not use condoms OR 0.633 (0.579–0.693), nor that it is possible for a healthy-looking person to have HIV, OR 0.814 (0.719–0.921). They would not buy vegetables from a vendor with HIV OR 0.817 (0.729–0.915) and were less likely to support that HIV positive children should be allowed to attend school with HIV negative children OR 0.804 (0.680–0.950). Similar results were obtained for men in the apostolic sector. These men also did not agree that women were justified to use condoms if the husband has an Sexually Transmitted Infection (STI) OR 0.851 (0.748–0.967).pConclusionspOur results suggest that apostolic sector lack adequate knowledge of HIV and associated risk factors than other religious groups. Targeting HIV prevention programmes by religious groups could be an efficient approach for controlling HIV in Zimbabwe."
160,160,Unsupervised Doppler Radar Based Activity Recognition for e-Healthcare,['2021'],https://pureportal.coventry.ac.uk/en/publications/unsupervised-doppler-radar-based-activity-recognition-for-e-healt,"['Sharifzadeh, S.']",['https://pureportal.coventry.ac.uk/en/persons/sara-sharifzadeh'],"Passive radio frequency (RF) sensing and monitoring of human daily activities in elderly care homes is an emerging topic. Micro-Doppler radars are an appealing solution considering their non-intrusiveness, deep penetration, and high-distance range. Unsupervised activity recognition using Doppler radar data has not received attention, in spite of its importance in case of unlabelled or poorly labelled activities in real scenarios. This study proposes two unsupervised feature extraction methods for the purpose of human activity monitoring using Doppler-streams. These include a local Discrete Cosine Transform (DCT)-based feature extraction method and a local entropy-based feature extraction method. In addition, a novel application of Convolutional Variational Autoencoder (CVAE) feature extraction is employed for the first time for Doppler radar data. The three feature extraction architectures are compared with the previously used Convolutional Autoencoder (CAE) and linear feature extraction based on Principal Component Analysis (PCA) and 2DPCA. Unsupervised clustering is performed using K-Means and K-Medoids. The results show the superiority of DCT-based method, entropy-based method, and CVAE features compared to CAE, PCA, and 2DPCA, with more than 5%-20% average accuracy. In regards to computation time, the two proposed methods are noticeably much faster than the existing CVAE. Furthermore, for high-dimensional data visualisation, three manifold learning techniques are considered. The methods are compared for the projection of raw data as well as the encoded CVAE features. All three methods show an improved visualisation ability when applied to the encoded CVAE features."
161,161,Using Machine Learning Algorithms to Develop a Clinical Decision-Making Tool for COVID-19 Inpatients,['9 Jun 2021'],https://pureportal.coventry.ac.uk/en/publications/using-machine-learning-algorithms-to-develop-a-clinical-decision-,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Background: Within the UK, COVID-19 has contributed towards over 103,000 deaths. Although multiple risk factors for COVID-19 have been identified, using this data to improve clinical care has proven challenging. The main aim of this study is to develop a reliable, multivariable predictive model for COVID-19 in-patient outcomes, thus enabling risk-stratification and earlier clinical decision-making. Methods: Anonymised data consisting of 44 independent predictor variables from 355 adults diagnosed with COVID-19, at a UK hospital, was manually extracted from electronic patient records for retrospective, case–control analysis. Primary outcomes included inpatient mortality, required ventilatory support, and duration of inpatient treatment. Pulmonary embolism sequala was the only secondary outcome. After balancing data, key variables were feature selected for each outcome using random forests. Predictive models were then learned and constructed using Bayesian networks. Results: The proposed probabilistic models were able to predict, using feature selected risk factors, the probability of the mentioned outcomes. Overall, our findings demonstrate reliable, multivariable, quantitative predictive models for four outcomes, which utilise readily available clinical information for COVID-19 adult inpatients. Further research is required to externally validate our models and demonstrate their utility as risk stratification and clinical decision-making tools."
162,162,WhONet: Wheel Odometry neural Network for vehicular localisation in GNSS-deprived environments,['Oct 2021'],https://pureportal.coventry.ac.uk/en/publications/whonet-wheel-odometry-neural-network-for-vehicular-localisation-i,"['Palade, V.', 'Herath, A.', 'Fitzpatrick, M. E.']","['https://pureportal.coventry.ac.uk/en/persons/vasile-palade', 'https://pureportal.coventry.ac.uk/en/persons/anuradha-herath', 'https://pureportal.coventry.ac.uk/en/persons/michael-fitzpatrick']","In this paper, a deep learning approach is proposed to accurately position wheeled vehicles in Global Navigation Satellite Systems (GNSS) deprived environments. In the absence of GNSS signals, information on the speed of the wheels of a vehicle (or other robots alike), recorded from the wheel encoder, can be used to provide continuous positioning information for the vehicle, through the integration of the vehicle's linear velocity to displacement. However, the displacement estimation from the wheel speed measurements are characterised by uncertainties, which could be manifested as wheel slips or/and changes to the tyre size or pressure, from wet and muddy road drives or tyres wearing out. As such, we exploit recent advances in deep learning to propose the Wheel Odometry neural Network (WhONet) to learn the uncertainties in the wheel speed measurements needed for correction and accurate positioning. The performance of the proposed WhONet is first evaluated on several challenging driving scenarios, such as on roundabouts, sharp cornering, hard-brake and wet roads (drifts). WhONet's performance is then further and extensively evaluated on longer-term GNSS outage scenarios of 30 s, 60 s, 120 s and 180 s duration, respectively over a total distance of 493 km. The experimental results obtained show that the proposed method is able to accurately position the vehicle with up to 93% reduction in the positioning error of its original counterpart (physics model) after any 180 s of travel."
163,163,"Working Towards Modern, Affordable & Sustainable Energy Systems in the Context of Displacement: Recommendations for Researchers and Practitioners",['18 Jan 2021'],https://pureportal.coventry.ac.uk/en/publications/working-towards-modern-affordable-amp-sustainable-energy-systems-,"['Halford, A.']",['https://pureportal.coventry.ac.uk/en/persons/alison-halford'],"Working towards modern, affordable & sustainable energy systems in the context of displacement: Recommendations for researchers and practitioners is a working paper drawn from presentations and discussions that emerged during the ‘Agency of Change: Energy in the Displaced Context’ digital Conference held on Wednesday 4th November 2020. The conference was organised by the Centre of Data Science, Coventry University on behalf of the GCRF EPSRC Humanitarian Engineering and Energy for Displacement (HEED) project. This report summarises the discussions that took place between practitioners, academics, policymakers and the HEED team during the HEED working conference on Wednesday 4 November 2020. Drawing upon a range of expertise in the field of social science, humanitarian and renewables engineering and computer science, conference participants sought to identify potential solutions, innovative responses and best practices to increase access to safe, sustainable and affordable energy in the context of displacement."
164,164,"‘Come, Follow Me’, The Sacralising of the Home, and The Guardian of the Family: How Do European Women Negotiate the Domestic Space in the Church of Jesus Christ of Latter-Day Saints?",['12 May 2021'],https://pureportal.coventry.ac.uk/en/publications/come-follow-me-the-sacralising-of-the-home-and-the-guardian-of-th,"['Halford, A.']",['https://pureportal.coventry.ac.uk/en/persons/alison-halford'],"In October 2018, the Prophet Russell M. Nelson informed members of the Church of Jesus Christ of Latter-day Saints that the Church teaching curriculum would shift focus away from lessons taught on Sunday. Instead, members were now asked to engage with ‘home-centred, church-supported’ religious instruction using the Church materials ‘Come, Follow Me’. In a religion where Church leaders still defend the idealised family structure of a stay-at-home mother and a father as the provider, the renewed emphasis on the domestic sphere as the site for Church teaching could also reinforce traditional Mormon gender roles. This article draws upon the lived religion of Latter-day Saint women in Sweden, Greece and England to understand how they negotiate gender in their homes. Looking at the implementation of ‘Come, Follow Me’ of sacralising of the home as a gendered practice, there appears to be reinforcing the primacy of the domestic space in the reproduction of religious practices and doctrinal instruction. Simultaneously, in conceptualising a gender role, the guardian of the family, I show the ways that European Latter-day Saint women are providing, protecting and nurturing their families. The domestic space then becomes instrumental in providing space for more nuanced, complex gender constructs that accommodate Mormon beliefs, cultural context and secular notions of gender without destabilising the institutional structure."
165,165,A Leap from Randomized to Quantum Clustering with Support Vector Machine - A Computation Complexity Analysis,['3 Aug 2020'],https://pureportal.coventry.ac.uk/en/publications/a-leap-from-randomized-to-quantum-clustering-with-support-vector-,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Supervised machine learning deals with developing complex non-linear models, which can be used later to predict the output for a known input. Clustering is usually treated as an unsupervised machine learning task, but we can formulate a solution to a clustering problem by using a supervised classification algorithm [1]. However, these classification algorithms are highly computationally intensive in nature, so the overall complexity in designing a clustering solution is often very costly from an implementation point of view. The more data we use, the more computational power is required too. Recent advancements in quantum computing show promising advantages in dealing with this kind of computational issues we face while training a complex machine-learning algorithm. In this paper, we do a theoretical investigation on the runtime complexity of algorithms, from classical to randomized, and then to quantum frameworks, when designing a clustering algorithm. The analysis shows significant computational advantages with a quantum framework as compared to the classical and randomized versions of the implementation."
166,166,A low cost and highly accurate technique for big data spatial-temporal interpolation,['1 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/a-low-cost-and-highly-accurate-technique-for-big-data-spatial-tem,"['Chatrabgoun, O.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/omid-chatrabgoun', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","The high velocity, variety and volume of data generation by today's systems have necessitated Big Data (BD) analytic techniques. This has penetrated a wide range of industries; BD as a notion has various types and characteristics, and therefore a variety of analytic techniques would be required. The traditional analysis methods are typically unable to analyse spatial-temporal BD. Interpolation is required to approximate the values between the already existing data points, yet since there exist both location and time dimensions, only a multivariate interpolation would be appropriate. Nevertheless, existing software are unable to perform such complex interpolations. To overcome this challenge, this paper presents a layer by layer interpolation approach for spatial-temporal BD. Developing this layered structure provides the opportunity for working with much smaller linear system of equations. Consequently, this structure increases the accuracy and stability of numerical structure of the considered BD interpolation. To construct this layer by layer interpolation, we have used the good properties of Radial Basis Functions (RBFs). The proposed new approach is applied to numerical examples in spatial-temporal big data and the obtained results confirm the high accuracy and low computational cost. Finally, our approach is applied to explore one of the air pollution indices, i.e. daily PMp2.5p concentration, based on different stations in the contiguous United States, and it is evaluated by leave-one-out cross validation."
167,167,A machine learning based software pipeline to pick the variable ordering for algorithms with polynomial inputs,['8 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/a-machine-learning-based-software-pipeline-to-pick-the-variable-o,"['England, M.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-england'],"We are interested in the application of Machine Learning (ML) technology to improve mathematical software.  It may seem that the probabilistic nature of ML tools would invalidate the exact results prized by such software, however, the algorithms which underpin the software often come with a range of choices which are good candidates for ML application.  We refer to choices which have no effect on the mathematical correctness of the software, but do impact its performance.  pIn the past we experimented with one such choice:  the variable ordering to use when building a Cylindrical Algebraic Decomposition (CAD).  We used the Python library Scikit-Learn (sklearn) to experiment with different ML models, and developed new techniques for feature generation and hyper-parameter selection.  pThese techniques could easily be adapted for making decisions other than our immediate application of CAD variable ordering.  Hence in this paper we present a software pipeline to use sklearn to pick the variable ordering for an algorithm that acts on a polynomial system.  The code described is freely available online."
168,168,A new hardware approach to self-organizing maps,['31 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/a-new-hardware-approach-to-self-organizing-maps,"['Gaura, E.']",['https://pureportal.coventry.ac.uk/en/persons/elena-gaura'],"Self-Organizing Maps (SOMs) are widely used as a data mining technique for applications that require data dimensionality reduction and clustering. Given the complexity of the SOM learning phase and the massive dimensionality of many data sets as well as their sample size in Big Data applications, high-speed processing is critical when implementing SOM approaches. This paper proposes a new hardware approach to SOM implementation, exploiting parallelization, to optimize the system's processing time. Unlike most implementations in the literature, this proposed approach allows the parallelization of the data dimensions instead of the map, ensuring high processing speed regardless of data dimensions. An implementation with field-programmable gate arrays (FPGA) is presented and evaluated. Key evaluation metrics are processing time (or throughput) and FPGA area occupancy (or hardware resources). "
169,169,A scalable hybrid MAC strategy for traffic-differentiated IoT-enabled intra-vehicular networks,['1 May 2020'],https://pureportal.coventry.ac.uk/en/publications/a-scalable-hybrid-mac-strategy-for-traffic-differentiated-iot-ena,"['Kurniawan, I. F.']",['https://pureportal.coventry.ac.uk/en/persons/ibnu-febry-kurniawan'],"The increasing popularity of Internet of Things-enabled Intra-Vehicular Wireless Sensor Networks (IoT-IVWSNs) relying on IEEE 802.15.4 standard has generated a massive amount of wireless data traffic and put a great pressure in the network functionalities. Along this trend, the existing medium-access control (MAC) protocol struggles to keep up with the unprecedented demand of vehicle monitoring sensors simultaneously emitting data, which can lead to packet collisions, severe network congestion and lost of time-critical data, due to the inflexible characteristics of the protocol. In order to mitigate these issues, this work proposes an enhanced MAC scheme that is scalable to account for diverse sensor-traffic quality of services. The hybrid scheme aims to effectively combine two procedures, namely history- and priority-based MAC, to allocate appropriate network resources for smooth transmission flow from multiple sensors. History-based MAC exploits historical contention data to optimize a near-future contention window that aims to minimize packet collision and expedite the average data delivery. Priority-based MAC assigns priority based on the time-criticality of the sensing data, which is subsequently being used to schedules network resources. Numerical results show the desirable performance of the hybrid scheme for IoT-IVWSNs in comparison to the existing MAC and sole history-based or priority-based strategies in the context of packet delivery ratio and transmission delay."
170,170,Behavioural Analytics: A Preventative Means for the Future of Policing,['17 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/behavioural-analytics-a-preventative-means-for-the-future-of-poli,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Without sufficient intelligence, police response to crimes occurs in the form a reactive retort. This is even more so in the case of cyberspace policing, as digital platforms increase the complexities involved in the overall police incident response development. In this paper, we briefly introduce cybercrime and the necessities that police forces have to deal with. We argue that there is an urgent need for development and adoption of proactive and preventive techniques to identify and curb cyber and cyber-enabled crimes. We then present topic modelling as one of effective preventive techniques for predicting behaviours that can potentially be linked to cybercrime activities on social media."
171,171,Components reuse in the building sector – A systematic review,['1 Apr 2020'],https://pureportal.coventry.ac.uk/en/publications/components-reuse-in-the-building-sector-a-systematic-review,[],[],"Widespread reuse of building components can promote the circularity of materials in the building sector. However, the reuse of building components is not yet a mainstream practise. Although there have been several studies on the factors affecting the reuse of building components, there is no single study that has tried to harmonize the circumstances affecting this intervention. Through a systematic literature review targeting peer-reviewed journal articles, this study intends to identify and stratify factors affecting the reuse of components of the superstructure of a building and eventually delineate correlations between these factors. Factors identified throughout this study are classified into six major categories and 23 sub-categories. Then the inter-dependencies between the barriers are studied by developing the correlation indices between the sub-categories. Results indicate that addressing the economic, social and regulatory barriers should be prioritized. Although the impact of barriers under perception, risk, compliance and market sub-categories are very pronounced, the highest inter-dependency among the sub-categories is found between perception and risk. It suggests that the perception of the stakeholders about building components reuse is affected by the potential risks associated with this intervention."
172,172,Constructing gene regulatory networks from microarray data using non-Gaussian pair-copula Bayesian networks,['24 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/constructing-gene-regulatory-networks-from-microarray-data-using-,"['Chatrabgoun, O.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/omid-chatrabgoun', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","Many biological and biomedical research areas such as drug design require analyzing the Gene Regulatory Networks (GRNs) to provide clear insight and understanding of the cellular processes in live cells. Under normality assumption for the genes, GRNs can be constructed by assessing the nonzero elements of the inverse covariance matrix. Nevertheless, such techniques are unable to deal with non-normality, multi-modality and heavy tailedness that are commonly seen in current massive genetic data. To relax this limitative constraint, one can apply copula function which is a multivariate cumulative distribution function with uniform marginal distribution. However, since the dependency structures of different pairs of genes in a multivariate problem are very different, the regular multivariate copula will not allow for the construction of an appropriate model. The solution to this problem is using Pair-Copula Constructions (PCCs) which are decompositions of a multivariate density into a cascade of bivariate copula, and therefore, assign different bivariate copula function for each local term. In fact, in this paper, we have constructed inverse covariance matrix based on the use of PCCs when the normality assumption can be moderately or severely violated for capturing a wide range of distributional features and complex dependency structure. To learn the non-Gaussian model for the considered GRN with non-Gaussian genomic data, we apply modified version of copula-based PC algorithm in which normality assumption of marginal densities is dropped. This paper also considers the Dynamic Time Warping (DTW) algorithm to determine the existence of a time delay relation between two genes. Breast cancer is one of the most common diseases in the world where GRN analysis of its subtypes is considerably important; Since by revealing the differences in the GRNs of these subtypes, new therapies and drugs can be found. The findings of our research are used to construct GRNs with high performance, for various subtypes of breast cancer rather than simply using previous models."
173,173,Contemporary Issues for the Church of Jesus Christ of Latter-day Saints in Ireland and the United Kingdom,['29 Nov 2020'],https://pureportal.coventry.ac.uk/en/publications/contemporary-issues-for-the-church-of-jesus-christ-of-latter-day-,"['Halford, A.']",['https://pureportal.coventry.ac.uk/en/persons/alison-halford'],"Many biological and biomedical research areas such as drug design require analyzing the Gene Regulatory Networks (GRNs) to provide clear insight and understanding of the cellular processes in live cells. Under normality assumption for the genes, GRNs can be constructed by assessing the nonzero elements of the inverse covariance matrix. Nevertheless, such techniques are unable to deal with non-normality, multi-modality and heavy tailedness that are commonly seen in current massive genetic data. To relax this limitative constraint, one can apply copula function which is a multivariate cumulative distribution function with uniform marginal distribution. However, since the dependency structures of different pairs of genes in a multivariate problem are very different, the regular multivariate copula will not allow for the construction of an appropriate model. The solution to this problem is using Pair-Copula Constructions (PCCs) which are decompositions of a multivariate density into a cascade of bivariate copula, and therefore, assign different bivariate copula function for each local term. In fact, in this paper, we have constructed inverse covariance matrix based on the use of PCCs when the normality assumption can be moderately or severely violated for capturing a wide range of distributional features and complex dependency structure. To learn the non-Gaussian model for the considered GRN with non-Gaussian genomic data, we apply modified version of copula-based PC algorithm in which normality assumption of marginal densities is dropped. This paper also considers the Dynamic Time Warping (DTW) algorithm to determine the existence of a time delay relation between two genes. Breast cancer is one of the most common diseases in the world where GRN analysis of its subtypes is considerably important; Since by revealing the differences in the GRNs of these subtypes, new therapies and drugs can be found. The findings of our research are used to construct GRNs with high performance, for various subtypes of breast cancer rather than simply using previous models."
174,174,Copula-based probabilistic assessment of intensity and duration of cold episodes: A case study of Malayer vineyard region,['15 Dec 2020'],https://pureportal.coventry.ac.uk/en/publications/copula-based-probabilistic-assessment-of-intensity-and-duration-o,"['Chatrabgoun, O.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/omid-chatrabgoun', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","Frost, particularly during the spring, is one of the most damaging weather phenomena for vineyards, causing significant economic losses to vineyards around the world each year. The risk of tardive frost damage in vineyards due to changing climate is considered as an important threat to the sustainable production of grapes. Therefore, the cold monitoring strategies is one of the criteria with significant impacts on the yields and prosperity of horticulture and raisin factories. Frost events can be characterized by duration and severity. This paper investigates the risk and impacts of frost phenomenon in the vineyards by modeling the joint distribution of duration and severity factors and analyzing the influential parameter’s dependency structure using capabilities of copula functions. A novel mathematical framework is developed within this study to understand the risk and uncertainties associate with frost events and the impacts on yields of vineyards by analyzing the non-linear dependency structure using copula functions as an efficient tool. The developed model was successfully validated for the case study of vineyard in Malayer city of Iran. The copula model developed in this study was shown to be a robust tool for predicting the return period of the frost events."
175,175,Digital Twin Technologies and Smart Cities,['2020'],https://pureportal.coventry.ac.uk/en/publications/digital-twin-technologies-and-smart-cities,"['Daneshkhah, A. (ed.)']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"This book provides a holistic perspective on Digital Twin (DT) technologies, and presents cutting-edge research in the field. It assesses the opportunities that DT can offer for smart cities, and covers the requirements for ensuring secure, safe and sustainable smart cities. Further, the book demonstrates that DT and its benefits with regard to:  pdata visualisation, real-time data analytics, and learning leading to improved confidence in decision making; reasoning, monitoring and warning to support accurate diagnostics and prognostics; acting using edge control and what-ifanalysis; and connection with back-end business applications  hold significant potential for applications in smart cities, by employing a wide range of sensory and data-acquisition systems in various parts of the urban infrastructure. pThe contributing authors reveal how and why DT technologies that are used for monitoring, visualising, diagnosing and predicting in real-time are vital to cities’ sustainability and efficiency. The concepts outlined in the book represents a city together with all of its infrastructure elements, which communicate with each other in a complex manner. Moreover, securing Internet of Things (IoT) which is one of the key enablers of DT’s is discussed in details and from various perspectives. pThe book offers an outstanding reference guide for practitioners and researchers in manufacturing, operations research and communications, who are considering digitising some of their assets and related services. It is also a valuable asset for graduate students and academics who are looking to identify research gaps and develop their own proposals for further research."
176,176,Effective Capacity Analysis over Generalized Composite Fading Channels,['17 Jun 2020'],https://pureportal.coventry.ac.uk/en/publications/effective-capacity-analysis-over-generalized-composite-fading-cha,"['Yoo, S. K.']",['https://pureportal.coventry.ac.uk/en/persons/seongki-yoo'],"A performance analysis of the effective capacity in two recently proposed generalized composite fading channels, namely $\kappa$-$\mu$ / inverse gamma and $\eta$-$\mu$ / inverse gamma composite fading channels, is conducted. To this end, accurate  analytic expressions  for the effective capacity are derived along with simple tight bound representations.  Additionally,  simple  approximate expressions  at  the  high  average signal-to-noise ratio  regime are also provided. The effective capacity is then analyzed for different delay constraint, multipath fading and shadowing conditions. The numerical results show that the achievable spectral efficiency lessens as the multipath fading and shadowing parameters decrease (i.e., severe multipath fading and heavy shadowing become prevalent) or the delay constraint increases. The  accuracy  and  tightness  of  the  proposed bounds is demonstrated and approximate representations are also provided to verify their usefulness. Furthermore, our numerical results are validated through a careful comparison with the simulated results."
177,177,Energy Optimization on Joint Task Computation Using Genetic Algorithm,['21 Dec 2020'],https://pureportal.coventry.ac.uk/en/publications/energy-optimization-on-joint-task-computation-using-genetic-algor,"['Kurniawan, I. F.', 'He, F.']","['https://pureportal.coventry.ac.uk/en/persons/ibnu-febry-kurniawan', 'https://pureportal.coventry.ac.uk/en/persons/fei-he']","Joint computation is a form of collaborative job execution running at separate physical units, which are previously grouped by their unique functionalities. While existing studies have mainly utilized joint computation with direct coordination between nodes in different segments, it is worth considering another scenario where an additional node within a layer relays data to another layer. As a consequence, the node can serve as an aggregation point for data capture units prior to transmission to the sink node. However, this new arrangement produces additional transmission paths and can thus cause additional energy spending. This pilot study investigates the joint computation problem aiming at optimizing energy consumption. Relevant components, such as computation and communication, are taken into account and modeled into formal representation. A genetic algorithm-based solution is then used as a tool to optimize parameter setup. According to the experiment results, the metaheuristic algorithm has potential to achieve the optimal system configuration, emphasizing the data length that affects the final energy spending on communications. However, the algorithm cannot always guarantee the optimality as it relies on the random variable used in the process."
178,178,"Evaluating assumptions of scales for subjective assessment of thermal environments – Do laypersons perceive them the way, we researchers believe?",['15 Mar 2020'],https://pureportal.coventry.ac.uk/en/publications/evaluating-assumptions-of-scales-for-subjective-assessment-of-the,"['Montazami, A.']",['https://pureportal.coventry.ac.uk/en/persons/azadeh-montazami'],"People's subjective response to any thermal environment is commonly investigated by using rating scales describing the degree of thermal sensation, comfort, and acceptability. Subsequent analyses of results collected in this way rely on the assumption that specific distances between verbal anchors placed on the scale exist and that relationships between verbal anchors from different dimensions that are assessed (e.g. thermal sensation and comfort) do not change. Another inherent assumption is that such scales are independent of the context in which they are used (climate zone, season, etc.). Despite their use worldwide, there is indication that contextual differences influence the way the scales are perceived and therefore question the reliability of the scales’ interpretation. To address this issue, a large international collaborative questionnaire study was conducted in 26 countries, using 21 different languages, which led to a dataset of 8225 questionnaires. Results, analysed by means of robust statistical techniques, revealed that only a subset of the responses are in accordance with the mentioned assumptions. Significant differences appeared between groups of participants in their perception of the scales, both in relation to distances of the anchors and relationships between scales. It was also found that respondents’ interpretations of scales changed with contextual factors, such as climate, season, and language. These findings highlight the need to carefully consider context-dependent factors in interpreting and reporting results from thermal comfort studies or post-occupancy evaluations, as well as to revisit the use of rating scales and the analysis methods used in thermal comfort studies to improve their reliability."
179,179,Farm Area Segmentation in Satellite Images Using DeepLabv3+ Neural Networks,['30 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/farm-area-segmentation-in-satellite-images-using-deeplabv3-neural,"['Sharifzadeh, S.']",['https://pureportal.coventry.ac.uk/en/persons/sara-sharifzadeh'],"Farm detection using low resolution satellite images is an important part of digital agriculture applications such as crop yield monitoring. However, it has not received enough attention compared to high-resolution images. Although high resolution images are more efficient for detection of land cover components, the analysis of low-resolution images are yet important due to the low-resolution repositories of the past satellite images used for timeseries analysis, free availability and economic concerns. In this paper, semantic segmentation of farm areas is addressed using low resolution satellite images. The segmentation is performed in two stages; First, local patches or Regions of Interest (ROI) that include farm areas are detected. Next, deep semantic segmentation strategies are employed to detect the farm pixels. For patch classification, two previously developed local patch classification strategies are employed; a two-step semi-supervised methodology using hand-crafted features and Support Vector Machine (SVM) modelling and transfer learning using the pretrained Convolutional Neural Networks (CNNs). For the latter, the high-level features learnt from the massive filter banks of deep Visual Geometry Group Network (VGG-16) are utilized. After classifying the image patches that contain farm areas, the DeepLabv3+ model is used for semantic segmentation of farm pixels. Four different pretrained networks, resnet18, resnet50, resnet101 and mobilenetv2, are used to transfer their learnt features for the new farm segmentation problem. The first step results show the superiority of the transfer learning compared to hand-crafted features for classification of patches. The second step results show that the model trained based on resnet50 achieved the highest semantic segmentation accuracy."
180,180,Generation of pedestrian pose structures using generative adversarial networks,['17 Feb 2020'],https://pureportal.coventry.ac.uk/en/publications/generation-of-pedestrian-pose-structures-using-generative-adversa,"['Palade, V.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/vasile-palade', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","The safety of vulnerable road users is of paramount importance as transport moves towards fully automated driving. The richness of real-world data required for testing autonomous vehicles is limited, and furthermore, the available data does not have a fair representation of different scenarios and rare events. This work presents a novel approach for the generation of human pose structures, specifically the type of pose structures that would appear to be in pedestrian scenarios. The results show that the generated pedestrian structures are indistinguishable from the ground truth pose structures when classified using a suitably trained classifier. The paper demonstrates that the Generative Adversarial Network architecture can be used to create realistic new training samples, and, in future, new pedestrian events."
181,181,Geometrical Frustration in Interacting Self-Avoiding Walk Models of Polymers in Dilute Solution,['22 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/geometrical-frustration-in-interacting-self-avoiding-walk-models-,[],[],"We look at the effects of geometric frustration in two-dimensional interacting self-avoiding walk models. Models in which these effects are present do not behave in the same way as the standard interacting self-avoiding walk model where an attractive interaction energy is included between non-consecutive, nearest-neighbour visited sites on the lattice. We present, in particular, the different numerical methods we have used to study these models, as well as some of the main results found for a number of different models."
182,182,Individual and community-level benefits of PrEP in western Kenya and South Africa: Implications for population prioritization of PrEP provision,['31 Dec 2020'],https://pureportal.coventry.ac.uk/en/publications/individual-and-community-level-benefits-of-prep-in-western-kenya-,[],[],"BACKGROUND: Pre-exposure prophylaxis (PrEP) is highly effective in preventing HIV and has the potential to significantly impact the HIV epidemic. Given limited resources for HIV prevention, identifying PrEP provision strategies that maximize impact is critical.pMETHODS: We used a stochastic individual-based network model to evaluate the direct (infections prevented among PrEP users) and indirect (infections prevented among non-PrEP users as a result of PrEP) benefits of PrEP, the person-years of PrEP required to prevent one HIV infection, and the community-level impact of providing PrEP to populations defined by gender and age in western Kenya and South Africa. We examined sensitivity of results to scale-up of antiretroviral therapy (ART) and voluntary medical male circumcision (VMMC) by comparing two scenarios: maintaining current coverage (""status quo"") and rapid scale-up to meet programmatic targets (""fast-track"").pRESULTS: The community-level impact of PrEP was greatest among women aged 15-24 due to high incidence, while PrEP use among men aged 15-24 yielded the highest proportion of indirect infections prevented in the community. These indirect infections prevented continue to increase over time (western Kenya: 0.4-5.5 (status quo); 0.4-4.9 (fast-track); South Africa: 0.5-1.8 (status quo); 0.5-3.0 (fast-track)) relative to direct infections prevented among PrEP users. The number of person-years of PrEP needed to prevent one HIV infection was lower (59 western Kenya and 69 in South Africa in the status quo scenario; 201 western Kenya and 87 in South Africa in the fast-track scenario) when PrEP was provided only to women compared with only to men over time horizons of up to 5 years, as the indirect benefits of providing PrEP to men accrue in later years.pCONCLUSIONS: Providing PrEP to women aged 15-24 prevents the greatest number of HIV infections per person-year of PrEP, but PrEP provision for young men also provides indirect benefits to women and to the community overall. This finding supports existing policies that prioritize PrEP use for young women, while also illuminating the community-level benefits of PrEP availability for men when resources permit."
183,183,Indoor Visible Light Communication: A Tutorial and Survey,['11 Dec 2020'],https://pureportal.coventry.ac.uk/en/publications/indoor-visible-light-communication-a-tutorial-and-survey,"['Khan, A. S.']",['https://pureportal.coventry.ac.uk/en/persons/amjad-saeed-khan'],"With the advancement of solid-state devices for lighting, illumination is on the verge of being completely restructured. This revolution comes with numerous advantages and viable opportunities that can transform the world of wireless communications for the better. Solid-state LEDs are rapidly replacing the contemporary incandescent and fluorescent lamps. In addition to their high energy efficiency, LEDs are desirable for their low heat generation, long lifespan, and their capability to switch on and off at an extremely high rate. The ability of switching between different levels of luminous intensity at such a rate has enabled the inception of a new communication technology referred to as visible light communication (VLC). With this technology, the LED lamps are additionally being used for data transmission. This paper provides a tutorial and a survey of VLC in terms of the design, development, and evaluation techniques as well as current challenges and their envisioned solutions. The focus of this paper is mainly directed towards an indoor setup. An overview of VLC, theory of illumination, system receivers, system architecture, and ongoing developments are provided. We further provide some baseline simulation results to give a technical background on the performance of VLC systems. Moreover, we provide the potential of incorporating VLC techniques in the current and upcoming technologies such as fifth-generation (5G), beyond fifth-generation (B5G) wireless communication trends including sixth-generation (6G), and intelligent reflective surfaces (IRSs) among others."
184,184,IO-VNBD: Inertial and Odometry Benchmark Dataset for Ground Vehicle Positioning,['4 May 2020'],https://pureportal.coventry.ac.uk/en/publications/io-vnbd-inertial-and-odometry-benchmark-dataset-for-ground-vehicl,"['Palade, V.']",['https://pureportal.coventry.ac.uk/en/persons/vasile-palade'],"Low-cost inertial navigation sensors (INS) can be exploited for a reliable tracking solution for autonomous vehicles. However, position errors grow exponentially due to noises in the measurements. Several deep learning techniques have been investigated to mitigate the errors for a better navigation solution [1-10]. However, these studies have involved the use of different datasets not made publicly available. The lack of a robust benchmark dataset has thus hindered the advancement in the research, comparison and adoption of deep learning techniques for vehicle positioning based on inertial navigation. In order to facilitate the benchmarking, fast development and evaluation of positioning algorithms, we therefore present the first of its kind large-scale and information-rich inertial and odometry focused public dataset called IO-VNBD (Inertial Odometry Vehicle Navigation Benchmark Dataset).The vehicle tracking dataset was recorded using a research vehicle equipped with ego-motion sensors on public roads in the United Kingdom, Nigeria, and France. The sensors include a GPS receiver, inertial navigation sensors, wheel-speed sensors amongst other sensors found on the car as well as the inertial navigation sensors and GPS receiver in an android smart phone sampling at 10HZ. A diverse number of scenarios and vehicle dynamics are captured such as traffic, round-abouts, hard-braking etc. on different road types (country roads, motorways etc.) with varying driving patterns. The dataset consists of a total driving time of about 40 hours over 1,300km for the vehicle extracted data and about 58 hours over 4,400 km for the smartphone recorded data. We hope that this dataset will prove valuable in furthering research on the correlation between vehicle dynamics and its displacement as well as other related studies "
185,185,Is modelling complexity always needed? Insights from modelling PrEP introduction in South Africa,['23 Nov 2020'],https://pureportal.coventry.ac.uk/en/publications/is-modelling-complexity-always-needed-insights-from-modelling-pre,[],[],"BACKGROUND: Mathematical models can be powerful policymaking tools. Simple, static models are user-friendly for policymakers. More complex, dynamic models account for time-dependent changes but are complicated to understand and produce. Under which conditions are static models adequate? We compare static and dynamic model predictions of whether behavioural disinhibition could undermine the impact of HIV pre-exposure prophylaxis (PrEP) provision to female sex workers in South Africa.pMETHODS: A static model of HIV risk was developed and adapted into a dynamic model. Both models were used to estimate the possible reduction in condom use, following PrEP introduction, without increasing HIV risk. The results were compared over a 20-year time horizon, in two contexts: at epidemic equilibrium and during an increasing epidemic.pRESULTS: Over time horizons of up to 5 years, the models are consistent. Over longer timeframes, the static model overstates the tolerated reduction in condom use where initial condom use is reasonably high ($\ge$50%) and/or PrEP effectiveness is low ($\le$45%), especially during an increasing epidemic.pCONCLUSIONS: Static models can provide useful deductions to guide policymaking around the introduction of a new HIV intervention over short-medium time horizons of up to 5 years. Over longer timeframes, static models may not sufficiently emphasise situations of programmatic importance, especially where underlying epidemics are still increasing."
186,186,Nonlinear System Identification of Neural Systems from Neurophysiological Signals,['Aug 2020'],https://pureportal.coventry.ac.uk/en/publications/nonlinear-system-identification-of-neural-systems-from-neurophysi,"['He, F.']",['https://pureportal.coventry.ac.uk/en/persons/fei-he'],"BACKGROUND: Mathematical models can be powerful policymaking tools. Simple, static models are user-friendly for policymakers. More complex, dynamic models account for time-dependent changes but are complicated to understand and produce. Under which conditions are static models adequate? We compare static and dynamic model predictions of whether behavioural disinhibition could undermine the impact of HIV pre-exposure prophylaxis (PrEP) provision to female sex workers in South Africa.pMETHODS: A static model of HIV risk was developed and adapted into a dynamic model. Both models were used to estimate the possible reduction in condom use, following PrEP introduction, without increasing HIV risk. The results were compared over a 20-year time horizon, in two contexts: at epidemic equilibrium and during an increasing epidemic.pRESULTS: Over time horizons of up to 5 years, the models are consistent. Over longer timeframes, the static model overstates the tolerated reduction in condom use where initial condom use is reasonably high ($\ge$50%) and/or PrEP effectiveness is low ($\le$45%), especially during an increasing epidemic.pCONCLUSIONS: Static models can provide useful deductions to guide policymaking around the introduction of a new HIV intervention over short-medium time horizons of up to 5 years. Over longer timeframes, static models may not sufficiently emphasise situations of programmatic importance, especially where underlying epidemics are still increasing."
187,187,On Shadowing the κ-μ Fading Model,['29 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/on-shadowing-the-%CE%BA-%CE%BC-fading-model,"['Yoo, S. K.']",['https://pureportal.coventry.ac.uk/en/persons/seongki-yoo'],"In this paper, we extensively investigate the way in which κ - μ fading channels can be impacted by shadowing. Following from this, a family of shadowed κ - μ fading models are introduced and classified according to whether the underlying κ - μ fading undergoes single or double shadowing. In total, we discuss three types of single shadowed κ - μ model (denoted Type I to Type III) and three types of double shadowed κ - μ model (denoted Type I to Type III). The taxonomy of the single shadowed Type I - III models is dependent upon whether the fading model assumes that the dominant component, the scattered waves, or both experience shadowing. Although the physical definition of the examined models make no predetermination of the statistics of the shadowing process, for illustrative purposes, two example cases are provided for each type of single shadowed model by assuming that the shadowing is influenced by either a Nakagami- m random variable (RV) or an inverse Nakagami- m RV. It is worth noting that these RVs have been shown to provide an adequate characterization of shadowing in numerous communication scenarios of practical interest. The categorization of the double shadowed Type I - III models is dependent upon whether a) the envelope experiences shadowing of the dominant component, which is preceded (or succeeded) by a secondary round of (multiplicative) shadowing, or b) the dominant and scattered contributions are fluctuated by two independent shadowing processes, or c) the scattered waves of the envelope are subject to shadowing, which is also preceded (or succeeded) by a secondary round of multiplicative shadowing. Similar to the single shadowed models, we provide two example cases for each type of double shadowed model by assuming that the shadowing phenomena are shaped by a Nakagami- m RV, an inverse Nakagami- m RV or their mixture. It is worth highlighting that the double shadowed κ - μ models offer remarkable flexibility as they include the κ - μ , η - μ , and the various types of single shadowed κ - μ distribution as special cases. This property renders them particularly useful for the effective characterization and modeling of the diverse composite fading conditions encountered in communication scenarios in many emerging wireless applications."
188,188,On the functional central limit theorem for first passage time of nonlinear semi-Markov reward processes,['1 Oct 2020'],https://pureportal.coventry.ac.uk/en/publications/on-the-functional-central-limit-theorem-for-first-passage-time-of,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"In this article we examine the functional central limit theorem for the first passage time of reward processes defined over a finite state space semi-Markov process. In order to apply this process for a wider range of real-world applications, the reward functions, considered in this work, are assumed to have general forms instead of the constant rates reported in the other studies. We benefit from the martingale theory and Poisson equations to prove and establish the convergence of the first passage time of reward processes to a zero mean Brownian motion. Necessary conditions to derive the results presented in this article are the existence of variances for sojourn times in each state and second order integrability of reward functions with respect to the distribution of sojourn times. We finally verify the presented methodology through a numerical illustration."
189,189,Opinion evidence in Cell Site Analysis,['Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/opinion-evidence-in-cell-site-analysis,"['Tart, M. S.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-stephen-tart'],"Issues concerning forensic inference exist in all areas of Forensic Science, and Cell Site Analysis is no exception. There is a standard concerning opinion evidence adopted by both the European Network of Forensic Science Institutes (ENFSI) and the Association of Forensic Science Providers (AFSP) based on the principles of the Case Assessment and Interpretation (CAI) Model widely used within “traditional” forensic Science. This standard has not been widely adopted, or does not appear to be particularly well known, either within Cell Site Analysis or in the general field of Digital Forensics. This paper is aimed at Cell Site Analysis experts and outlines the legislative and regulatory framework within which opinion in Cell Site Analysis is provided and addresses how the principles defined in the AFSP standard can be applied to Cell Site Analysis. A case example highlighting differences between a task-driven approach commonly used within Cell Site Analysis and a CAI approach to the same data is presented and explored."
190,190,Polymer in wedge-shaped confinement: Effect on the θ  temperature,['20 Mar 2020'],https://pureportal.coventry.ac.uk/en/publications/polymer-in-wedge-shaped-confinement-effect-on-the-%CE%B8-temperature,[],[],"The equilibrium properties of a finite-length linear polymer chain confined in an infinite wedge composed of two perfectly reflecting hard walls meeting at a variable apex angle (α) are presented. One end of the polymer is anchored a distance y from the apex on the conical axis of symmetry, while the other end is free. We report here, the nonmonotonic behavior of θ temperature as a function of y for a finite-length chain. Data collapse for different chain lengths indicates that such behavior will exist for all finite lengths. We delineate the origin of such nonmonotonic behavior, which may have potential applications in understanding the cellular process occurring in nanoconfined geometries."
191,191,Quantifying early COVID-19 outbreak transmission in South Africa and exploring vaccine efficacy scenarios,['24 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/quantifying-early-covid-19-outbreak-transmission-in-south-africa-,[],[],"The emergence and fast global spread of COVID-19 has presented one of the greatest public health challenges in modern times with no proven cure or vaccine. Africa is still early in this epidemic, therefore the extent of disease severity is not yet clear. We used a mathematical model to fit to the observed cases of COVID-19 in South Africa to estimate the basic reproductive number and critical vaccination coverage to control the disease for different hypothetical vaccine efficacy scenarios. We also estimated the percentage reduction in effective contacts due to the social distancing measures implemented. Early model estimates show that COVID-19 outbreak in South Africa had a basic reproductive number of 2.95 (95% credible interval [CrI] 2.83-3.33). A vaccine with 70% efficacy had the capacity to contain COVID-19 outbreak but at very higher vaccination coverage 94.44% (95% Crl 92.44-99.92%) with a vaccine of 100% efficacy requiring 66.10% (95% Crl 64.72-69.95%) coverage. Social distancing measures put in place have so far reduced the number of social contacts by 80.31% (95% Crl 79.76-80.85%). These findings suggest that a highly efficacious vaccine would have been required to contain COVID-19 in South Africa. Therefore, the current social distancing measures to reduce contacts will remain key in controlling the infection in the absence of vaccines and other therapeutics."
192,192,Safeguarding gains in the Sexual and Reproductive Health and AIDS Response amidst COVID-19: The Role of African Civil Society,['1 Nov 2020'],https://pureportal.coventry.ac.uk/en/publications/safeguarding-gains-in-the-sexual-and-reproductive-health-and-aids,[],[],"This article outlines the role of African civil society in safeguarding gains registered to date in sexual and reproductive health and the response to HIV. The case is made for why civil society organizations (CSOs) must be engaged vigilantly in the COVID-19 response in Africa. Lockdown disruptions and the rerouting of health funds to the pandemic have impeded access to essential sexual and reproductive health (SRH) and social protection services. Compounded by pre-existing inequalities faced by vulnerable populations, the poor SRH outcomes amid COVID-19 call for CSOs to intensify demand for the accountability of governments. CSOs should also continue to persevere in their aim to rapidly close community-health facility gaps and provide safety nets to mitigate the gendered impact of COVID-19."
193,193,Some Computational Considerations for Kernel-Based Support Vector Machine,['2020'],https://pureportal.coventry.ac.uk/en/publications/some-computational-considerations-for-kernel-based-support-vector,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Sometimes healthcare perspectives in communications technologies require data mining, especially classification as a supervised learning. Support vector machines (SVMs) are considered as efficient supervised learning approaches for classification due to their robustness against several types of model misspecifications and outliers. Kernel-based SVMs are known to be more flexible tools for a wide range of supervised learning tasks and can efficiently handle non-linear relationship between input variables and outputs (or labels). They are more robust with respect to the aforementioned model misspecifications, and also more accurate in the sense that the root-mean-square error computed by fitting the kernel-based SVMs is considerably smaller than the one computed by fitting the standard/linear SVMs. However, the choice of kernel type and particularity kernel’s parameters could have significant impact on the classification accuracy and other supervised learning tasks required in network security, Internet of things, cybersecurity, etc. One of the findings of this study is that larger kernel parameter(s) would encourage SVMs with more localities and vice versa. This chapter provides some results on the effect of the kernel parameter on the kernel-based SVM classification. We thus first examine the effect of these parameters on the classification results using the kernel-based SVM, and then specify the optimal value of these parameters using cross-validation (CV) technique."
194,194,Spatiotemporal transmission dynamics of the COVID-19 pandemic and its impact on critical healthcare capacity,['Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/spatiotemporal-transmission-dynamics-of-the-covid-19-pandemic-and,[],[],"The role of geospatial disparities in the dynamics of the COVID-19 pandemic is poorly understood. We developed a spatially-explicit mathematical model to simulate transmission dynamics of COVID-19 disease infection in relation with the uneven distribution of the healthcare capacity in Ohio, U.S. The results showed substantial spatial variation in the spread of the disease, with localized areas showing marked differences in disease attack rates. Higher COVID-19 attack rates experienced in some highly connected and urbanized areas (274 cases per 100,000 people) could substantially impact the critical health care response of these areas regardless of their potentially high healthcare capacity compared to more rural and less connected counterparts (85 cases per 100,000). Accounting for the spatially uneven disease diffusion linked to the geographical distribution of the critical care resources is essential in designing effective prevention and control programmes aimed at reducing the impact of COVID-19 pandemic."
195,195,Stemming cholera tides in Zimbabwe through mass vaccination,['1 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/stemming-cholera-tides-in-zimbabwe-through-mass-vaccination,[],[],"BackgroundpIn 2018, Zimbabwe declared another major cholera outbreak a decade after recording one of the worst cholera outbreaks in Africa.pMethodspA mathematical model for cholera was used to estimate the magnitude of the cholera outbreak and vaccination coverage using cholera cases reported data. A Markov chain Monte Carlo method based on a Bayesian framework was used to fit the model in order to estimate the basic reproductive number and required vaccination coverage for cholera control.pResultspThe results showed that the outbreak had a basic reproductive number of 1.82 (95% credible interval [CrI] 1.53–2.11) and required vaccination coverage of at least 58% (95% Crl 45–68%) to be contained using an oral cholera vaccine of 78% efficacy. Sensitivity analysis demonstrated that a vaccine with at least 55% efficacy was sufficient to contain the outbreak but at higher coverage of 75% (95% Crl 58–88%). However, high-efficacy vaccines would greatly reduce the required coverage, with 100% efficacy vaccine reducing coverage to 45% (95% Crl 35–53%).pConclusionspThese findings reinforce the crucial need for oral cholera vaccines to control cholera in Zimbabwe, considering that the decay of water reticulation and sewerage infrastructure is unlikely to be effectively addressed in the coming years."
196,196,"The empty womb, the unanswered prayer: Female Infertility and involuntary childlessness in British Mormon communities",['28 Dec 2020'],https://pureportal.coventry.ac.uk/en/publications/the-empty-womb-the-unanswered-prayer-female-infertility-and-invol,"['Halford, A.']",['https://pureportal.coventry.ac.uk/en/persons/alison-halford'],"BackgroundpIn 2018, Zimbabwe declared another major cholera outbreak a decade after recording one of the worst cholera outbreaks in Africa.pMethodspA mathematical model for cholera was used to estimate the magnitude of the cholera outbreak and vaccination coverage using cholera cases reported data. A Markov chain Monte Carlo method based on a Bayesian framework was used to fit the model in order to estimate the basic reproductive number and required vaccination coverage for cholera control.pResultspThe results showed that the outbreak had a basic reproductive number of 1.82 (95% credible interval [CrI] 1.53–2.11) and required vaccination coverage of at least 58% (95% Crl 45–68%) to be contained using an oral cholera vaccine of 78% efficacy. Sensitivity analysis demonstrated that a vaccine with at least 55% efficacy was sufficient to contain the outbreak but at higher coverage of 75% (95% Crl 58–88%). However, high-efficacy vaccines would greatly reduce the required coverage, with 100% efficacy vaccine reducing coverage to 45% (95% Crl 35–53%).pConclusionspThese findings reinforce the crucial need for oral cholera vaccines to control cholera in Zimbabwe, considering that the decay of water reticulation and sewerage infrastructure is unlikely to be effectively addressed in the coming years."
197,197,The impact of physical exercise on the fatigue symptoms in patients with multiple sclerosis: A systematic review and meta-analysis,['13 Mar 2020'],https://pureportal.coventry.ac.uk/en/publications/the-impact-of-physical-exercise-on-the-fatigue-symptoms-in-patien,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Background: Despite many benefits of the physical activity on physical and mental health of patients with Multiple Sclerosis (MS), the activity level in these patients is still very limited, and they continue to suffer from impairment in functioning ability. The main aim of this study is thus to closely examine exercise's effect on fatigue of patients with MS worldwide, with particular interest on Iran based on a comprehensive systematic review and meta-analysis. Methods: The studies used in this systematic review were selected from the articles published from 1996 to 2019, in national and international databases including SID, Magiran, Iranmedex, Irandoc, Google Scholar, Cochrane, Embase, ScienceDirect, Scopus, PubMed and Web of Science (ISI). These databases were thoroughly searched, and the relevant ones were selected based on some plausible keywords to the aim of this study. Heterogeneity index between studies was determined using Cochran's test and Ip2p. Due to heterogeneity in studies, the random effects model was used to estimate standardized mean difference. Results: From the systematic review, a meta-analysis was performed on 31 articles which were fulfilled the inclusion criteria. The sample including of 714 subjects was selected from the intervention group, and almost the same sample size of 720 individuals were selected in the control group. Based on the results derived from this meta-analysis, the standardized mean difference between the intervention group before and after the intervention was respectively estimated to be 23.8 ± 6.2 and 16.9 ± 3.2, which indicates that the physical exercise reduces fatigue in patients with MS. Conclusion: The results of this study extracted from a detailed meta-analysis reveal and confirm that physical exercise significantly reduces fatigue in patients with MS. As a results, a regular exercise program is strongly recommended to be part of a rehabilitation program for these patients."
198,198,"The influence of acclimatization, age and gender-related differences on thermal perception in university buildings: case studies in Scotland and England",['15 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/the-influence-of-acclimatization-age-and-gender-related-differenc,"['Brusey, J.', 'Montazami, A.']","['https://pureportal.coventry.ac.uk/en/persons/james-brusey', 'https://pureportal.coventry.ac.uk/en/persons/azadeh-montazami']","The higher education sector in the UK is responsible for large amount of the country's energy consumption. Space heating, which is the largest and most expensive part of the energy used in the UK educational buildings is a potential target for improving energy efficiency. However, the role of thermal comfort in students' productivity in academic environments cannot be overlooked. Considering the prevalence of two different climatic conditions in Northern and Southern/Midland regions of the UK, this study investigated thermal comfort in two university campuses in Scotland and England. environmental measurements combined with a simultaneous questionnaire survey were conducted in eight university buildings in Edinburgh and Coventry. The field study was carried out during the academic year of 2017-18 on 3507 students. The results confirmed influence of students' acclimatization, showing a warmer than neutral mean Thermal Sensation Vote (TSV) and cooler thermal preference in Edinburgh than Coventry. The higher acceptable temperature in Coventry (23.5 °C) than Edinburgh (22.1 °C) reinforced the results on the influence of climatic adaptation. Thermal acceptability was examined in a direct (analysing the actual votes on thermal acceptability) and an indirect approach (considering the TSV between −1 and 1 as acceptable). The indirect approach was shown to be a better predictor of the thermal acceptability as this method extends beyond the acceptable range suggested by the direct method. Thermal perceptions of females were shown to be colder than males in university classrooms. However, no statistically significant difference was observed in the thermal comfort of different age groups."
199,199,The prevalence of Restless Legs Syndrome/Willis-ekbom disease (RLS/WED) in the third trimester of pregnancy: a systematic review,['13 Apr 2020'],https://pureportal.coventry.ac.uk/en/publications/the-prevalence-of-restless-legs-syndromewillis-ekbom-disease-rlsw,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"BACKGROUND: RLS is known as one of the most common movement disorders during pregnancy, which is most aggravated in the third trimester of pregnancy and can affect up to one-third of pregnant women. This study intends to determine the total prevalence of RLS in the third trimester of pregnancy through a systematic review.pMETHODS: The present study was conducted via meta-analysis method up to 2019. The papers related to the subject of interest were obtained through searching in SID, MagIran, IranDoc, Scopus, Embase, Web of Science (ISI), PubMed, Science Direct, and Google Scholar databases. Heterogeneity of the studies was examined via I2 index, and the data were analyzed in Comprehensive meta-analysis software.pRESULTS: In investigating 10 papers capturing 2431 subjects within the age range of 25-39 years, the total prevalence of RLS in the third trimester of pregnancy based on meta-analysis was obtained as 22.9% (95% CI: 14.7-33.8%). Further, as the sample size increased, the RLS prevalence diminished, while with increase in years, this prevalence increased, where this difference was statistically significant (P < 0.05).pCONCLUSION: Prevalence of RLS in the third trimester of pregnancy is high, healthcare policymakers should organize educational classes to improve the life dimensions among this group of pregnant women."
200,200,The prevalence of severe depression in Iranian older adult: a meta-analysis and meta-regression,['3 Feb 2020'],https://pureportal.coventry.ac.uk/en/publications/the-prevalence-of-severe-depression-in-iranian-older-adult-a-meta,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Background: Depression is one of the most common psychiatric disorders in the older adult and one of the most common risk factors for suicide in the older adult. Studies show different and inconsistent prevalence rates in Iran. This study aims to determine the prevalence of severe depression in Iranian older adult through a meta-analysis approach. Methods: The present meta-analysis was conducted between January 2000-August 2019. Articles related to the subject matter were obtained by searching Scopus, Sciencedirect, SID, magiran, Barakat Knowledge Network System, Medline (PubMed), and Google Scholar databases. The heterogeneity of the studies was evaluated using I
              p2p index and the data were analyzed in Comprehensive Meta-Analysis software. Results: In a study of 3948 individuals aged 50-90 years, the overall prevalence of severe depression in Iranian older adult was 8.2% (95% CI, 4.14-6.3%) based on meta-analysis. Also, in order to investigate the effects of potential factors (sample size and year of study) on the heterogeneity of severe depression in Iranian older adult, meta-regression was used. It was reported that the prevalence of severe depression in Iranian older adult decreased with increasing sample size and increasing years of the study, which is significantly different (P < 0.05). Conclusion: Considering the high prevalence of severe depression in Iranian older adult, it is necessary for health policy makers to take effective control measures and periodic care for the older adult.
            "
201,201,The prevalence of sleep disturbances among physicians and nurses facing the COVID-19 patients: a systematic review and meta-analysis,['29 Sep 2020'],https://pureportal.coventry.ac.uk/en/publications/the-prevalence-of-sleep-disturbances-among-physicians-and-nurses-,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Background: In all epidemics, healthcare staff are at the centre of risks and damages caused by pathogens. Today, nurses and physicians are faced with unprecedented work pressures in the face of the COVID-19 pandemic, resulting in several psychological disorders such as stress, anxiety and sleep disturbances. The aim of this study is to investigate the prevalence of sleep disturbances in hospital nurses and physicians facing the COVID-19 patients. Method: A systematic review and metanalysis was conducted in accordance with the PRISMA criteria. The PubMed, Scopus, Science direct, Web of science, CINHAL, Medline, and Google Scholar databases were searched with no lower time-limt and until 24 June 2020. The heterogeneity of the studies was measured using I2 test and the publication bias was assessed by the Egger's test at the significance level of 0.05. Results: The I2 test was used to evaluate the heterogeneity of the selected studies, based on the results of I2 test, the prevalence of sleep disturbances in nurses and physicians is I2: 97.4% and I2: 97.3% respectively. After following the systematic review processes, 7 cross-sectional studies were selected for meta-analysis. Six studies with the sample size of 3745 nurses were examined in and the prevalence of sleep disturbances was approximated to be 34.8% (95% CI: 24.8-46.4%). The prevalence of sleep disturbances in physicians was also measured in 5 studies with the sample size of 2123 physicians. According to the results, the prevalence of sleep disturbances in physicians caring for the COVID-19 patients was reported to be 41.6% (95% CI: 27.7-57%). Conclusion: Healthcare workers, as the front line of the fight against COVID-19, are more vulnerable to the harmful effects of this disease than other groups in society. Increasing workplace stress increases sleep disturbances in the medical staff, especially nurses and physicians. In other words, increased stress due to the exposure to COVID-19 increases the prevalence of sleep disturbances in nurses and physicians. Therefore, it is important for health policymakers to provide solutions and interventions to reduce the workplace stress and pressures on medical staff."
202,202,"The prevalence of stress, anxiety and depression within front-line healthcare workers caring for COVID-19 patients: a systematic review and meta-regression",['17 Dec 2020'],https://pureportal.coventry.ac.uk/en/publications/the-prevalence-of-stress-anxiety-and-depression-within-front-line,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"Background Stress, anxiety, and depression are some of the most important research and practice challenges for psychologists, psychiatrists, and behavioral scientists. Due to the importance of issue and the lack of general statistics on these disorders among the Hospital staff treating the COVID-19 patients, this study aims to systematically review and determine the prevalence of stress, anxiety and depression within front-line healthcare workers caring for COVID-19 patients.Methods In this research work, the systematic review, meta-analysis and meta-regression approaches are used to approximate the prevalence of stress, anxiety and depression within front-line healthcare workers caring for COVID-19 patients. The keywords of prevalence, anxiety, stress, depression, psychopathy, mental illness, mental disorder, doctor, physician, nurse, hospital staff, 2019-nCoV, COVID-19, SARS-CoV-2 and Coronaviruses were used for searching the SID, MagIran, IranMedex, IranDoc, ScienceDirect, Embase, Scopus, PubMed, Web of Science (ISI) and Google Scholar databases. The search process was conducted in December 2019 to June 2020. In order to amalgamate and analyze the reported results within the collected studies, the random effects model is used. The heterogeneity of the studies is assessed using the I2 index. Lastly, the data analysis is performed within the Comprehensive Meta-Analysis software.Results Of the 29 studies with a total sample size of 22,380, 21 papers have reported the prevalence of depression, 23 have reported the prevalence of anxiety, and 9 studies have reported the prevalence of stress. The prevalence of depression is 24.3% (18% CI 18.2–31.6%), the prevalence of anxiety is 25.8% (95% CI 20.5–31.9%), and the prevalence of stress is 45% (95% CI 24.3–67.5%) among the hospitals’ Hospital staff caring for the COVID-19 patients. According to the results of meta-regression analysis, with increasing the sample size, the prevalence of depression and anxiety decreased, and this was statistically significant (P < 0.05), however, the prevalence of stress increased with increasing the sample size, yet this was not statistically significant (P = 0.829).Conclusion The results of this study clearly demonstrate that the prevalence of stress, anxiety and depression within front-line healthcare workers caring for COVID-19 patients is high. Therefore, the health policy-makers should take measures to control and prevent mental disorders in the Hospital staff."
203,203,Time to Scale Up Preexposure Prophylaxis Beyond the Highest-Risk Populations? Modeling Insights From High-Risk Women in Sub-Saharan Africa,['1 Nov 2020'],https://pureportal.coventry.ac.uk/en/publications/time-to-scale-up-preexposure-prophylaxis-beyond-the-highest-risk-,[],[],"OBJECTIVES: New HIV infections remain higher in women than men in sub-Saharan Africa. Preexposure prophylaxis (PrEP) is an effective HIV prevention measure, currently prioritized for those at highest risk, such as female sex workers (FSWs), for whom it is most cost-effective. However, the greatest number of HIV infections in sub-Saharan Africa occurs in women in the general population. As countries consider wider PrEP scale-up, there is a need to weigh the population-level impact, cost, and relative cost-effectiveness to inform priority setting. METHODS: We developed mathematical models of HIV risk to women and derived tools to highlight key considerations for PrEP programming. The models were fitted to South Africa, Zimbabwe, and Kenya, spanning a range of HIV burden in sub-Saharan Africa. The impact, cost, and cost-effectiveness of PrEP scale-up for adolescent girls and young women (AGYW), women 25 to 34 years old, and women 35 to 49 years old were assessed, accounting for differences in population sizes and the low program retention levels reported in demonstration projects. RESULTS: Preexposure prophylaxis could avert substantially more infections a year among women in general population than among FSW. The greatest number of infections could be averted annually among AGYW in South Africa (24-fold that for FSW). In Zimbabwe, the greatest number of infections could be averted among women 25 to 34 years old (8-fold that for FSW); and in Kenya, similarly between AGYW and women 25 to 34 years old (3-fold that for FSW). However, the unit costs of PrEP delivery for AGYW, women 25 to 34 years old, and women 35 to 49 years old would have to reduce considerably (by 70.8%-91.0% across scenarios) for scale-up to these populations to be as cost-effective as for FSW. CONCLUSIONS: Preexposure prophylaxis has the potential to substantially reduce new HIV infections in HIV-endemic countries in sub-Saharan Africa. This will necessitate PrEP being made widely available beyond those at highest individual risk and continued integration into a range of national services and at community level to significantly bring down the costs and improve cost-effectiveness."
204,204,"Understanding Household Fuel Choice Behaviour in the Amazonas State, Brazil: Effects of Validation and Feature Selection",['28 Jul 2020'],https://pureportal.coventry.ac.uk/en/publications/understanding-household-fuel-choice-behaviour-in-the-amazonas-sta,"['Gaura, E.', 'Brusey, J.']","['https://pureportal.coventry.ac.uk/en/persons/elena-gaura', 'https://pureportal.coventry.ac.uk/en/persons/james-brusey']","Since 2003, Brazil has striven to provide energy access to all, in rural areas, in an effort to economically empower the communities. Unpacking fuel stacking behaviour can shed light onto the speed of transition toward the exclusive use of advanced fuel types. This paper presents findings from surveys that were carried out with 14 non-electrified communities in a rural area of Rio Negro, Amazonas State, Brazil. We identify the fuel choice determinants in these communities using a multinomial logistic regression model and more generally discuss the validity and robustness of such models in the context of statistical validation and evaluation metrics. Specifically for the Amazonas communities considered in this study, the research showed that the fuel choice determinants are the age of household, the number of people at meals each day, the number of meals daily, the community, education of the household head, and the income level of the household. Moreover, given the Brazilian policies related to energy and sustainability, this region is not likely to reach the Sustainable Development Goals proposed by United Nations for 2030."
205,205,Vehicular localisation at high and low estimation rates during gnss outages: A deep learning approach,['25 Sep 2020'],https://pureportal.coventry.ac.uk/en/publications/vehicular-localisation-at-high-and-low-estimation-rates-during-gn,"['Palade, V.', 'Christopoulos, S. R. G.']","['https://pureportal.coventry.ac.uk/en/persons/vasile-palade', 'https://pureportal.coventry.ac.uk/en/persons/stavros-christopoulos']","Road localisation of autonomous vehicles is reliant on consistent accurate GNSS (Global Navigation Satellite System) positioning information. Commercial GNSS receivers usually sample at 1 Hz, which is not sufficient to robustly and accurately track a vehicle in certain scenarios, such as driving on the highway, where the vehicle could travel at medium to high speeds, or in safety-critical scenarios. In addition, the GNSS relies on a number of satellites to perform triangulation and may experience signal loss around tall buildings, bridges, tunnels and trees. An approach to overcoming this problem involves integrating the GNSS with a vehicle-mounted Inertial Navigation Sensor (INS) system to provide a continuous and more reliable high rate positioning solution. INSs are however plagued by unbounded exponential error drifts during the double integration of the acceleration to displacement. Several deep learning algorithms have been employed to learn the error drift for a better positioning prediction. We therefore investigate in this chapter the performance of Long Short-Term Memory (LSTM), Input Delay Neural Network (IDNN), Multi-Layer Neural Network (MLNN) and Kalman Filter (KF) for high data rate positioning. We show that Deep Neural Network-based solutions can exhibit better performances for high data rate positioning of vehicles in comparison to commonly used approaches like the Kalman filter."
206,206,Cell site analysis: Roles and interpretation,['28 Aug 2019'],https://pureportal.coventry.ac.uk/en/publications/cell-site-analysis-roles-and-interpretation,"['Tart, M. S.']",['https://pureportal.coventry.ac.uk/en/persons/matthew-stephen-tart'],"This paper considers the confusion that exists between opinion and non-opinion evidence concerning telecommunication data – and thus the boundary between expert and technical evidence. The difference between presentation, explanation and interpretation (for Technical, Investigative or Evaluative purposes) of data is outlined. The authors consider how the term “interpretation” may be used differently in connection with expert witnesses, witnesses giving technical evidence, and by the judiciary, suggesting that this may give rise to unrealistic expectations of a practitioner’s ability to reliably answer questions. Recommendations for core competencies are made for those giving telecommunications evidence to recognise when they are presenting opinion evidence and therefore (potentially inadvertently) acting as expert witnesses."
207,207,Mass transpiration in magneto-hydrodynamic boundary layer flow over a superlinear stretching sheet embedded in porous medium with slip,['1 Jan 2019'],https://pureportal.coventry.ac.uk/en/publications/mass-transpiration-in-magneto-hydrodynamic-boundary-layer-flow-ov,"['Daneshkhah, A.']",['https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah'],"We have studied mass transpiration of a magneto-hydrodynamic (MHD) flow of a Newtonian fluid over a superlinear stretching sheet embedded in a porous medium. A model was created of a nonlinear system of partial differential equations that are transformed into third-order nonlinear ordinary differential equations via similarity transformations and then solved analytically using differential transform method and Pade approximants. The main focus of the present study is on the effect of Navier’s slip boundary condition on flow behavior. A comprehensive study is presented on the effects of various parameters, such as Navier’s slip condition, mass transpiration (suction/injection), and Darcy number on the axial and transverse velocity profiles of the laminar boundary layer flow through the stretching sheet."
208,208,Remote sensing technologies and energy applications in refugee camps,['1 Jan 2019'],https://pureportal.coventry.ac.uk/en/publications/remote-sensing-technologies-and-energy-applications-in-refugee-ca,"['Nixon, J. D.', 'Gaura, E.']","['https://pureportal.coventry.ac.uk/en/persons/jonathan-nixon', 'https://pureportal.coventry.ac.uk/en/persons/elena-gaura']","Whilst technological breakthroughs alone cannot revolutionise energy access for refugees, a number of innovations are offering the possibility of transformational change. One area, explored in this chapter by the University of Coventry, is the need for wireless sensor networks and communication technology to gather data to inform systematic decision making. This chapter reviews a range of energy technologies and delivery approaches that have been trialled in camps, including discussion of the resulting problems and challenges that have been met. The chapter makes the case for improved energy intervention planning and identifies multi-criteria decision-making approaches that could be utilised in the context of refugee camps for dealing with both evaluation and design problems. The chapter concludes by exploring the possibility of using alternative wireless sensors and monitoring devices to gather data on a range of energy systems to inform decision making and management of shared community resources."
209,209,Spontaneous Fruit Fly Optimisation for truss weight minimisation: Performance evaluation based on the no free lunch theorem,['24 Sep 2019'],https://pureportal.coventry.ac.uk/en/publications/spontaneous-fruit-fly-optimisation-for-truss-weight-minimisation-,"['Fitzpatrick, M. E.']",['https://pureportal.coventry.ac.uk/en/persons/michael-fitzpatrick']," Over the past decade, several researchers have presented various optimisation algorithms for use in truss design. The no free lunch theorem implies that no optimisation algorithm fits all problems; therefore, the interest is not only in the accuracy and convergence rate of the algorithm but also the tuning effort and population size required for achieving the optimal result. The latter is particularly crucial for computationally intensive or high-dimensional problems. Contrast-based Fruit-fly Optimisation Algorithm (c-FOA) proposed by Kanarachos et al. in 2017 is based on the efficiency of fruit flies in food foraging by olfaction and visual contrast. The proposed Spontaneous Fruit Fly Optimisation (s-FOA) enhances c-FOA and addresses the difficulty in solving nonlinear optimisation algorithms by presenting standard parameters and lean population size for use on all optimisation problems. Six benchmark problems were studied to assess the performance of s-FOA. A comparison of the results obtained from documented literature and other investigated techniques demonstrates the competence and robustness of the algorithm in truss optimisation. "
210,210,"The Scales Project, a cross-national dataset on the interpretation of thermal perception scales",['26 Nov 2019'],https://pureportal.coventry.ac.uk/en/publications/the-scales-project-a-cross-national-dataset-on-the-interpretation,"['Azadeh, M.']",['https://pureportal.coventry.ac.uk/en/persons/azadeh-montazami'],"Thermal discomfort is one of the main triggers for occupants’ interactions with components of the built environment such as adjustments of thermostats and/or opening windows and strongly related to the energy use in buildings. Understanding causes for thermal (dis-)comfort is crucial for design and operation of any type of building. The assessment of human thermal perception through rating scales, for example in post-occupancy studies, has been applied for several decades; however, long-existing assumptions related to these rating scales had been questioned by several researchers. The aim of this study was to gain deeper knowledge on contextual influences on the interpretation of thermal perception scales and their verbal anchors by survey participants. A questionnaire was designed and consequently applied in 21 language versions. These surveys were conducted in 57 cities in 30 countries resulting in a dataset containing responses from 8225 participants. The database offers potential for further analysis in the areas of building design and operation, psycho-physical relationships between human perception and the built environment, and linguistic analyses."
211,211,Algebraic tools in the study of Multistationarity of Chemical Reaction Networks,['Oct 2018'],https://pureportal.coventry.ac.uk/en/publications/algebraic-tools-in-the-study-of-multistationarity-of-chemical-rea,"['Sadeghimanesh, A.']",['https://pureportal.coventry.ac.uk/en/persons/amirhosein-sadeghimanesh-sadeghi-manesh'],"Thermal discomfort is one of the main triggers for occupants’ interactions with components of the built environment such as adjustments of thermostats and/or opening windows and strongly related to the energy use in buildings. Understanding causes for thermal (dis-)comfort is crucial for design and operation of any type of building. The assessment of human thermal perception through rating scales, for example in post-occupancy studies, has been applied for several decades; however, long-existing assumptions related to these rating scales had been questioned by several researchers. The aim of this study was to gain deeper knowledge on contextual influences on the interpretation of thermal perception scales and their verbal anchors by survey participants. A questionnaire was designed and consequently applied in 21 language versions. These surveys were conducted in 57 cities in 30 countries resulting in a dataset containing responses from 8225 participants. The database offers potential for further analysis in the areas of building design and operation, psycho-physical relationships between human perception and the built environment, and linguistic analyses."
212,212,Among the last ones to leave? Understanding the Journeys of Muslim Children in the Care System in England,['2018'],https://pureportal.coventry.ac.uk/en/publications/among-the-last-ones-to-leave-understanding-the-journeys-of-muslim,"['Cheruvallil-Contractor, S.', 'Halford, A.']","['https://pureportal.coventry.ac.uk/en/persons/sariya-cheruvallil-contractor', 'https://pureportal.coventry.ac.uk/en/persons/alison-halford']","Children of Muslim heritage are likely to experience significant delay in finding a fostering or adoptive placement and where a child has complex needs due to health, disability, age, mixed or multiple heritage background or being part of a sibling group, finding permanent placement takes even longer. In some cases, they may never find a permanent home at all. Such delays cause lasting harm for children and according to Selwyn et al, ‘delay in decision making and action has an unacceptable price in terms of the reduction in children’s life chances and the financial costs to local authorities, the emotional and financial burden later placed on adoptive families and future costs to society’ (2006).  Policy makers’ response has been to emphasise transracial placements so that the process of finding a permanent home is expedited for these children.pThrough interviews with social workers, foster carers, adoptive parents and prospective adoptive parents, this research presents a research-informed narrative of the complexities in Muslim children’s circumstances and identities, which influence how decisions are made about their lives. By better understanding the journeys of these children through the care system, this research will provide an evidence base for practitioners, policy makers and communities to draw upon, and in doing so will improve outcomes for these children, their families and for society as a whole.pThis research provides strong evidence of the salience of Islam to Muslim children’s identities. When children come into care they experience upheaval, displacement and trauma – in such contexts faith is familiar and enables children to be resilient. If in their new home, children’s faith and ethnic needs are provided, they are happier, are more settled and attach better and sooner to their carers. Foster carers and adopters agree that faith is central to their identities too, that faith motivates them to care for the children they look after and that they may be best placed to meet the needs of children who come from ethnic and religious backgrounds similar to their own. For adopters there was an additional emphasis on the child they adopted ‘looking like them’. pBased on this key finding of the salience of religion to the formation, evolution and preservation of the identities of children in public care, we suggest 7 inter-related recommendations for policy makers, social workers, carers and for the Muslim community to take forward. We do not assign a particular recommendation to a particular group, instead we call for joined-up thinking and collective action from these stakeholders, aimed at prioritising each child’s welfare, security and happiness.pAs a final word we emphasise the good practice that we can evidence in how social workers address the faith needs of Muslim children. The story is by no means only about good practice. Indeed, we have found evidence of blind-spots and lacunae. Nevertheless for a profession that faces regular unfair coverage from the media, it is important to emphasise the strengths of the profession and the conscientious care it provides to the most vulnerable children in our societies. Our intention with this report, is to celebrate and share the good practice and where there are blind-spots to engage critically but also collegially to fill the gaps in provision.pThe seven recommendations we make on the basis of this project are as follows:pRecommendation 1: Include religion in SSDA903 returns and the national DfE database on looked after childrenpRecommendation 2: Recognise the salience of faith in children’s journeys through the care system and enhance the faith literacy of social work practitioners and policy makers.   pRecommendation 3: Develop and disseminate Islamic theological guidance on adoption and fostering that prioritises the children’s needs.pRecommendation 4: Where required adoptive parents need be offered theological advice on the issue of establishing Mahram relations with their adopted children. If they choose to lactate their children they should be offered medical supportpRecommendation 5: The agreements between Islamic modesty guidelines and safeguarding policy need to be shared with Muslim foster carers.pRecommendation 6: In line with the recommendation of the Education Select Committee, more outreach, information and recruitment work needs to be undertaken with diverse British Muslim communities to increase the number of Muslim foster carers and adopters.pRecommendation 7: Need to evaluate the impact of the removal of ethnicity from adoption law and guidance in England on practice."
213,213,Discrete Weighted Exponential Distribution of the Second Type: Properties and Applications,['2018'],https://pureportal.coventry.ac.uk/en/publications/discrete-weighted-exponential-distribution-of-the-second-type-pro,"['Chatrabgoun, O.', 'Daneshkhah, A.']","['https://pureportal.coventry.ac.uk/en/persons/omid-chatrabgoun', 'https://pureportal.coventry.ac.uk/en/persons/alireza-daneshkhah']","In this paper, we propose a new lifetime model as a discrete version of the continuous weighted exponential distribution which is called discrete weighted exponential distribution (DWED). This model is a generalization of the discrete exponential distribution which is originally introduced by Chakraborty (2015). We present various statistical indices/properties of this distribution including reliability indices, moment generating function, probability generating function, survival and hazard rate functions, index of dispersion, and stress-strength parameter. We rst present a numerical method to compute the maximum likelihood estima-tions (MLEs) of the models parameters, and then conduct a simulation study to further analyze these estimations. The advantages of the DWED are shown in practice by applying it on two real world applications and compare it with some other well-known lifetime distributions."
214,214,h*pt: 一种鼓励质量平衡产量的 h 型指数,['Jan 2017'],https://pureportal.coventry.ac.uk/en/publications/hpt-an-h-type-index-encouraging-quality-and-balancing-productivit,"['Jiang, X.']",['https://pureportal.coventry.ac.uk/en/persons/xiaorui-jiang'],"As a balanced indicator for both the quality and productivity of researchers’ scientific outputs, h-index suffers severely from loss of significant information in citation distributions so that its ability to discriminate researchers is rather limited. H-index not only fails to distinguish researchers with quasi the same h-values, but also lacks the ability to promote researchers’ foci on originality and high quality. Current extensions to h-index by exploiting citation distribution characteristics all exhibit some “pathologically” eccentric behaviors against either real datasets or theoretical distributions. With a motivation of balancing quality and quantity, this paper proposes a new h-type index h*pt by exploiting citation distribution characteristics, which encourages quality by defining reward/penalty factors to excess/long-tail citations, and at the same time balances productivity by scaling citations outside the h-core to the average performance of the long-tail papers. Extensive experiments on both the ACL Anthology Network dataset and several theoretical citation distributions prove that the proposed h*pt achieves reasonably better results than previous h-type extensions."
215,215,基于城市群的空气质量数据的可视分析方法研究,['15 Mar 2017'],https://pureportal.coventry.ac.uk/en/publications/urban-agglomerations-based-visual-analysis-of-air-quality-data,"['Jiang, X.']",['https://pureportal.coventry.ac.uk/en/persons/xiaorui-jiang'],"Air pollution has gradually become an important issue, and has attracted more and more attention from the general public and the scientific community. How do different cities interact with each other with respect to the air quality issue? What is the similarity and difference among the air quality attributes of distinct cities, and what factors may influence the interaction? We answer these intricate questions by proposing a comprehensive visual analysis system to explore the evolution of an urban agglomeration. The method proposes a Voronoi diagram to show the spatial distribution of urban agglomeration and the evolution of urban agglomeration in space, a stacked graph with threads embedded to show urban agglomeration in the time evolution process, and a parallel coordinates diagram to show the pollution situation of urban agglomerations. We have applied our method to the real urban air quality data. Our system was used to explore the evolution of urban agglomeration and provide a necessary foundation for united pollution prevention of urban agglomerations."
216,216,Major Differences of Cloud Computing Adoption in Universities: Europe vs Middle East,['Dec 2014'],https://pureportal.coventry.ac.uk/en/publications/major-differences-of-cloud-computing-adoption-in-universities-eur-2,"['Warwick, K.']",['https://pureportal.coventry.ac.uk/en/persons/kevin-warwick'],"The extensive use of cloud computing in educational institutes around the world brings unique challenges for universities. Some of these challenges are due to clear differences between Europe and Middle East universities. These differencespstem from the natural variation between people. Cloud computing has created a new concept to deal with software services and hardware infrastructure. Some benefits are immediately gained, for instance, to allow students to share theirpinformation easily and to discover new experiences of the education system. However, this introduces more challenges, such as security and configuration of resources in shared environments. Educational institutes cannot escape from these challenges. Yet some differences occur between universities which use cloud computing as an educational tool or a form of social connection. This paper discusses some benefits and limitations of using cloud computing and major differences in using cloud computing at universities in Europe and the Middle East, based on the social perspective, security and economics concepts, and personal responsibility. "
217,217,Extraction of cardiac and respiratory motion information from cardiac x-ray fluoroscopy images using hierarchical manifold learning,['2013'],https://pureportal.coventry.ac.uk/en/publications/extraction-of-cardiac-and-respiratory-motion-information-from-car,"['Ma, Y.']",['https://pureportal.coventry.ac.uk/en/persons/yingliang-ma'],"We present a novel and clinically useful method to automatically determine the regions that carry cardiac and respiratory motion information directly from standard mono-plane X-ray fluoroscopy images. We demonstrate the application of our method for the purposes of retrospective cardiac and respiratory gating of X-ray images. Validation is performed on five mono-plane imaging sequences comprising a total of 284 frames from five patients undergoing radiofrequency ablation for the treatment of atrial fibrillation. We established end-inspiration, end-expiration and systolic gating with success rates of 100%, 100% and 95.3%, respectively. This technique is useful for retrospective gating of X-ray images and, unlike many previously proposed techniques, does not require specific catheters to be visible and works without any knowledge of catheter geometry."
218,218,Infarct Segmentation Challenge on Delayed Enhancement MRI of the Left Ventricle,['2013'],https://pureportal.coventry.ac.uk/en/publications/infarct-segmentation-challenge-on-delayed-enhancement-mri-of-the-,"['Ma, Y.']",['https://pureportal.coventry.ac.uk/en/persons/yingliang-ma'],This paper presents collated results from the Delayed en-hancement MRI (DE-MRI) segmentation challenge as part of MICCAI 2012. DE-MRI Images from fifteen patients and fifteen pigs were randomly selected from two different imaging centres. Three independent sets of manual segmentations were obtained and included in this study. A ground truth consensus segmentation based on all human rater segmentations was obtained using an Expectation-Maximization (EM) method (the STAPLE method). Automated segmentations from five groups contributed to this challenge.
219,219,Real-Time Catheter Extraction from 2D X-Ray Fluoroscopic and 3D Echocardiographic Images for Cardiac Interventions,['2013'],https://pureportal.coventry.ac.uk/en/publications/real-time-catheter-extraction-from-2d-x-ray-fluoroscopic-and-3d-e,"['Ma, Y.']",['https://pureportal.coventry.ac.uk/en/persons/yingliang-ma'],"X-ray fluoroscopic images are widely used for image guidance in cardiac electrophysiology (EP) procedures to diagnose or treat cardiac arrhythmias based on catheter ablation. However, the main disadvantage of fluoroscopic imaging is the lack of soft tissue information and harmful radiation. In contrast, ultrasound (US) has the advantages of low-cost, non-radiation, and high contrast in soft tissue. In this paper we propose a framework to extract the catheter from both X-ray and US images in real time for cardiac interventions. The catheter extraction from X-ray images is based on SURF features, local patch analysis and Kalman filtering to acquire a set of sorted key points representing the catheter. At the same time, the transformation between the X-ray and US images can be obtained via 2D/3D rigid registration between a 3D model of the US probe and its projection on X-ray images. By backprojecting the information about the catheter location in the X-ray images to the US images the search space can be drastically reduced. The extraction of the catheter from US is based on 3D SURF feature clusters, graph model building, A* algorithm and B-spline smoothing. Experiments show the overall process can be achieved in 2.72 seconds for one frame and the reprojected error is 1.99 mm on average."
220,220,Adding Logical Operators to Tree Pattern Queries onGraph-Structured Data,['Aug 2012'],https://pureportal.coventry.ac.uk/en/publications/adding-logical-operators-to-tree-pattern-queries-ongraph-structur,"['Jiang, X.']",['https://pureportal.coventry.ac.uk/en/persons/xiaorui-jiang'],"As data are increasingly modeled as graphs for expressing com-plex relationships, the tree pattern query on graph-structured databecomes an important type of queries in real-world applications.Most practical query languages, such as XQuery and SPARQL,support logical expressions using logical-AND/OR/NOT operatorsto define structural constraints of tree patterns. In this paper, (1)we propose generalized tree pattern queries (GTPQs) over graph-structured data, which fully support propositional logic of struc-tural constraints. (2) We make a thorough study of fundamentalproblems including satisfiability, containment and minimization,and analyze the computational complexity and the decision pro-cedures of these problems. (3) We propose a compact graph repre-sentation of intermediate results and a pruning approach to reducethe size of intermediate results and the number of join operations –two factors that often impair the efficiency of traditional algorithmsfor evaluating tree pattern queries. (4) We present an efficient algo-rithm for evaluating GTPQs using 3-hop as the underlying reach-ability index. (5) Experiments on both real-life and synthetic datasets demonstrate the effectiveness and efficiency of our algorithm,from several times to orders of magnitude faster than state-of-the-art algorithms in terms of evaluation time, even for traditional treepattern queries with only conjunctive operations."
